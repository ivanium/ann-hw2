16:16:13.349 Training @ 0 epoch...
16:16:15.474   Training iter 50, batch loss 0.4504, batch acc 0.1704
16:16:17.579   Training iter 100, batch loss 0.4284, batch acc 0.3242
16:16:19.696   Training iter 150, batch loss 0.3840, batch acc 0.4980
16:16:21.772   Training iter 200, batch loss 0.3233, batch acc 0.6530
16:16:23.870   Training iter 250, batch loss 0.2934, batch acc 0.7230
16:16:25.988   Training iter 300, batch loss 0.2704, batch acc 0.7616
16:16:28.098   Training iter 350, batch loss 0.2594, batch acc 0.7878
16:16:30.464   Training iter 400, batch loss 0.2493, batch acc 0.8042
16:16:32.566   Training iter 450, batch loss 0.2360, batch acc 0.8258
16:16:34.656   Training iter 500, batch loss 0.2323, batch acc 0.8262
16:16:36.744   Training iter 550, batch loss 0.2292, batch acc 0.8328
16:16:38.829   Training iter 600, batch loss 0.2182, batch acc 0.8468
16:16:38.831 Testing @ 0 epoch...
16:16:40.047     Testing, total mean loss 0.21351, total acc 0.85250
16:16:40.047 Training @ 1 epoch...
16:16:42.144   Training iter 50, batch loss 0.2154, batch acc 0.8514
16:16:44.241   Training iter 100, batch loss 0.2116, batch acc 0.8514
16:16:46.335   Training iter 150, batch loss 0.2043, batch acc 0.8688
16:16:48.433   Training iter 200, batch loss 0.1953, batch acc 0.8728
16:16:50.531   Training iter 250, batch loss 0.1961, batch acc 0.8670
16:16:52.643   Training iter 300, batch loss 0.1924, batch acc 0.8698
16:16:54.740   Training iter 350, batch loss 0.1896, batch acc 0.8742
16:16:56.799   Training iter 400, batch loss 0.1810, batch acc 0.8828
16:16:58.837   Training iter 450, batch loss 0.1787, batch acc 0.8822
16:17:00.875   Training iter 500, batch loss 0.1767, batch acc 0.8920
16:17:02.913   Training iter 550, batch loss 0.1757, batch acc 0.8834
16:17:04.953   Training iter 600, batch loss 0.1701, batch acc 0.8956
16:17:04.954 Training @ 2 epoch...
16:17:06.996   Training iter 50, batch loss 0.1651, batch acc 0.8986
16:17:09.040   Training iter 100, batch loss 0.1628, batch acc 0.9048
16:17:11.077   Training iter 150, batch loss 0.1628, batch acc 0.9002
16:17:13.109   Training iter 200, batch loss 0.1614, batch acc 0.9010
16:17:15.150   Training iter 250, batch loss 0.1569, batch acc 0.9072
16:17:17.181   Training iter 300, batch loss 0.1527, batch acc 0.9118
16:17:19.213   Training iter 350, batch loss 0.1538, batch acc 0.9116
16:17:21.253   Training iter 400, batch loss 0.1523, batch acc 0.9184
16:17:23.287   Training iter 450, batch loss 0.1496, batch acc 0.9192
16:17:25.323   Training iter 500, batch loss 0.1494, batch acc 0.9118
16:17:27.355   Training iter 550, batch loss 0.1463, batch acc 0.9208
16:17:29.393   Training iter 600, batch loss 0.1441, batch acc 0.9240
16:17:29.394 Training @ 3 epoch...
16:17:31.436   Training iter 50, batch loss 0.1428, batch acc 0.9224
16:17:33.466   Training iter 100, batch loss 0.1437, batch acc 0.9230
16:17:35.496   Training iter 150, batch loss 0.1410, batch acc 0.9264
16:17:37.532   Training iter 200, batch loss 0.1425, batch acc 0.9262
16:17:39.566   Training iter 250, batch loss 0.1386, batch acc 0.9282
16:17:41.596   Training iter 300, batch loss 0.1395, batch acc 0.9272
16:17:43.595   Training iter 350, batch loss 0.1406, batch acc 0.9202
16:17:45.609   Training iter 400, batch loss 0.1362, batch acc 0.9346
16:17:47.634   Training iter 450, batch loss 0.1371, batch acc 0.9302
16:17:49.665   Training iter 500, batch loss 0.1342, batch acc 0.9372
16:17:51.686   Training iter 550, batch loss 0.1318, batch acc 0.9380
16:17:53.693   Training iter 600, batch loss 0.1379, batch acc 0.9316
16:17:53.694 Training @ 4 epoch...
16:17:55.724   Training iter 50, batch loss 0.1350, batch acc 0.9338
16:17:57.732   Training iter 100, batch loss 0.1311, batch acc 0.9378
16:17:59.738   Training iter 150, batch loss 0.1320, batch acc 0.9362
16:18:01.740   Training iter 200, batch loss 0.1325, batch acc 0.9318
16:18:03.752   Training iter 250, batch loss 0.1329, batch acc 0.9332
16:18:05.774   Training iter 300, batch loss 0.1316, batch acc 0.9392
16:18:07.801   Training iter 350, batch loss 0.1300, batch acc 0.9402
16:18:09.804   Training iter 400, batch loss 0.1321, batch acc 0.9342
16:18:11.803   Training iter 450, batch loss 0.1286, batch acc 0.9392
16:18:13.808   Training iter 500, batch loss 0.1297, batch acc 0.9344
16:18:15.812   Training iter 550, batch loss 0.1281, batch acc 0.9382
16:18:17.815   Training iter 600, batch loss 0.1302, batch acc 0.9332
16:18:17.816 Training @ 5 epoch...
16:18:19.822   Training iter 50, batch loss 0.1281, batch acc 0.9396
16:18:21.827   Training iter 100, batch loss 0.1276, batch acc 0.9390
16:18:23.824   Training iter 150, batch loss 0.1277, batch acc 0.9376
16:18:25.828   Training iter 200, batch loss 0.1286, batch acc 0.9362
16:18:27.840   Training iter 250, batch loss 0.1261, batch acc 0.9426
16:18:29.844   Training iter 300, batch loss 0.1275, batch acc 0.9390
16:18:31.850   Training iter 350, batch loss 0.1262, batch acc 0.9414
16:18:33.851   Training iter 400, batch loss 0.1238, batch acc 0.9440
16:18:35.850   Training iter 450, batch loss 0.1267, batch acc 0.9414
16:18:37.860   Training iter 500, batch loss 0.1234, batch acc 0.9456
16:18:39.864   Training iter 550, batch loss 0.1232, batch acc 0.9452
16:18:41.868   Training iter 600, batch loss 0.1228, batch acc 0.9458
16:18:41.869 Testing @ 5 epoch...
16:18:43.026     Testing, total mean loss 0.12046, total acc 0.94790
16:18:43.026 Training @ 6 epoch...
16:18:45.038   Training iter 50, batch loss 0.1234, batch acc 0.9410
16:18:47.039   Training iter 100, batch loss 0.1244, batch acc 0.9426
16:18:49.038   Training iter 150, batch loss 0.1228, batch acc 0.9464
16:18:51.038   Training iter 200, batch loss 0.1244, batch acc 0.9440
16:18:53.038   Training iter 250, batch loss 0.1230, batch acc 0.9400
16:18:55.048   Training iter 300, batch loss 0.1227, batch acc 0.9434
16:18:57.048   Training iter 350, batch loss 0.1211, batch acc 0.9430
16:18:59.048   Training iter 400, batch loss 0.1206, batch acc 0.9440
16:19:01.046   Training iter 450, batch loss 0.1233, batch acc 0.9454
16:19:03.048   Training iter 500, batch loss 0.1201, batch acc 0.9446
16:19:05.060   Training iter 550, batch loss 0.1203, batch acc 0.9456
16:19:07.063   Training iter 600, batch loss 0.1178, batch acc 0.9474
16:19:07.064 Training @ 7 epoch...
16:19:09.077   Training iter 50, batch loss 0.1218, batch acc 0.9460
16:19:11.099   Training iter 100, batch loss 0.1202, batch acc 0.9456
16:19:13.123   Training iter 150, batch loss 0.1204, batch acc 0.9456
16:19:15.152   Training iter 200, batch loss 0.1216, batch acc 0.9420
16:19:17.179   Training iter 250, batch loss 0.1181, batch acc 0.9456
16:19:19.210   Training iter 300, batch loss 0.1170, batch acc 0.9466
16:19:21.241   Training iter 350, batch loss 0.1196, batch acc 0.9454
16:19:23.271   Training iter 400, batch loss 0.1158, batch acc 0.9512
16:19:25.301   Training iter 450, batch loss 0.1191, batch acc 0.9472
16:19:27.328   Training iter 500, batch loss 0.1215, batch acc 0.9416
16:19:29.353   Training iter 550, batch loss 0.1175, batch acc 0.9506
16:19:31.379   Training iter 600, batch loss 0.1192, batch acc 0.9462
16:19:31.380 Training @ 8 epoch...
16:19:33.389   Training iter 50, batch loss 0.1163, batch acc 0.9476
16:19:35.394   Training iter 100, batch loss 0.1180, batch acc 0.9458
16:19:37.410   Training iter 150, batch loss 0.1172, batch acc 0.9480
16:19:39.416   Training iter 200, batch loss 0.1197, batch acc 0.9430
16:19:41.427   Training iter 250, batch loss 0.1159, batch acc 0.9518
16:19:43.438   Training iter 300, batch loss 0.1157, batch acc 0.9452
16:19:45.452   Training iter 350, batch loss 0.1158, batch acc 0.9520
16:19:47.457   Training iter 400, batch loss 0.1153, batch acc 0.9482
16:19:49.470   Training iter 450, batch loss 0.1143, batch acc 0.9528
16:19:51.487   Training iter 500, batch loss 0.1162, batch acc 0.9490
16:19:53.506   Training iter 550, batch loss 0.1148, batch acc 0.9476
16:19:55.526   Training iter 600, batch loss 0.1160, batch acc 0.9458
16:19:55.527 Training @ 9 epoch...
16:19:57.534   Training iter 50, batch loss 0.1159, batch acc 0.9490
16:19:59.550   Training iter 100, batch loss 0.1152, batch acc 0.9484
16:20:01.556   Training iter 150, batch loss 0.1141, batch acc 0.9494
16:20:03.567   Training iter 200, batch loss 0.1154, batch acc 0.9490
16:20:05.568   Training iter 250, batch loss 0.1120, batch acc 0.9538
16:20:07.568   Training iter 300, batch loss 0.1137, batch acc 0.9494
16:20:09.571   Training iter 350, batch loss 0.1154, batch acc 0.9488
16:20:11.586   Training iter 400, batch loss 0.1158, batch acc 0.9452
16:20:13.598   Training iter 450, batch loss 0.1125, batch acc 0.9534
16:20:15.601   Training iter 500, batch loss 0.1160, batch acc 0.9474
16:20:17.619   Training iter 550, batch loss 0.1147, batch acc 0.9500
16:20:19.644   Training iter 600, batch loss 0.1103, batch acc 0.9524
16:20:19.645 Training @ 10 epoch...
16:20:21.669   Training iter 50, batch loss 0.1154, batch acc 0.9456
16:20:23.678   Training iter 100, batch loss 0.1147, batch acc 0.9526
16:20:25.679   Training iter 150, batch loss 0.1117, batch acc 0.9502
16:20:27.689   Training iter 200, batch loss 0.1154, batch acc 0.9476
16:20:29.698   Training iter 250, batch loss 0.1141, batch acc 0.9460
16:20:31.708   Training iter 300, batch loss 0.1133, batch acc 0.9512
16:20:33.707   Training iter 350, batch loss 0.1120, batch acc 0.9540
16:20:35.706   Training iter 400, batch loss 0.1111, batch acc 0.9518
16:20:37.708   Training iter 450, batch loss 0.1095, batch acc 0.9518
16:20:39.710   Training iter 500, batch loss 0.1131, batch acc 0.9502
16:20:41.720   Training iter 550, batch loss 0.1095, batch acc 0.9568
16:20:43.738   Training iter 600, batch loss 0.1109, batch acc 0.9544
16:20:43.739 Testing @ 10 epoch...
16:20:44.904     Testing, total mean loss 0.10741, total acc 0.95610
16:20:44.904 Training @ 11 epoch...
16:20:46.916   Training iter 50, batch loss 0.1099, batch acc 0.9560
16:20:48.917   Training iter 100, batch loss 0.1145, batch acc 0.9520
16:20:50.924   Training iter 150, batch loss 0.1101, batch acc 0.9534
16:20:52.938   Training iter 200, batch loss 0.1108, batch acc 0.9468
16:20:54.950   Training iter 250, batch loss 0.1111, batch acc 0.9522
16:20:56.957   Training iter 300, batch loss 0.1104, batch acc 0.9524
16:20:58.962   Training iter 350, batch loss 0.1106, batch acc 0.9534
16:21:00.976   Training iter 400, batch loss 0.1119, batch acc 0.9528
16:21:02.976   Training iter 450, batch loss 0.1101, batch acc 0.9514
16:21:04.988   Training iter 500, batch loss 0.1117, batch acc 0.9462
16:21:07.008   Training iter 550, batch loss 0.1116, batch acc 0.9504
16:21:09.011   Training iter 600, batch loss 0.1091, batch acc 0.9552
16:21:09.012 Training @ 12 epoch...
16:21:11.019   Training iter 50, batch loss 0.1080, batch acc 0.9560
16:21:13.038   Training iter 100, batch loss 0.1115, batch acc 0.9518
16:21:15.051   Training iter 150, batch loss 0.1060, batch acc 0.9538
16:21:17.070   Training iter 200, batch loss 0.1109, batch acc 0.9528
16:21:19.089   Training iter 250, batch loss 0.1101, batch acc 0.9544
16:21:21.098   Training iter 300, batch loss 0.1097, batch acc 0.9506
16:21:23.108   Training iter 350, batch loss 0.1119, batch acc 0.9502
16:21:25.119   Training iter 400, batch loss 0.1109, batch acc 0.9520
16:21:27.137   Training iter 450, batch loss 0.1075, batch acc 0.9542
16:21:29.149   Training iter 500, batch loss 0.1124, batch acc 0.9506
16:21:31.167   Training iter 550, batch loss 0.1080, batch acc 0.9570
16:21:33.180   Training iter 600, batch loss 0.1084, batch acc 0.9590
16:21:33.181 Training @ 13 epoch...
16:21:35.199   Training iter 50, batch loss 0.1079, batch acc 0.9544
16:21:37.207   Training iter 100, batch loss 0.1076, batch acc 0.9566
16:21:39.219   Training iter 150, batch loss 0.1087, batch acc 0.9544
16:21:41.218   Training iter 200, batch loss 0.1093, batch acc 0.9518
16:21:43.227   Training iter 250, batch loss 0.1104, batch acc 0.9512
16:21:45.232   Training iter 300, batch loss 0.1095, batch acc 0.9496
16:21:47.240   Training iter 350, batch loss 0.1089, batch acc 0.9522
16:21:49.247   Training iter 400, batch loss 0.1093, batch acc 0.9560
16:21:51.247   Training iter 450, batch loss 0.1065, batch acc 0.9568
16:21:53.247   Training iter 500, batch loss 0.1082, batch acc 0.9588
16:21:55.250   Training iter 550, batch loss 0.1067, batch acc 0.9548
16:21:57.260   Training iter 600, batch loss 0.1095, batch acc 0.9546
16:21:57.261 Training @ 14 epoch...
16:21:59.271   Training iter 50, batch loss 0.1070, batch acc 0.9538
16:22:01.287   Training iter 100, batch loss 0.1077, batch acc 0.9544
16:22:03.289   Training iter 150, batch loss 0.1084, batch acc 0.9524
16:22:05.309   Training iter 200, batch loss 0.1052, batch acc 0.9560
16:22:07.318   Training iter 250, batch loss 0.1104, batch acc 0.9522
16:22:09.333   Training iter 300, batch loss 0.1081, batch acc 0.9536
16:22:11.357   Training iter 350, batch loss 0.1075, batch acc 0.9554
16:22:13.377   Training iter 400, batch loss 0.1056, batch acc 0.9560
16:22:15.394   Training iter 450, batch loss 0.1091, batch acc 0.9498
16:22:17.396   Training iter 500, batch loss 0.1092, batch acc 0.9522
16:22:19.397   Training iter 550, batch loss 0.1054, batch acc 0.9584
16:22:21.407   Training iter 600, batch loss 0.1059, batch acc 0.9600
16:22:21.408 Training @ 15 epoch...
16:22:23.435   Training iter 50, batch loss 0.1085, batch acc 0.9550
16:22:25.449   Training iter 100, batch loss 0.1059, batch acc 0.9576
16:22:27.458   Training iter 150, batch loss 0.1071, batch acc 0.9552
16:22:29.477   Training iter 200, batch loss 0.1061, batch acc 0.9564
16:22:31.489   Training iter 250, batch loss 0.1064, batch acc 0.9536
16:22:33.510   Training iter 300, batch loss 0.1055, batch acc 0.9580
16:22:35.527   Training iter 350, batch loss 0.1070, batch acc 0.9534
16:22:37.526   Training iter 400, batch loss 0.1071, batch acc 0.9536
16:22:39.536   Training iter 450, batch loss 0.1046, batch acc 0.9574
16:22:41.541   Training iter 500, batch loss 0.1075, batch acc 0.9526
16:22:43.548   Training iter 550, batch loss 0.1070, batch acc 0.9550
16:22:45.547   Training iter 600, batch loss 0.1054, batch acc 0.9588
16:22:45.548 Testing @ 15 epoch...
16:22:46.711     Testing, total mean loss 0.10330, total acc 0.95890
16:22:46.711 Training @ 16 epoch...
16:22:48.717   Training iter 50, batch loss 0.1045, batch acc 0.9562
16:22:50.717   Training iter 100, batch loss 0.1082, batch acc 0.9536
16:22:52.728   Training iter 150, batch loss 0.1054, batch acc 0.9526
16:22:54.737   Training iter 200, batch loss 0.1045, batch acc 0.9574
16:22:56.737   Training iter 250, batch loss 0.1075, batch acc 0.9556
16:22:58.738   Training iter 300, batch loss 0.1051, batch acc 0.9552
16:23:00.738   Training iter 350, batch loss 0.1032, batch acc 0.9596
16:23:02.747   Training iter 400, batch loss 0.1066, batch acc 0.9544
16:23:04.752   Training iter 450, batch loss 0.1034, batch acc 0.9556
16:23:06.767   Training iter 500, batch loss 0.1084, batch acc 0.9508
16:23:08.779   Training iter 550, batch loss 0.1041, batch acc 0.9578
16:23:10.799   Training iter 600, batch loss 0.1041, batch acc 0.9594
16:23:10.800 Training @ 17 epoch...
16:23:12.817   Training iter 50, batch loss 0.1055, batch acc 0.9526
16:23:14.830   Training iter 100, batch loss 0.1056, batch acc 0.9540
16:23:16.839   Training iter 150, batch loss 0.1048, batch acc 0.9554
16:23:18.856   Training iter 200, batch loss 0.1049, batch acc 0.9536
16:23:20.861   Training iter 250, batch loss 0.1070, batch acc 0.9550
16:23:22.867   Training iter 300, batch loss 0.1060, batch acc 0.9538
16:23:24.884   Training iter 350, batch loss 0.1053, batch acc 0.9556
16:23:26.898   Training iter 400, batch loss 0.1045, batch acc 0.9530
16:23:28.906   Training iter 450, batch loss 0.1037, batch acc 0.9608
16:23:30.909   Training iter 500, batch loss 0.1042, batch acc 0.9586
16:23:32.927   Training iter 550, batch loss 0.1040, batch acc 0.9574
16:23:34.946   Training iter 600, batch loss 0.1049, batch acc 0.9616
16:23:34.946 Training @ 18 epoch...
16:23:36.961   Training iter 50, batch loss 0.1066, batch acc 0.9570
16:23:38.978   Training iter 100, batch loss 0.1038, batch acc 0.9574
16:23:40.979   Training iter 150, batch loss 0.1049, batch acc 0.9556
16:23:42.988   Training iter 200, batch loss 0.1022, batch acc 0.9608
16:23:44.986   Training iter 250, batch loss 0.1057, batch acc 0.9546
16:23:46.998   Training iter 300, batch loss 0.1030, batch acc 0.9620
16:23:49.008   Training iter 350, batch loss 0.1016, batch acc 0.9606
16:23:51.006   Training iter 400, batch loss 0.1030, batch acc 0.9580
16:23:53.008   Training iter 450, batch loss 0.1045, batch acc 0.9534
16:23:55.016   Training iter 500, batch loss 0.1059, batch acc 0.9576
16:23:57.027   Training iter 550, batch loss 0.1045, batch acc 0.9556
16:23:59.027   Training iter 600, batch loss 0.1038, batch acc 0.9534
16:23:59.028 Training @ 19 epoch...
16:24:01.047   Training iter 50, batch loss 0.1027, batch acc 0.9604
16:24:03.049   Training iter 100, batch loss 0.1020, batch acc 0.9580
16:24:05.071   Training iter 150, batch loss 0.1045, batch acc 0.9590
16:24:07.090   Training iter 200, batch loss 0.1062, batch acc 0.9510
16:24:09.119   Training iter 250, batch loss 0.1019, batch acc 0.9582
16:24:11.143   Training iter 300, batch loss 0.1053, batch acc 0.9524
16:24:13.158   Training iter 350, batch loss 0.1024, batch acc 0.9602
16:24:15.175   Training iter 400, batch loss 0.1046, batch acc 0.9564
16:24:17.203   Training iter 450, batch loss 0.1048, batch acc 0.9588
16:24:19.229   Training iter 500, batch loss 0.1045, batch acc 0.9564
16:24:21.257   Training iter 550, batch loss 0.1027, batch acc 0.9578
16:24:23.277   Training iter 600, batch loss 0.1046, batch acc 0.9524
16:24:23.278 Training @ 20 epoch...
16:24:25.298   Training iter 50, batch loss 0.1021, batch acc 0.9610
16:24:27.321   Training iter 100, batch loss 0.1058, batch acc 0.9508
16:24:29.333   Training iter 150, batch loss 0.1024, batch acc 0.9528
16:24:31.356   Training iter 200, batch loss 0.1063, batch acc 0.9544
16:24:33.379   Training iter 250, batch loss 0.1030, batch acc 0.9590
16:24:35.387   Training iter 300, batch loss 0.1020, batch acc 0.9532
16:24:37.400   Training iter 350, batch loss 0.1031, batch acc 0.9590
16:24:39.426   Training iter 400, batch loss 0.1028, batch acc 0.9592
16:24:41.451   Training iter 450, batch loss 0.1041, batch acc 0.9554
16:24:43.478   Training iter 500, batch loss 0.1028, batch acc 0.9602
16:24:45.497   Training iter 550, batch loss 0.1032, batch acc 0.9598
16:24:47.524   Training iter 600, batch loss 0.1021, batch acc 0.9588
16:24:47.525 Testing @ 20 epoch...
16:24:48.688     Testing, total mean loss 0.09933, total acc 0.95870
16:24:48.688 Training @ 21 epoch...
16:24:50.718   Training iter 50, batch loss 0.1034, batch acc 0.9570
16:24:52.740   Training iter 100, batch loss 0.1017, batch acc 0.9584
16:24:54.758   Training iter 150, batch loss 0.1017, batch acc 0.9600
16:24:56.771   Training iter 200, batch loss 0.1013, batch acc 0.9598
16:24:58.788   Training iter 250, batch loss 0.1008, batch acc 0.9578
16:25:00.793   Training iter 300, batch loss 0.1050, batch acc 0.9502
16:25:02.818   Training iter 350, batch loss 0.1024, batch acc 0.9556
16:25:04.839   Training iter 400, batch loss 0.1042, batch acc 0.9554
16:25:06.848   Training iter 450, batch loss 0.1000, batch acc 0.9592
16:25:08.879   Training iter 500, batch loss 0.1032, batch acc 0.9588
16:25:10.899   Training iter 550, batch loss 0.1041, batch acc 0.9592
16:25:12.925   Training iter 600, batch loss 0.1023, batch acc 0.9616
16:25:12.926 Training @ 22 epoch...
16:25:14.951   Training iter 50, batch loss 0.1057, batch acc 0.9562
16:25:16.957   Training iter 100, batch loss 0.1032, batch acc 0.9594
16:25:18.958   Training iter 150, batch loss 0.1018, batch acc 0.9566
16:25:20.978   Training iter 200, batch loss 0.1021, batch acc 0.9592
16:25:22.998   Training iter 250, batch loss 0.1035, batch acc 0.9568
16:25:25.009   Training iter 300, batch loss 0.1023, batch acc 0.9576
16:25:27.035   Training iter 350, batch loss 0.1001, batch acc 0.9624
16:25:29.049   Training iter 400, batch loss 0.1037, batch acc 0.9550
16:25:31.065   Training iter 450, batch loss 0.1018, batch acc 0.9574
16:25:33.090   Training iter 500, batch loss 0.1009, batch acc 0.9618
16:25:35.112   Training iter 550, batch loss 0.1033, batch acc 0.9578
16:25:37.138   Training iter 600, batch loss 0.1019, batch acc 0.9596
16:25:37.139 Training @ 23 epoch...
16:25:39.162   Training iter 50, batch loss 0.1022, batch acc 0.9588
16:25:41.186   Training iter 100, batch loss 0.1025, batch acc 0.9606
16:25:43.188   Training iter 150, batch loss 0.0998, batch acc 0.9614
16:25:45.188   Training iter 200, batch loss 0.1022, batch acc 0.9576
16:25:47.197   Training iter 250, batch loss 0.1020, batch acc 0.9602
16:25:49.210   Training iter 300, batch loss 0.1023, batch acc 0.9596
16:25:51.227   Training iter 350, batch loss 0.1025, batch acc 0.9542
16:25:53.237   Training iter 400, batch loss 0.1009, batch acc 0.9598
16:25:55.240   Training iter 450, batch loss 0.1011, batch acc 0.9598
16:25:57.258   Training iter 500, batch loss 0.1050, batch acc 0.9570
16:25:59.257   Training iter 550, batch loss 0.1014, batch acc 0.9568
16:26:01.263   Training iter 600, batch loss 0.1025, batch acc 0.9548
16:26:01.264 Training @ 24 epoch...
16:26:03.276   Training iter 50, batch loss 0.1024, batch acc 0.9592
16:26:05.280   Training iter 100, batch loss 0.1004, batch acc 0.9618
16:26:07.292   Training iter 150, batch loss 0.1023, batch acc 0.9598
16:26:09.307   Training iter 200, batch loss 0.1019, batch acc 0.9608
16:26:11.306   Training iter 250, batch loss 0.1012, batch acc 0.9606
16:26:13.319   Training iter 300, batch loss 0.1051, batch acc 0.9546
16:26:15.328   Training iter 350, batch loss 0.1011, batch acc 0.9600
16:26:17.328   Training iter 400, batch loss 0.1044, batch acc 0.9524
16:26:19.338   Training iter 450, batch loss 0.1002, batch acc 0.9624
16:26:21.348   Training iter 500, batch loss 0.1002, batch acc 0.9626
16:26:23.351   Training iter 550, batch loss 0.0996, batch acc 0.9604
16:26:25.368   Training iter 600, batch loss 0.1024, batch acc 0.9550
16:26:25.369 Training @ 25 epoch...
16:26:27.379   Training iter 50, batch loss 0.0998, batch acc 0.9664
16:26:29.390   Training iter 100, batch loss 0.1004, batch acc 0.9562
16:26:31.399   Training iter 150, batch loss 0.1033, batch acc 0.9546
16:26:33.416   Training iter 200, batch loss 0.1022, batch acc 0.9586
16:26:35.417   Training iter 250, batch loss 0.1021, batch acc 0.9598
16:26:37.417   Training iter 300, batch loss 0.1034, batch acc 0.9596
16:26:39.427   Training iter 350, batch loss 0.1009, batch acc 0.9572
16:26:41.428   Training iter 400, batch loss 0.1032, batch acc 0.9624
16:26:43.435   Training iter 450, batch loss 0.1005, batch acc 0.9614
16:26:45.437   Training iter 500, batch loss 0.1018, batch acc 0.9598
16:26:47.438   Training iter 550, batch loss 0.0993, batch acc 0.9576
16:26:49.437   Training iter 600, batch loss 0.1015, batch acc 0.9572
16:26:49.438 Testing @ 25 epoch...
16:26:50.599     Testing, total mean loss 0.09887, total acc 0.96090
16:26:50.600 Training @ 26 epoch...
16:26:52.627   Training iter 50, batch loss 0.1007, batch acc 0.9634
16:26:54.637   Training iter 100, batch loss 0.1014, batch acc 0.9578
16:26:56.645   Training iter 150, batch loss 0.1016, batch acc 0.9602
16:26:58.663   Training iter 200, batch loss 0.1016, batch acc 0.9594
16:27:00.668   Training iter 250, batch loss 0.1025, batch acc 0.9554
16:27:02.678   Training iter 300, batch loss 0.0980, batch acc 0.9640
16:27:04.689   Training iter 350, batch loss 0.1034, batch acc 0.9558
16:27:06.707   Training iter 400, batch loss 0.1020, batch acc 0.9580
16:27:08.707   Training iter 450, batch loss 0.1031, batch acc 0.9544
16:27:10.730   Training iter 500, batch loss 0.1019, batch acc 0.9584
16:27:12.737   Training iter 550, batch loss 0.1004, batch acc 0.9566
16:27:14.748   Training iter 600, batch loss 0.0981, batch acc 0.9614
16:27:14.749 Training @ 27 epoch...
16:27:16.756   Training iter 50, batch loss 0.0998, batch acc 0.9624
16:27:18.757   Training iter 100, batch loss 0.1024, batch acc 0.9608
16:27:20.765   Training iter 150, batch loss 0.1007, batch acc 0.9630
16:27:22.768   Training iter 200, batch loss 0.1005, batch acc 0.9602
16:27:24.778   Training iter 250, batch loss 0.1002, batch acc 0.9588
16:27:26.777   Training iter 300, batch loss 0.0998, batch acc 0.9632
16:27:28.780   Training iter 350, batch loss 0.1012, batch acc 0.9574
16:27:30.789   Training iter 400, batch loss 0.1015, batch acc 0.9618
16:27:32.800   Training iter 450, batch loss 0.1023, batch acc 0.9586
16:27:34.818   Training iter 500, batch loss 0.1017, batch acc 0.9562
16:27:36.818   Training iter 550, batch loss 0.1014, batch acc 0.9566
16:27:38.817   Training iter 600, batch loss 0.1009, batch acc 0.9612
16:27:38.818 Training @ 28 epoch...
16:27:40.827   Training iter 50, batch loss 0.1009, batch acc 0.9610
16:27:42.838   Training iter 100, batch loss 0.1018, batch acc 0.9572
16:27:44.848   Training iter 150, batch loss 0.0990, batch acc 0.9618
16:27:46.858   Training iter 200, batch loss 0.1011, batch acc 0.9608
16:27:48.866   Training iter 250, batch loss 0.1000, batch acc 0.9598
16:27:50.878   Training iter 300, batch loss 0.1013, batch acc 0.9588
16:27:52.887   Training iter 350, batch loss 0.1004, batch acc 0.9604
16:27:54.897   Training iter 400, batch loss 0.0992, batch acc 0.9622
16:27:56.900   Training iter 450, batch loss 0.1033, batch acc 0.9558
16:27:58.908   Training iter 500, batch loss 0.1007, batch acc 0.9602
16:28:00.919   Training iter 550, batch loss 0.1022, batch acc 0.9542
16:28:02.926   Training iter 600, batch loss 0.0993, batch acc 0.9636
16:28:02.927 Training @ 29 epoch...
16:28:04.936   Training iter 50, batch loss 0.0997, batch acc 0.9630
16:28:06.938   Training iter 100, batch loss 0.1013, batch acc 0.9568
16:28:08.948   Training iter 150, batch loss 0.1010, batch acc 0.9602
16:28:10.957   Training iter 200, batch loss 0.1017, batch acc 0.9572
16:28:12.964   Training iter 250, batch loss 0.1042, batch acc 0.9546
16:28:14.967   Training iter 300, batch loss 0.0978, batch acc 0.9644
16:28:16.970   Training iter 350, batch loss 0.1037, batch acc 0.9564
16:28:18.987   Training iter 400, batch loss 0.0980, batch acc 0.9644
16:28:20.986   Training iter 450, batch loss 0.1005, batch acc 0.9588
16:28:22.990   Training iter 500, batch loss 0.0984, batch acc 0.9654
16:28:24.997   Training iter 550, batch loss 0.0993, batch acc 0.9596
16:28:26.997   Training iter 600, batch loss 0.1004, batch acc 0.9646
16:28:26.998 Training @ 30 epoch...
16:28:29.008   Training iter 50, batch loss 0.1020, batch acc 0.9586
16:28:31.007   Training iter 100, batch loss 0.1010, batch acc 0.9594
16:28:33.017   Training iter 150, batch loss 0.0979, batch acc 0.9606
16:28:35.018   Training iter 200, batch loss 0.0984, batch acc 0.9624
16:28:37.018   Training iter 250, batch loss 0.0994, batch acc 0.9600
16:28:39.017   Training iter 300, batch loss 0.0995, batch acc 0.9636
16:28:41.016   Training iter 350, batch loss 0.1024, batch acc 0.9562
16:28:43.016   Training iter 400, batch loss 0.1007, batch acc 0.9650
16:28:45.014   Training iter 450, batch loss 0.0990, batch acc 0.9620
16:28:47.018   Training iter 500, batch loss 0.0991, batch acc 0.9582
16:28:49.013   Training iter 550, batch loss 0.1032, batch acc 0.9580
16:28:51.017   Training iter 600, batch loss 0.1005, batch acc 0.9564
16:28:51.018 Testing @ 30 epoch...
16:28:52.180     Testing, total mean loss 0.09640, total acc 0.96250
16:28:52.180 Training @ 31 epoch...
16:28:54.187   Training iter 50, batch loss 0.0999, batch acc 0.9602
16:28:56.188   Training iter 100, batch loss 0.0979, batch acc 0.9596
16:28:58.196   Training iter 150, batch loss 0.1002, batch acc 0.9620
16:29:00.198   Training iter 200, batch loss 0.1000, batch acc 0.9554
16:29:02.197   Training iter 250, batch loss 0.1004, batch acc 0.9604
16:29:04.207   Training iter 300, batch loss 0.1010, batch acc 0.9592
16:29:06.219   Training iter 350, batch loss 0.0995, batch acc 0.9572
16:29:08.231   Training iter 400, batch loss 0.0992, batch acc 0.9642
16:29:10.239   Training iter 450, batch loss 0.0987, batch acc 0.9598
16:29:12.248   Training iter 500, batch loss 0.1025, batch acc 0.9620
16:29:14.256   Training iter 550, batch loss 0.1009, batch acc 0.9592
16:29:16.268   Training iter 600, batch loss 0.0994, batch acc 0.9626
16:29:16.269 Training @ 32 epoch...
16:29:18.288   Training iter 50, batch loss 0.0993, batch acc 0.9602
16:29:20.297   Training iter 100, batch loss 0.0994, batch acc 0.9650
16:29:22.300   Training iter 150, batch loss 0.1016, batch acc 0.9586
16:29:24.308   Training iter 200, batch loss 0.1008, batch acc 0.9608
16:29:26.308   Training iter 250, batch loss 0.0992, batch acc 0.9628
16:29:28.328   Training iter 300, batch loss 0.0980, batch acc 0.9624
16:29:30.327   Training iter 350, batch loss 0.0998, batch acc 0.9592
16:29:32.342   Training iter 400, batch loss 0.1008, batch acc 0.9580
16:29:34.358   Training iter 450, batch loss 0.1002, batch acc 0.9596
16:29:36.377   Training iter 500, batch loss 0.0994, batch acc 0.9586
16:29:38.378   Training iter 550, batch loss 0.0983, batch acc 0.9602
16:29:40.381   Training iter 600, batch loss 0.1002, batch acc 0.9586
16:29:40.382 Training @ 33 epoch...
16:29:42.387   Training iter 50, batch loss 0.1000, batch acc 0.9634
16:29:44.387   Training iter 100, batch loss 0.0985, batch acc 0.9642
16:29:46.398   Training iter 150, batch loss 0.0994, batch acc 0.9636
16:29:48.407   Training iter 200, batch loss 0.0975, batch acc 0.9606
16:29:50.425   Training iter 250, batch loss 0.0975, batch acc 0.9650
16:29:52.435   Training iter 300, batch loss 0.1005, batch acc 0.9618
16:29:54.453   Training iter 350, batch loss 0.0998, batch acc 0.9618
16:29:56.466   Training iter 400, batch loss 0.1008, batch acc 0.9554
16:29:58.476   Training iter 450, batch loss 0.1004, batch acc 0.9576
16:30:00.489   Training iter 500, batch loss 0.1012, batch acc 0.9580
16:30:02.506   Training iter 550, batch loss 0.0995, batch acc 0.9582
16:30:04.509   Training iter 600, batch loss 0.1004, batch acc 0.9604
16:30:04.510 Training @ 34 epoch...
16:30:06.538   Training iter 50, batch loss 0.1007, batch acc 0.9584
16:30:08.553   Training iter 100, batch loss 0.0986, batch acc 0.9602
16:30:10.561   Training iter 150, batch loss 0.0993, batch acc 0.9602
16:30:12.577   Training iter 200, batch loss 0.0964, batch acc 0.9648
16:30:14.598   Training iter 250, batch loss 0.0981, batch acc 0.9628
16:30:16.618   Training iter 300, batch loss 0.0992, batch acc 0.9636
16:30:18.640   Training iter 350, batch loss 0.1015, batch acc 0.9594
16:30:20.670   Training iter 400, batch loss 0.1014, batch acc 0.9604
16:30:22.698   Training iter 450, batch loss 0.1003, batch acc 0.9580
16:30:24.718   Training iter 500, batch loss 0.1005, batch acc 0.9572
16:30:26.730   Training iter 550, batch loss 0.0996, batch acc 0.9624
16:30:28.747   Training iter 600, batch loss 0.0985, batch acc 0.9614
16:30:28.748 Training @ 35 epoch...
16:30:30.776   Training iter 50, batch loss 0.1007, batch acc 0.9592
16:30:32.801   Training iter 100, batch loss 0.1030, batch acc 0.9596
16:30:34.828   Training iter 150, batch loss 0.0986, batch acc 0.9610
16:30:36.855   Training iter 200, batch loss 0.0977, batch acc 0.9654
16:30:38.881   Training iter 250, batch loss 0.1015, batch acc 0.9562
16:30:40.911   Training iter 300, batch loss 0.0974, batch acc 0.9640
16:30:42.926   Training iter 350, batch loss 0.1003, batch acc 0.9626
16:30:44.951   Training iter 400, batch loss 0.0995, batch acc 0.9606
16:30:46.978   Training iter 450, batch loss 0.0973, batch acc 0.9632
16:30:49.008   Training iter 500, batch loss 0.0989, batch acc 0.9602
16:30:51.031   Training iter 550, batch loss 0.0984, batch acc 0.9590
16:30:53.058   Training iter 600, batch loss 0.0989, batch acc 0.9606
16:30:53.059 Testing @ 35 epoch...
16:30:54.221     Testing, total mean loss 0.09695, total acc 0.96210
16:30:54.221 Training @ 36 epoch...
16:30:56.248   Training iter 50, batch loss 0.1003, batch acc 0.9566
16:30:58.258   Training iter 100, batch loss 0.1003, batch acc 0.9598
16:31:00.270   Training iter 150, batch loss 0.1000, batch acc 0.9600
16:31:02.280   Training iter 200, batch loss 0.1005, batch acc 0.9624
16:31:04.298   Training iter 250, batch loss 0.0984, batch acc 0.9616
16:31:06.309   Training iter 300, batch loss 0.0975, batch acc 0.9630
16:31:08.318   Training iter 350, batch loss 0.0986, batch acc 0.9638
16:31:10.320   Training iter 400, batch loss 0.1002, batch acc 0.9592
16:31:12.337   Training iter 450, batch loss 0.1000, batch acc 0.9598
16:31:14.334   Training iter 500, batch loss 0.0996, batch acc 0.9608
16:31:16.350   Training iter 550, batch loss 0.0975, batch acc 0.9600
16:31:18.357   Training iter 600, batch loss 0.0958, batch acc 0.9628
16:31:18.358 Training @ 37 epoch...
16:31:20.380   Training iter 50, batch loss 0.1004, batch acc 0.9596
16:31:22.398   Training iter 100, batch loss 0.0988, batch acc 0.9642
16:31:24.408   Training iter 150, batch loss 0.0976, batch acc 0.9602
16:31:26.417   Training iter 200, batch loss 0.0987, batch acc 0.9556
16:31:28.430   Training iter 250, batch loss 0.0985, batch acc 0.9628
16:31:30.449   Training iter 300, batch loss 0.0953, batch acc 0.9682
16:31:32.459   Training iter 350, batch loss 0.0977, batch acc 0.9630
16:31:34.469   Training iter 400, batch loss 0.1008, batch acc 0.9566
16:31:36.478   Training iter 450, batch loss 0.1004, batch acc 0.9556
16:31:38.490   Training iter 500, batch loss 0.0995, batch acc 0.9622
16:31:40.502   Training iter 550, batch loss 0.0985, batch acc 0.9620
16:31:42.518   Training iter 600, batch loss 0.0999, batch acc 0.9630
16:31:42.518 Training @ 38 epoch...
16:31:44.528   Training iter 50, batch loss 0.1006, batch acc 0.9596
16:31:46.528   Training iter 100, batch loss 0.1008, batch acc 0.9614
16:31:48.527   Training iter 150, batch loss 0.0992, batch acc 0.9588
16:31:50.530   Training iter 200, batch loss 0.1023, batch acc 0.9566
16:31:52.541   Training iter 250, batch loss 0.0972, batch acc 0.9634
16:31:54.558   Training iter 300, batch loss 0.0962, batch acc 0.9644
16:31:56.566   Training iter 350, batch loss 0.0982, batch acc 0.9604
16:31:58.567   Training iter 400, batch loss 0.0969, batch acc 0.9646
16:32:00.577   Training iter 450, batch loss 0.0978, batch acc 0.9600
16:32:02.578   Training iter 500, batch loss 0.1004, batch acc 0.9574
16:32:04.587   Training iter 550, batch loss 0.0989, batch acc 0.9632
16:32:06.598   Training iter 600, batch loss 0.0985, batch acc 0.9634
16:32:06.599 Training @ 39 epoch...
16:32:08.617   Training iter 50, batch loss 0.0981, batch acc 0.9628
16:32:10.631   Training iter 100, batch loss 0.0976, batch acc 0.9628
16:32:12.644   Training iter 150, batch loss 0.0996, batch acc 0.9580
16:32:14.648   Training iter 200, batch loss 0.0985, batch acc 0.9608
16:32:16.656   Training iter 250, batch loss 0.0982, batch acc 0.9614
16:32:18.677   Training iter 300, batch loss 0.0989, batch acc 0.9594
16:32:20.680   Training iter 350, batch loss 0.0992, batch acc 0.9590
16:32:22.696   Training iter 400, batch loss 0.0993, batch acc 0.9582
16:32:24.701   Training iter 450, batch loss 0.0981, batch acc 0.9672
16:32:26.707   Training iter 500, batch loss 0.0972, batch acc 0.9600
16:32:28.714   Training iter 550, batch loss 0.0998, batch acc 0.9618
16:32:30.732   Training iter 600, batch loss 0.1000, batch acc 0.9600
16:32:30.733 Training @ 40 epoch...
16:32:32.737   Training iter 50, batch loss 0.0973, batch acc 0.9602
16:32:34.737   Training iter 100, batch loss 0.1011, batch acc 0.9560
16:32:36.747   Training iter 150, batch loss 0.0990, batch acc 0.9596
16:32:38.750   Training iter 200, batch loss 0.0986, batch acc 0.9622
16:32:40.757   Training iter 250, batch loss 0.0972, batch acc 0.9614
16:32:42.767   Training iter 300, batch loss 0.0968, batch acc 0.9638
16:32:44.767   Training iter 350, batch loss 0.0990, batch acc 0.9632
16:32:46.783   Training iter 400, batch loss 0.1011, batch acc 0.9572
16:32:48.789   Training iter 450, batch loss 0.0978, batch acc 0.9624
16:32:50.798   Training iter 500, batch loss 0.0961, batch acc 0.9648
16:32:52.799   Training iter 550, batch loss 0.1003, batch acc 0.9578
16:32:54.818   Training iter 600, batch loss 0.1000, batch acc 0.9566
16:32:54.819 Testing @ 40 epoch...
16:32:55.981     Testing, total mean loss 0.09543, total acc 0.96340
16:32:55.981 Training @ 41 epoch...
16:32:57.998   Training iter 50, batch loss 0.0985, batch acc 0.9594
16:33:00.008   Training iter 100, batch loss 0.0979, batch acc 0.9584
16:33:02.008   Training iter 150, batch loss 0.0970, batch acc 0.9688
16:33:04.017   Training iter 200, batch loss 0.0977, batch acc 0.9642
16:33:06.034   Training iter 250, batch loss 0.0992, batch acc 0.9612
16:33:08.042   Training iter 300, batch loss 0.0989, batch acc 0.9606
16:33:10.058   Training iter 350, batch loss 0.0978, batch acc 0.9640
16:33:12.067   Training iter 400, batch loss 0.1009, batch acc 0.9572
16:33:14.075   Training iter 450, batch loss 0.0984, batch acc 0.9614
16:33:16.090   Training iter 500, batch loss 0.0968, batch acc 0.9634
16:33:18.096   Training iter 550, batch loss 0.0995, batch acc 0.9582
16:33:20.108   Training iter 600, batch loss 0.0980, batch acc 0.9596
16:33:20.109 Training @ 42 epoch...
16:33:22.118   Training iter 50, batch loss 0.1001, batch acc 0.9612
16:33:24.127   Training iter 100, batch loss 0.1009, batch acc 0.9568
16:33:26.138   Training iter 150, batch loss 0.0977, batch acc 0.9622
16:33:28.139   Training iter 200, batch loss 0.0994, batch acc 0.9622
16:33:30.161   Training iter 250, batch loss 0.0973, batch acc 0.9608
16:33:32.179   Training iter 300, batch loss 0.0993, batch acc 0.9594
16:33:34.189   Training iter 350, batch loss 0.0982, batch acc 0.9598
16:33:36.209   Training iter 400, batch loss 0.0991, batch acc 0.9618
16:33:38.227   Training iter 450, batch loss 0.0971, batch acc 0.9650
16:33:40.237   Training iter 500, batch loss 0.0966, batch acc 0.9622
16:33:42.246   Training iter 550, batch loss 0.0982, batch acc 0.9596
16:33:44.256   Training iter 600, batch loss 0.0958, batch acc 0.9634
16:33:44.257 Training @ 43 epoch...
16:33:46.277   Training iter 50, batch loss 0.0970, batch acc 0.9632
16:33:48.288   Training iter 100, batch loss 0.0974, batch acc 0.9608
16:33:50.309   Training iter 150, batch loss 0.1013, batch acc 0.9578
16:33:52.317   Training iter 200, batch loss 0.0995, batch acc 0.9618
16:33:54.339   Training iter 250, batch loss 0.1013, batch acc 0.9574
16:33:56.358   Training iter 300, batch loss 0.0967, batch acc 0.9604
16:33:58.358   Training iter 350, batch loss 0.0970, batch acc 0.9654
16:34:00.368   Training iter 400, batch loss 0.0985, batch acc 0.9622
16:34:02.377   Training iter 450, batch loss 0.0964, batch acc 0.9658
16:34:04.377   Training iter 500, batch loss 0.0985, batch acc 0.9596
16:34:06.394   Training iter 550, batch loss 0.0974, batch acc 0.9604
16:34:08.401   Training iter 600, batch loss 0.0952, batch acc 0.9630
16:34:08.401 Training @ 44 epoch...
16:34:10.411   Training iter 50, batch loss 0.0982, batch acc 0.9602
16:34:12.421   Training iter 100, batch loss 0.0977, batch acc 0.9598
16:34:14.428   Training iter 150, batch loss 0.0974, batch acc 0.9636
16:34:16.445   Training iter 200, batch loss 0.0985, batch acc 0.9618
16:34:18.464   Training iter 250, batch loss 0.0975, batch acc 0.9602
16:34:20.467   Training iter 300, batch loss 0.0984, batch acc 0.9598
16:34:22.478   Training iter 350, batch loss 0.0979, batch acc 0.9612
16:34:24.494   Training iter 400, batch loss 0.0990, batch acc 0.9574
16:34:26.509   Training iter 450, batch loss 0.0988, batch acc 0.9612
16:34:28.525   Training iter 500, batch loss 0.0990, batch acc 0.9590
16:34:30.538   Training iter 550, batch loss 0.0963, batch acc 0.9652
16:34:32.538   Training iter 600, batch loss 0.0978, batch acc 0.9634
16:34:32.539 Training @ 45 epoch...
16:34:34.557   Training iter 50, batch loss 0.0982, batch acc 0.9608
16:34:36.558   Training iter 100, batch loss 0.0962, batch acc 0.9632
16:34:38.557   Training iter 150, batch loss 0.0974, batch acc 0.9626
16:34:40.558   Training iter 200, batch loss 0.0977, batch acc 0.9586
16:34:42.569   Training iter 250, batch loss 0.0955, batch acc 0.9664
16:34:44.579   Training iter 300, batch loss 0.0998, batch acc 0.9580
16:34:46.596   Training iter 350, batch loss 0.0979, batch acc 0.9604
16:34:48.598   Training iter 400, batch loss 0.0958, batch acc 0.9652
16:34:50.609   Training iter 450, batch loss 0.0987, batch acc 0.9602
16:34:52.617   Training iter 500, batch loss 0.0992, batch acc 0.9608
16:34:54.616   Training iter 550, batch loss 0.0978, batch acc 0.9618
16:34:56.620   Training iter 600, batch loss 0.0985, batch acc 0.9614
16:34:56.621 Testing @ 45 epoch...
16:34:57.780     Testing, total mean loss 0.09424, total acc 0.96460
16:34:57.780 Training @ 46 epoch...
16:34:59.800   Training iter 50, batch loss 0.0963, batch acc 0.9624
16:35:01.822   Training iter 100, batch loss 0.0973, batch acc 0.9670
16:35:03.838   Training iter 150, batch loss 0.0986, batch acc 0.9586
16:35:05.858   Training iter 200, batch loss 0.0968, batch acc 0.9642
16:35:07.878   Training iter 250, batch loss 0.0973, batch acc 0.9588
16:35:09.888   Training iter 300, batch loss 0.0979, batch acc 0.9598
16:35:11.898   Training iter 350, batch loss 0.0959, batch acc 0.9652
16:35:13.917   Training iter 400, batch loss 0.0973, batch acc 0.9586
16:35:15.918   Training iter 450, batch loss 0.0985, batch acc 0.9576
16:35:17.942   Training iter 500, batch loss 0.0999, batch acc 0.9614
16:35:19.967   Training iter 550, batch loss 0.0954, batch acc 0.9644
16:35:21.967   Training iter 600, batch loss 0.0999, batch acc 0.9606
16:35:21.968 Training @ 47 epoch...
16:35:23.988   Training iter 50, batch loss 0.0983, batch acc 0.9574
16:35:25.988   Training iter 100, batch loss 0.0960, batch acc 0.9628
16:35:27.987   Training iter 150, batch loss 0.1003, batch acc 0.9598
16:35:29.993   Training iter 200, batch loss 0.0969, batch acc 0.9608
16:35:32.001   Training iter 250, batch loss 0.0976, batch acc 0.9626
16:35:34.010   Training iter 300, batch loss 0.0984, batch acc 0.9616
16:35:36.019   Training iter 350, batch loss 0.0973, batch acc 0.9614
16:35:38.017   Training iter 400, batch loss 0.0991, batch acc 0.9598
16:35:40.030   Training iter 450, batch loss 0.0976, batch acc 0.9640
16:35:42.037   Training iter 500, batch loss 0.0969, batch acc 0.9614
16:35:44.037   Training iter 550, batch loss 0.0967, batch acc 0.9620
16:35:46.038   Training iter 600, batch loss 0.0976, batch acc 0.9618
16:35:46.039 Training @ 48 epoch...
16:35:48.047   Training iter 50, batch loss 0.0970, batch acc 0.9626
16:35:50.048   Training iter 100, batch loss 0.0971, batch acc 0.9580
16:35:52.048   Training iter 150, batch loss 0.0982, batch acc 0.9582
16:35:54.061   Training iter 200, batch loss 0.0987, batch acc 0.9604
16:35:56.064   Training iter 250, batch loss 0.0976, batch acc 0.9606
16:35:58.068   Training iter 300, batch loss 0.0973, batch acc 0.9642
16:36:00.069   Training iter 350, batch loss 0.0972, batch acc 0.9612
16:36:02.077   Training iter 400, batch loss 0.0983, batch acc 0.9624
16:36:04.089   Training iter 450, batch loss 0.0979, batch acc 0.9654
16:36:06.101   Training iter 500, batch loss 0.0959, batch acc 0.9630
16:36:08.108   Training iter 550, batch loss 0.0958, batch acc 0.9620
16:36:10.107   Training iter 600, batch loss 0.0975, batch acc 0.9582
16:36:10.108 Training @ 49 epoch...
16:36:12.121   Training iter 50, batch loss 0.0978, batch acc 0.9620
16:36:14.127   Training iter 100, batch loss 0.0963, batch acc 0.9658
16:36:16.137   Training iter 150, batch loss 0.0961, batch acc 0.9584
16:36:18.137   Training iter 200, batch loss 0.0978, batch acc 0.9636
16:36:20.139   Training iter 250, batch loss 0.0966, batch acc 0.9626
16:36:22.147   Training iter 300, batch loss 0.0967, batch acc 0.9634
16:36:24.149   Training iter 350, batch loss 0.1001, batch acc 0.9578
16:36:26.157   Training iter 400, batch loss 0.0969, batch acc 0.9644
16:36:28.158   Training iter 450, batch loss 0.0977, batch acc 0.9644
16:36:30.167   Training iter 500, batch loss 0.0971, batch acc 0.9598
16:36:32.169   Training iter 550, batch loss 0.0988, batch acc 0.9624
16:36:34.179   Training iter 600, batch loss 0.0959, batch acc 0.9598
16:36:34.179 Training @ 50 epoch...
16:36:36.190   Training iter 50, batch loss 0.0960, batch acc 0.9628
16:36:38.211   Training iter 100, batch loss 0.0993, batch acc 0.9586
16:36:40.227   Training iter 150, batch loss 0.0942, batch acc 0.9650
16:36:42.227   Training iter 200, batch loss 0.0973, batch acc 0.9592
16:36:44.230   Training iter 250, batch loss 0.0969, batch acc 0.9624
16:36:46.245   Training iter 300, batch loss 0.0968, batch acc 0.9634
16:36:48.265   Training iter 350, batch loss 0.0978, batch acc 0.9590
16:36:50.278   Training iter 400, batch loss 0.0976, batch acc 0.9658
16:36:52.293   Training iter 450, batch loss 0.0961, batch acc 0.9636
16:36:54.308   Training iter 500, batch loss 0.0997, batch acc 0.9576
16:36:56.308   Training iter 550, batch loss 0.0972, batch acc 0.9630
16:36:58.318   Training iter 600, batch loss 0.0975, batch acc 0.9604
16:36:58.319 Testing @ 50 epoch...
16:36:59.542     Testing, total mean loss 0.09327, total acc 0.96420
16:36:59.543 Training @ 51 epoch...
16:37:01.625   Training iter 50, batch loss 0.0956, batch acc 0.9634
16:37:03.635   Training iter 100, batch loss 0.0999, batch acc 0.9618
16:37:05.636   Training iter 150, batch loss 0.0958, batch acc 0.9628
16:37:07.643   Training iter 200, batch loss 0.0972, batch acc 0.9614
16:37:09.643   Training iter 250, batch loss 0.0955, batch acc 0.9630
16:37:11.644   Training iter 300, batch loss 0.0978, batch acc 0.9640
16:37:13.647   Training iter 350, batch loss 0.0975, batch acc 0.9612
16:37:15.646   Training iter 400, batch loss 0.0972, batch acc 0.9630
16:37:17.647   Training iter 450, batch loss 0.0973, batch acc 0.9614
16:37:19.649   Training iter 500, batch loss 0.0995, batch acc 0.9612
16:37:21.655   Training iter 550, batch loss 0.0946, batch acc 0.9648
16:37:23.665   Training iter 600, batch loss 0.0966, batch acc 0.9594
16:37:23.666 Training @ 52 epoch...
16:37:25.684   Training iter 50, batch loss 0.0988, batch acc 0.9602
16:37:27.682   Training iter 100, batch loss 0.0959, batch acc 0.9642
16:37:29.695   Training iter 150, batch loss 0.0968, batch acc 0.9594
16:37:31.699   Training iter 200, batch loss 0.0976, batch acc 0.9638
16:37:33.698   Training iter 250, batch loss 0.0980, batch acc 0.9602
16:37:35.712   Training iter 300, batch loss 0.0957, batch acc 0.9642
16:37:37.718   Training iter 350, batch loss 0.0982, batch acc 0.9610
16:37:39.726   Training iter 400, batch loss 0.0951, batch acc 0.9644
16:37:41.727   Training iter 450, batch loss 0.0980, batch acc 0.9618
16:37:43.731   Training iter 500, batch loss 0.0981, batch acc 0.9602
16:37:45.740   Training iter 550, batch loss 0.0955, batch acc 0.9628
16:37:47.740   Training iter 600, batch loss 0.0982, batch acc 0.9610
16:37:47.741 Training @ 53 epoch...
16:37:49.754   Training iter 50, batch loss 0.0973, batch acc 0.9582
16:37:51.756   Training iter 100, batch loss 0.0985, batch acc 0.9596
16:37:53.762   Training iter 150, batch loss 0.0960, batch acc 0.9656
16:37:55.765   Training iter 200, batch loss 0.0976, batch acc 0.9594
16:37:57.765   Training iter 250, batch loss 0.0957, batch acc 0.9630
16:37:59.772   Training iter 300, batch loss 0.0963, batch acc 0.9636
16:38:01.778   Training iter 350, batch loss 0.0968, batch acc 0.9586
16:38:03.779   Training iter 400, batch loss 0.0984, batch acc 0.9616
16:38:05.786   Training iter 450, batch loss 0.0995, batch acc 0.9582
16:38:07.787   Training iter 500, batch loss 0.0963, batch acc 0.9674
16:38:09.785   Training iter 550, batch loss 0.0940, batch acc 0.9634
16:38:11.792   Training iter 600, batch loss 0.0973, batch acc 0.9630
16:38:11.793 Training @ 54 epoch...
16:38:13.801   Training iter 50, batch loss 0.0954, batch acc 0.9638
16:38:15.806   Training iter 100, batch loss 0.0974, batch acc 0.9600
16:38:17.812   Training iter 150, batch loss 0.0973, batch acc 0.9608
16:38:19.813   Training iter 200, batch loss 0.0963, batch acc 0.9620
16:38:21.814   Training iter 250, batch loss 0.0984, batch acc 0.9612
16:38:23.818   Training iter 300, batch loss 0.0980, batch acc 0.9602
16:38:25.821   Training iter 350, batch loss 0.0965, batch acc 0.9646
16:38:27.821   Training iter 400, batch loss 0.0968, batch acc 0.9588
16:38:29.823   Training iter 450, batch loss 0.0963, batch acc 0.9624
16:38:31.825   Training iter 500, batch loss 0.0973, batch acc 0.9624
16:38:33.829   Training iter 550, batch loss 0.0963, batch acc 0.9608
16:38:35.831   Training iter 600, batch loss 0.0949, batch acc 0.9644
16:38:35.832 Training @ 55 epoch...
16:38:37.845   Training iter 50, batch loss 0.0981, batch acc 0.9586
16:38:39.845   Training iter 100, batch loss 0.0942, batch acc 0.9664
16:38:41.842   Training iter 150, batch loss 0.0969, batch acc 0.9598
16:38:43.842   Training iter 200, batch loss 0.0974, batch acc 0.9618
16:38:45.848   Training iter 250, batch loss 0.0966, batch acc 0.9652
16:38:47.846   Training iter 300, batch loss 0.0971, batch acc 0.9596
16:38:49.849   Training iter 350, batch loss 0.0977, batch acc 0.9604
16:38:51.856   Training iter 400, batch loss 0.0967, batch acc 0.9620
16:38:53.862   Training iter 450, batch loss 0.0958, batch acc 0.9646
16:38:55.868   Training iter 500, batch loss 0.0966, batch acc 0.9626
16:38:57.871   Training iter 550, batch loss 0.0954, batch acc 0.9658
16:38:59.877   Training iter 600, batch loss 0.0976, batch acc 0.9580
16:38:59.878 Testing @ 55 epoch...
16:39:01.044     Testing, total mean loss 0.09314, total acc 0.96480
16:39:01.044 Training @ 56 epoch...
16:39:03.048   Training iter 50, batch loss 0.0958, batch acc 0.9650
16:39:05.048   Training iter 100, batch loss 0.0978, batch acc 0.9634
16:39:07.048   Training iter 150, batch loss 0.0978, batch acc 0.9620
16:39:09.048   Training iter 200, batch loss 0.0968, batch acc 0.9618
16:39:11.046   Training iter 250, batch loss 0.0981, batch acc 0.9612
16:39:13.046   Training iter 300, batch loss 0.0986, batch acc 0.9610
16:39:15.047   Training iter 350, batch loss 0.0946, batch acc 0.9636
16:39:17.047   Training iter 400, batch loss 0.0954, batch acc 0.9630
16:39:19.046   Training iter 450, batch loss 0.0941, batch acc 0.9658
16:39:21.046   Training iter 500, batch loss 0.0950, batch acc 0.9638
16:39:23.047   Training iter 550, batch loss 0.0976, batch acc 0.9624
16:39:25.046   Training iter 600, batch loss 0.0975, batch acc 0.9592
16:39:25.047 Training @ 57 epoch...
16:39:27.057   Training iter 50, batch loss 0.0972, batch acc 0.9642
16:39:29.058   Training iter 100, batch loss 0.0959, batch acc 0.9646
16:39:31.056   Training iter 150, batch loss 0.0976, batch acc 0.9602
16:39:33.059   Training iter 200, batch loss 0.0960, batch acc 0.9600
16:39:35.056   Training iter 250, batch loss 0.0948, batch acc 0.9628
16:39:37.057   Training iter 300, batch loss 0.0986, batch acc 0.9586
16:39:39.057   Training iter 350, batch loss 0.0960, batch acc 0.9630
16:39:41.059   Training iter 400, batch loss 0.0970, batch acc 0.9652
16:39:43.056   Training iter 450, batch loss 0.0976, batch acc 0.9644
16:39:45.057   Training iter 500, batch loss 0.0957, batch acc 0.9634
16:39:47.058   Training iter 550, batch loss 0.0955, batch acc 0.9626
16:39:49.057   Training iter 600, batch loss 0.0954, batch acc 0.9598
16:39:49.058 Training @ 58 epoch...
16:39:51.071   Training iter 50, batch loss 0.0960, batch acc 0.9650
16:39:53.080   Training iter 100, batch loss 0.0976, batch acc 0.9578
16:39:55.089   Training iter 150, batch loss 0.0936, batch acc 0.9666
16:39:57.098   Training iter 200, batch loss 0.0989, batch acc 0.9620
16:39:59.102   Training iter 250, batch loss 0.0942, batch acc 0.9672
16:40:01.117   Training iter 300, batch loss 0.0989, batch acc 0.9586
16:40:03.118   Training iter 350, batch loss 0.0982, batch acc 0.9628
16:40:05.118   Training iter 400, batch loss 0.0948, batch acc 0.9636
16:40:07.126   Training iter 450, batch loss 0.0962, batch acc 0.9638
16:40:09.128   Training iter 500, batch loss 0.0967, batch acc 0.9608
16:40:11.128   Training iter 550, batch loss 0.0969, batch acc 0.9626
16:40:13.128   Training iter 600, batch loss 0.0970, batch acc 0.9608
16:40:13.129 Training @ 59 epoch...
16:40:15.148   Training iter 50, batch loss 0.0963, batch acc 0.9622
16:40:17.147   Training iter 100, batch loss 0.0970, batch acc 0.9610
16:40:19.148   Training iter 150, batch loss 0.0972, batch acc 0.9616
16:40:21.147   Training iter 200, batch loss 0.0987, batch acc 0.9616
16:40:23.148   Training iter 250, batch loss 0.0969, batch acc 0.9656
16:40:25.148   Training iter 300, batch loss 0.0962, batch acc 0.9618
16:40:27.148   Training iter 350, batch loss 0.0941, batch acc 0.9614
16:40:29.147   Training iter 400, batch loss 0.0950, batch acc 0.9646
16:40:31.157   Training iter 450, batch loss 0.0960, batch acc 0.9646
16:40:33.157   Training iter 500, batch loss 0.0963, batch acc 0.9626
16:40:35.158   Training iter 550, batch loss 0.0957, batch acc 0.9656
16:40:37.158   Training iter 600, batch loss 0.0985, batch acc 0.9576
16:40:37.159 Training @ 60 epoch...
16:40:39.168   Training iter 50, batch loss 0.0948, batch acc 0.9650
16:40:41.168   Training iter 100, batch loss 0.0986, batch acc 0.9586
16:40:43.170   Training iter 150, batch loss 0.0975, batch acc 0.9654
16:40:45.181   Training iter 200, batch loss 0.0974, batch acc 0.9598
16:40:47.188   Training iter 250, batch loss 0.0950, batch acc 0.9644
16:40:49.198   Training iter 300, batch loss 0.0983, batch acc 0.9588
16:40:51.197   Training iter 350, batch loss 0.0965, batch acc 0.9632
16:40:53.210   Training iter 400, batch loss 0.0932, batch acc 0.9672
16:40:55.220   Training iter 450, batch loss 0.0962, batch acc 0.9622
16:40:57.237   Training iter 500, batch loss 0.0961, batch acc 0.9624
16:40:59.247   Training iter 550, batch loss 0.0957, batch acc 0.9596
16:41:01.250   Training iter 600, batch loss 0.0975, batch acc 0.9614
16:41:01.251 Testing @ 60 epoch...
16:41:02.486     Testing, total mean loss 0.09188, total acc 0.96500
16:41:02.486 Training @ 61 epoch...
16:41:04.631   Training iter 50, batch loss 0.0967, batch acc 0.9616
16:41:06.684   Training iter 100, batch loss 0.0944, batch acc 0.9684
16:41:08.736   Training iter 150, batch loss 0.0969, batch acc 0.9630
16:41:10.780   Training iter 200, batch loss 0.0956, batch acc 0.9632
16:41:12.829   Training iter 250, batch loss 0.0947, batch acc 0.9620
16:41:14.880   Training iter 300, batch loss 0.0947, batch acc 0.9630
16:41:16.923   Training iter 350, batch loss 0.0997, batch acc 0.9558
16:41:18.969   Training iter 400, batch loss 0.0951, batch acc 0.9658
16:41:21.017   Training iter 450, batch loss 0.0966, batch acc 0.9616
16:41:23.066   Training iter 500, batch loss 0.0973, batch acc 0.9646
16:41:25.116   Training iter 550, batch loss 0.0958, batch acc 0.9606
16:41:27.168   Training iter 600, batch loss 0.0985, batch acc 0.9624
16:41:27.169 Training @ 62 epoch...
16:41:29.222   Training iter 50, batch loss 0.0924, batch acc 0.9672
16:41:31.272   Training iter 100, batch loss 0.0964, batch acc 0.9650
16:41:33.319   Training iter 150, batch loss 0.0967, batch acc 0.9614
16:41:35.373   Training iter 200, batch loss 0.0963, batch acc 0.9624
16:41:37.421   Training iter 250, batch loss 0.0973, batch acc 0.9628
16:41:39.477   Training iter 300, batch loss 0.0966, batch acc 0.9614
16:41:41.525   Training iter 350, batch loss 0.0981, batch acc 0.9594
16:41:43.573   Training iter 400, batch loss 0.0971, batch acc 0.9610
16:41:45.626   Training iter 450, batch loss 0.0953, batch acc 0.9640
16:41:47.675   Training iter 500, batch loss 0.0942, batch acc 0.9654
16:41:49.726   Training iter 550, batch loss 0.0966, batch acc 0.9592
16:41:51.779   Training iter 600, batch loss 0.0953, batch acc 0.9632
16:41:51.780 Training @ 63 epoch...
16:41:53.834   Training iter 50, batch loss 0.0961, batch acc 0.9630
16:41:55.883   Training iter 100, batch loss 0.0951, batch acc 0.9656
16:41:57.932   Training iter 150, batch loss 0.0957, batch acc 0.9650
16:41:59.988   Training iter 200, batch loss 0.0951, batch acc 0.9636
16:42:02.041   Training iter 250, batch loss 0.0958, batch acc 0.9620
16:42:04.089   Training iter 300, batch loss 0.0959, batch acc 0.9624
16:42:06.138   Training iter 350, batch loss 0.0971, batch acc 0.9642
16:42:08.188   Training iter 400, batch loss 0.0967, batch acc 0.9630
16:42:10.238   Training iter 450, batch loss 0.0972, batch acc 0.9642
16:42:12.285   Training iter 500, batch loss 0.0976, batch acc 0.9628
16:42:14.333   Training iter 550, batch loss 0.0962, batch acc 0.9584
16:42:16.383   Training iter 600, batch loss 0.0954, batch acc 0.9580
16:42:16.384 Training @ 64 epoch...
16:42:18.433   Training iter 50, batch loss 0.0951, batch acc 0.9632
16:42:20.479   Training iter 100, batch loss 0.0969, batch acc 0.9620
16:42:22.526   Training iter 150, batch loss 0.0966, batch acc 0.9608
16:42:24.571   Training iter 200, batch loss 0.0937, batch acc 0.9638
16:42:26.617   Training iter 250, batch loss 0.0994, batch acc 0.9572
16:42:28.659   Training iter 300, batch loss 0.0944, batch acc 0.9654
16:42:30.707   Training iter 350, batch loss 0.0939, batch acc 0.9674
16:42:32.754   Training iter 400, batch loss 0.0956, batch acc 0.9634
16:42:34.798   Training iter 450, batch loss 0.0951, batch acc 0.9622
16:42:36.841   Training iter 500, batch loss 0.0976, batch acc 0.9594
16:42:38.889   Training iter 550, batch loss 0.0960, batch acc 0.9628
16:42:40.934   Training iter 600, batch loss 0.0970, batch acc 0.9636
16:42:40.935 Training @ 65 epoch...
16:42:42.986   Training iter 50, batch loss 0.0957, batch acc 0.9608
16:42:45.041   Training iter 100, batch loss 0.0968, batch acc 0.9610
16:42:47.096   Training iter 150, batch loss 0.0995, batch acc 0.9568
16:42:49.149   Training iter 200, batch loss 0.0946, batch acc 0.9658
16:42:51.203   Training iter 250, batch loss 0.0942, batch acc 0.9640
16:42:53.256   Training iter 300, batch loss 0.0958, batch acc 0.9672
16:42:55.312   Training iter 350, batch loss 0.0951, batch acc 0.9650
16:42:57.366   Training iter 400, batch loss 0.0983, batch acc 0.9618
16:42:59.420   Training iter 450, batch loss 0.0949, batch acc 0.9614
16:43:01.475   Training iter 500, batch loss 0.0955, batch acc 0.9634
16:43:03.531   Training iter 550, batch loss 0.0955, batch acc 0.9630
16:43:05.583   Training iter 600, batch loss 0.0943, batch acc 0.9630
16:43:05.584 Testing @ 65 epoch...
16:43:06.774     Testing, total mean loss 0.09250, total acc 0.96530
16:43:06.774 Training @ 66 epoch...
16:43:08.822   Training iter 50, batch loss 0.0956, batch acc 0.9620
16:43:10.863   Training iter 100, batch loss 0.0928, batch acc 0.9658
16:43:12.912   Training iter 150, batch loss 0.0968, batch acc 0.9634
16:43:14.958   Training iter 200, batch loss 0.0943, batch acc 0.9640
16:43:17.004   Training iter 250, batch loss 0.0969, batch acc 0.9660
16:43:19.053   Training iter 300, batch loss 0.0950, batch acc 0.9656
16:43:21.104   Training iter 350, batch loss 0.0979, batch acc 0.9578
16:43:23.150   Training iter 400, batch loss 0.0956, batch acc 0.9614
16:43:25.196   Training iter 450, batch loss 0.0954, batch acc 0.9650
16:43:27.243   Training iter 500, batch loss 0.0947, batch acc 0.9628
16:43:29.292   Training iter 550, batch loss 0.0967, batch acc 0.9604
16:43:31.340   Training iter 600, batch loss 0.0973, batch acc 0.9592
16:43:31.341 Training @ 67 epoch...
16:43:33.393   Training iter 50, batch loss 0.0961, batch acc 0.9616
16:43:35.441   Training iter 100, batch loss 0.0973, batch acc 0.9582
16:43:37.490   Training iter 150, batch loss 0.0936, batch acc 0.9656
16:43:39.538   Training iter 200, batch loss 0.0976, batch acc 0.9580
16:43:41.586   Training iter 250, batch loss 0.0945, batch acc 0.9630
16:43:43.637   Training iter 300, batch loss 0.0959, batch acc 0.9592
16:43:45.691   Training iter 350, batch loss 0.0933, batch acc 0.9656
16:43:47.741   Training iter 400, batch loss 0.0970, batch acc 0.9602
16:43:49.791   Training iter 450, batch loss 0.0941, batch acc 0.9680
16:43:51.841   Training iter 500, batch loss 0.0975, batch acc 0.9622
16:43:53.891   Training iter 550, batch loss 0.0945, batch acc 0.9688
16:43:55.942   Training iter 600, batch loss 0.0959, batch acc 0.9630
16:43:55.943 Training @ 68 epoch...
16:43:57.995   Training iter 50, batch loss 0.0940, batch acc 0.9656
16:44:00.042   Training iter 100, batch loss 0.0950, batch acc 0.9624
16:44:02.092   Training iter 150, batch loss 0.0965, batch acc 0.9618
16:44:04.142   Training iter 200, batch loss 0.0983, batch acc 0.9604
16:44:06.191   Training iter 250, batch loss 0.0944, batch acc 0.9652
16:44:08.243   Training iter 300, batch loss 0.0953, batch acc 0.9656
16:44:10.295   Training iter 350, batch loss 0.0961, batch acc 0.9606
16:44:12.345   Training iter 400, batch loss 0.0962, batch acc 0.9610
16:44:14.394   Training iter 450, batch loss 0.0938, batch acc 0.9642
16:44:16.449   Training iter 500, batch loss 0.0957, batch acc 0.9632
16:44:18.494   Training iter 550, batch loss 0.0966, batch acc 0.9602
16:44:20.543   Training iter 600, batch loss 0.0953, batch acc 0.9634
16:44:20.544 Training @ 69 epoch...
16:44:22.594   Training iter 50, batch loss 0.0978, batch acc 0.9596
16:44:24.648   Training iter 100, batch loss 0.0959, batch acc 0.9588
16:44:26.697   Training iter 150, batch loss 0.0948, batch acc 0.9648
16:44:28.747   Training iter 200, batch loss 0.0945, batch acc 0.9706
16:44:30.796   Training iter 250, batch loss 0.0944, batch acc 0.9670
16:44:32.841   Training iter 300, batch loss 0.0939, batch acc 0.9654
16:44:34.889   Training iter 350, batch loss 0.0956, batch acc 0.9606
16:44:36.933   Training iter 400, batch loss 0.0965, batch acc 0.9630
16:44:38.979   Training iter 450, batch loss 0.0966, batch acc 0.9598
16:44:41.024   Training iter 500, batch loss 0.0951, batch acc 0.9628
16:44:43.075   Training iter 550, batch loss 0.0941, batch acc 0.9646
16:44:45.121   Training iter 600, batch loss 0.0968, batch acc 0.9600
16:44:45.122 Training @ 70 epoch...
16:44:47.173   Training iter 50, batch loss 0.0991, batch acc 0.9548
16:44:49.222   Training iter 100, batch loss 0.0964, batch acc 0.9590
16:44:51.272   Training iter 150, batch loss 0.0929, batch acc 0.9656
16:44:53.321   Training iter 200, batch loss 0.0955, batch acc 0.9656
16:44:55.366   Training iter 250, batch loss 0.0981, batch acc 0.9568
16:44:57.413   Training iter 300, batch loss 0.0941, batch acc 0.9632
16:44:59.461   Training iter 350, batch loss 0.0950, batch acc 0.9646
16:45:01.509   Training iter 400, batch loss 0.0944, batch acc 0.9644
16:45:03.557   Training iter 450, batch loss 0.0933, batch acc 0.9654
16:45:05.602   Training iter 500, batch loss 0.0965, batch acc 0.9658
16:45:07.651   Training iter 550, batch loss 0.0960, batch acc 0.9658
16:45:09.703   Training iter 600, batch loss 0.0958, batch acc 0.9644
16:45:09.704 Testing @ 70 epoch...
16:45:10.884     Testing, total mean loss 0.09194, total acc 0.96560
16:45:10.884 Training @ 71 epoch...
16:45:12.935   Training iter 50, batch loss 0.0949, batch acc 0.9636
16:45:14.985   Training iter 100, batch loss 0.0976, batch acc 0.9620
16:45:17.034   Training iter 150, batch loss 0.0947, batch acc 0.9600
16:45:19.085   Training iter 200, batch loss 0.0974, batch acc 0.9626
16:45:21.135   Training iter 250, batch loss 0.0964, batch acc 0.9622
16:45:23.186   Training iter 300, batch loss 0.0946, batch acc 0.9644
16:45:25.232   Training iter 350, batch loss 0.0957, batch acc 0.9602
16:45:27.280   Training iter 400, batch loss 0.0946, batch acc 0.9618
16:45:29.329   Training iter 450, batch loss 0.0939, batch acc 0.9652
16:45:31.379   Training iter 500, batch loss 0.0951, batch acc 0.9640
16:45:33.432   Training iter 550, batch loss 0.0951, batch acc 0.9652
16:45:35.482   Training iter 600, batch loss 0.0947, batch acc 0.9610
16:45:35.483 Training @ 72 epoch...
16:45:37.529   Training iter 50, batch loss 0.0959, batch acc 0.9610
16:45:39.581   Training iter 100, batch loss 0.0964, batch acc 0.9626
16:45:41.623   Training iter 150, batch loss 0.0972, batch acc 0.9612
16:45:43.671   Training iter 200, batch loss 0.0953, batch acc 0.9622
16:45:45.722   Training iter 250, batch loss 0.0953, batch acc 0.9646
16:45:47.766   Training iter 300, batch loss 0.0962, batch acc 0.9628
16:45:49.812   Training iter 350, batch loss 0.0951, batch acc 0.9644
16:45:51.857   Training iter 400, batch loss 0.0938, batch acc 0.9648
16:45:53.905   Training iter 450, batch loss 0.0949, batch acc 0.9646
16:45:55.952   Training iter 500, batch loss 0.0958, batch acc 0.9592
16:45:57.992   Training iter 550, batch loss 0.0941, batch acc 0.9610
16:46:00.034   Training iter 600, batch loss 0.0955, batch acc 0.9660
16:46:00.035 Training @ 73 epoch...
16:46:02.083   Training iter 50, batch loss 0.0941, batch acc 0.9658
16:46:04.126   Training iter 100, batch loss 0.0963, batch acc 0.9632
16:46:06.171   Training iter 150, batch loss 0.0943, batch acc 0.9652
16:46:08.214   Training iter 200, batch loss 0.0941, batch acc 0.9624
16:46:10.260   Training iter 250, batch loss 0.0926, batch acc 0.9660
16:46:12.305   Training iter 300, batch loss 0.0966, batch acc 0.9604
16:46:14.349   Training iter 350, batch loss 0.0935, batch acc 0.9674
16:46:16.392   Training iter 400, batch loss 0.0945, batch acc 0.9614
16:46:18.442   Training iter 450, batch loss 0.0969, batch acc 0.9628
16:46:20.489   Training iter 500, batch loss 0.0972, batch acc 0.9566
16:46:22.534   Training iter 550, batch loss 0.0969, batch acc 0.9646
16:46:24.581   Training iter 600, batch loss 0.0964, batch acc 0.9586
16:46:24.582 Training @ 74 epoch...
16:46:26.631   Training iter 50, batch loss 0.0953, batch acc 0.9650
16:46:28.675   Training iter 100, batch loss 0.0937, batch acc 0.9678
16:46:30.722   Training iter 150, batch loss 0.0937, batch acc 0.9642
16:46:32.767   Training iter 200, batch loss 0.0944, batch acc 0.9634
16:46:34.813   Training iter 250, batch loss 0.0946, batch acc 0.9644
16:46:36.858   Training iter 300, batch loss 0.0965, batch acc 0.9634
16:46:38.902   Training iter 350, batch loss 0.0968, batch acc 0.9570
16:46:40.945   Training iter 400, batch loss 0.0974, batch acc 0.9600
16:46:42.988   Training iter 450, batch loss 0.0949, batch acc 0.9602
16:46:45.032   Training iter 500, batch loss 0.0956, batch acc 0.9616
16:46:47.073   Training iter 550, batch loss 0.0965, batch acc 0.9612
16:46:49.117   Training iter 600, batch loss 0.0956, batch acc 0.9628
16:46:49.118 Training @ 75 epoch...
16:46:51.164   Training iter 50, batch loss 0.0933, batch acc 0.9640
16:46:53.208   Training iter 100, batch loss 0.0948, batch acc 0.9638
16:46:55.251   Training iter 150, batch loss 0.0946, batch acc 0.9640
16:46:57.296   Training iter 200, batch loss 0.0935, batch acc 0.9654
16:46:59.341   Training iter 250, batch loss 0.0970, batch acc 0.9568
16:47:01.385   Training iter 300, batch loss 0.0965, batch acc 0.9640
16:47:03.429   Training iter 350, batch loss 0.0928, batch acc 0.9668
16:47:05.471   Training iter 400, batch loss 0.0978, batch acc 0.9568
16:47:07.513   Training iter 450, batch loss 0.0962, batch acc 0.9604
16:47:09.556   Training iter 500, batch loss 0.0964, batch acc 0.9632
16:47:11.601   Training iter 550, batch loss 0.0934, batch acc 0.9670
16:47:13.644   Training iter 600, batch loss 0.0954, batch acc 0.9634
16:47:13.645 Testing @ 75 epoch...
16:47:14.831     Testing, total mean loss 0.09337, total acc 0.96650
16:47:14.831 Training @ 76 epoch...
16:47:16.882   Training iter 50, batch loss 0.0968, batch acc 0.9586
16:47:18.923   Training iter 100, batch loss 0.0925, batch acc 0.9686
16:47:20.969   Training iter 150, batch loss 0.0957, batch acc 0.9616
16:47:23.014   Training iter 200, batch loss 0.0952, batch acc 0.9602
16:47:25.064   Training iter 250, batch loss 0.0932, batch acc 0.9654
16:47:27.111   Training iter 300, batch loss 0.0955, batch acc 0.9620
16:47:29.161   Training iter 350, batch loss 0.0949, batch acc 0.9646
16:47:31.208   Training iter 400, batch loss 0.0953, batch acc 0.9634
16:47:33.254   Training iter 450, batch loss 0.0957, batch acc 0.9638
16:47:35.299   Training iter 500, batch loss 0.0965, batch acc 0.9630
16:47:37.346   Training iter 550, batch loss 0.0934, batch acc 0.9658
16:47:39.392   Training iter 600, batch loss 0.0965, batch acc 0.9616
16:47:39.393 Training @ 77 epoch...
16:47:41.440   Training iter 50, batch loss 0.0950, batch acc 0.9652
16:47:43.482   Training iter 100, batch loss 0.0951, batch acc 0.9624
16:47:45.531   Training iter 150, batch loss 0.0983, batch acc 0.9604
16:47:47.582   Training iter 200, batch loss 0.0942, batch acc 0.9644
16:47:49.625   Training iter 250, batch loss 0.0931, batch acc 0.9626
16:47:51.670   Training iter 300, batch loss 0.0942, batch acc 0.9660
16:47:53.719   Training iter 350, batch loss 0.0937, batch acc 0.9644
16:47:55.767   Training iter 400, batch loss 0.0975, batch acc 0.9628
16:47:57.812   Training iter 450, batch loss 0.0948, batch acc 0.9644
16:47:59.855   Training iter 500, batch loss 0.0972, batch acc 0.9556
16:48:01.907   Training iter 550, batch loss 0.0941, batch acc 0.9652
16:48:03.954   Training iter 600, batch loss 0.0944, batch acc 0.9646
16:48:03.955 Training @ 78 epoch...
16:48:06.004   Training iter 50, batch loss 0.0953, batch acc 0.9618
16:48:08.049   Training iter 100, batch loss 0.0955, batch acc 0.9622
16:48:10.102   Training iter 150, batch loss 0.0946, batch acc 0.9632
16:48:12.144   Training iter 200, batch loss 0.0963, batch acc 0.9596
16:48:14.188   Training iter 250, batch loss 0.0931, batch acc 0.9648
16:48:16.231   Training iter 300, batch loss 0.0976, batch acc 0.9598
16:48:18.269   Training iter 350, batch loss 0.0941, batch acc 0.9654
16:48:20.308   Training iter 400, batch loss 0.0959, batch acc 0.9616
16:48:22.347   Training iter 450, batch loss 0.0944, batch acc 0.9706
16:48:24.387   Training iter 500, batch loss 0.0924, batch acc 0.9640
16:48:26.426   Training iter 550, batch loss 0.0953, batch acc 0.9608
16:48:28.465   Training iter 600, batch loss 0.0952, batch acc 0.9626
16:48:28.466 Training @ 79 epoch...
16:48:30.515   Training iter 50, batch loss 0.0928, batch acc 0.9686
16:48:32.560   Training iter 100, batch loss 0.0951, batch acc 0.9636
16:48:34.604   Training iter 150, batch loss 0.0984, batch acc 0.9578
16:48:36.646   Training iter 200, batch loss 0.0947, batch acc 0.9634
16:48:38.692   Training iter 250, batch loss 0.0944, batch acc 0.9628
16:48:40.735   Training iter 300, batch loss 0.0936, batch acc 0.9656
16:48:42.774   Training iter 350, batch loss 0.0975, batch acc 0.9592
16:48:44.813   Training iter 400, batch loss 0.0947, batch acc 0.9674
16:48:46.853   Training iter 450, batch loss 0.0951, batch acc 0.9616
16:48:48.894   Training iter 500, batch loss 0.0923, batch acc 0.9640
16:48:50.933   Training iter 550, batch loss 0.0943, batch acc 0.9648
16:48:52.973   Training iter 600, batch loss 0.0963, batch acc 0.9626
16:48:52.974 Training @ 80 epoch...
16:48:55.020   Training iter 50, batch loss 0.0943, batch acc 0.9648
16:48:57.065   Training iter 100, batch loss 0.0979, batch acc 0.9572
16:48:59.109   Training iter 150, batch loss 0.0934, batch acc 0.9676
16:49:01.149   Training iter 200, batch loss 0.0928, batch acc 0.9674
16:49:03.192   Training iter 250, batch loss 0.0965, batch acc 0.9624
16:49:05.235   Training iter 300, batch loss 0.0953, batch acc 0.9642
16:49:07.283   Training iter 350, batch loss 0.0930, batch acc 0.9646
16:49:09.325   Training iter 400, batch loss 0.0939, batch acc 0.9650
16:49:11.366   Training iter 450, batch loss 0.0950, batch acc 0.9646
16:49:13.404   Training iter 500, batch loss 0.0954, batch acc 0.9602
16:49:15.446   Training iter 550, batch loss 0.0958, batch acc 0.9618
16:49:17.489   Training iter 600, batch loss 0.0965, batch acc 0.9608
16:49:17.490 Testing @ 80 epoch...
16:49:18.675     Testing, total mean loss 0.09226, total acc 0.96650
16:49:18.675 Training @ 81 epoch...
16:49:20.727   Training iter 50, batch loss 0.0941, batch acc 0.9628
16:49:22.777   Training iter 100, batch loss 0.0961, batch acc 0.9664
16:49:24.828   Training iter 150, batch loss 0.0927, batch acc 0.9670
16:49:26.880   Training iter 200, batch loss 0.0944, batch acc 0.9646
16:49:28.936   Training iter 250, batch loss 0.0957, batch acc 0.9612
16:49:30.992   Training iter 300, batch loss 0.0946, batch acc 0.9644
16:49:33.049   Training iter 350, batch loss 0.0938, batch acc 0.9634
16:49:35.105   Training iter 400, batch loss 0.0957, batch acc 0.9628
16:49:37.162   Training iter 450, batch loss 0.0934, batch acc 0.9620
16:49:39.219   Training iter 500, batch loss 0.0968, batch acc 0.9620
16:49:41.275   Training iter 550, batch loss 0.0945, batch acc 0.9614
16:49:43.331   Training iter 600, batch loss 0.0955, batch acc 0.9606
16:49:43.332 Training @ 82 epoch...
16:49:45.384   Training iter 50, batch loss 0.0952, batch acc 0.9618
16:49:47.430   Training iter 100, batch loss 0.0955, batch acc 0.9638
16:49:49.477   Training iter 150, batch loss 0.0938, batch acc 0.9678
16:49:51.519   Training iter 200, batch loss 0.0935, batch acc 0.9642
16:49:53.560   Training iter 250, batch loss 0.0920, batch acc 0.9668
16:49:55.602   Training iter 300, batch loss 0.0969, batch acc 0.9602
16:49:57.649   Training iter 350, batch loss 0.0955, batch acc 0.9644
16:49:59.695   Training iter 400, batch loss 0.0964, batch acc 0.9588
16:50:01.746   Training iter 450, batch loss 0.0942, batch acc 0.9668
16:50:03.792   Training iter 500, batch loss 0.0940, batch acc 0.9644
16:50:05.838   Training iter 550, batch loss 0.0943, batch acc 0.9640
16:50:07.883   Training iter 600, batch loss 0.0955, batch acc 0.9580
16:50:07.884 Training @ 83 epoch...
16:50:09.929   Training iter 50, batch loss 0.0948, batch acc 0.9636
16:50:12.009   Training iter 100, batch loss 0.0943, batch acc 0.9612
16:50:14.050   Training iter 150, batch loss 0.0981, batch acc 0.9592
16:50:16.092   Training iter 200, batch loss 0.0921, batch acc 0.9684
16:50:18.139   Training iter 250, batch loss 0.0946, batch acc 0.9608
16:50:20.184   Training iter 300, batch loss 0.0964, batch acc 0.9632
16:50:22.223   Training iter 350, batch loss 0.0924, batch acc 0.9654
16:50:24.268   Training iter 400, batch loss 0.0947, batch acc 0.9654
16:50:26.313   Training iter 450, batch loss 0.0953, batch acc 0.9634
16:50:28.356   Training iter 500, batch loss 0.0926, batch acc 0.9674
16:50:30.397   Training iter 550, batch loss 0.0968, batch acc 0.9612
16:50:32.439   Training iter 600, batch loss 0.0949, batch acc 0.9626
16:50:32.440 Training @ 84 epoch...
16:50:34.492   Training iter 50, batch loss 0.0938, batch acc 0.9646
16:50:36.536   Training iter 100, batch loss 0.0953, batch acc 0.9622
16:50:38.586   Training iter 150, batch loss 0.0953, batch acc 0.9608
16:50:40.629   Training iter 200, batch loss 0.0946, batch acc 0.9660
16:50:42.672   Training iter 250, batch loss 0.0939, batch acc 0.9630
16:50:44.716   Training iter 300, batch loss 0.0972, batch acc 0.9624
16:50:46.762   Training iter 350, batch loss 0.0960, batch acc 0.9618
16:50:48.807   Training iter 400, batch loss 0.0939, batch acc 0.9632
16:50:50.847   Training iter 450, batch loss 0.0944, batch acc 0.9636
16:50:52.891   Training iter 500, batch loss 0.0955, batch acc 0.9668
16:50:54.937   Training iter 550, batch loss 0.0946, batch acc 0.9638
16:50:56.983   Training iter 600, batch loss 0.0921, batch acc 0.9654
16:50:56.984 Training @ 85 epoch...
16:50:59.031   Training iter 50, batch loss 0.0972, batch acc 0.9634
16:51:01.076   Training iter 100, batch loss 0.0945, batch acc 0.9640
16:51:03.123   Training iter 150, batch loss 0.0933, batch acc 0.9622
16:51:05.165   Training iter 200, batch loss 0.0943, batch acc 0.9636
16:51:07.210   Training iter 250, batch loss 0.0964, batch acc 0.9638
16:51:09.252   Training iter 300, batch loss 0.0931, batch acc 0.9634
16:51:11.294   Training iter 350, batch loss 0.0942, batch acc 0.9636
16:51:13.341   Training iter 400, batch loss 0.0942, batch acc 0.9650
16:51:15.394   Training iter 450, batch loss 0.0954, batch acc 0.9656
16:51:17.469   Training iter 500, batch loss 0.0951, batch acc 0.9626
16:51:19.514   Training iter 550, batch loss 0.0938, batch acc 0.9648
16:51:21.563   Training iter 600, batch loss 0.0946, batch acc 0.9648
16:51:21.564 Testing @ 85 epoch...
16:51:22.747     Testing, total mean loss 0.09099, total acc 0.96720
16:51:22.747 Training @ 86 epoch...
16:51:24.797   Training iter 50, batch loss 0.0945, batch acc 0.9620
16:51:26.837   Training iter 100, batch loss 0.0929, batch acc 0.9694
16:51:28.882   Training iter 150, batch loss 0.0941, batch acc 0.9628
16:51:30.922   Training iter 200, batch loss 0.0952, batch acc 0.9624
16:51:32.964   Training iter 250, batch loss 0.0954, batch acc 0.9632
16:51:35.003   Training iter 300, batch loss 0.0938, batch acc 0.9656
16:51:37.045   Training iter 350, batch loss 0.0920, batch acc 0.9630
16:51:39.085   Training iter 400, batch loss 0.0958, batch acc 0.9642
16:51:41.130   Training iter 450, batch loss 0.0949, batch acc 0.9622
16:51:43.176   Training iter 500, batch loss 0.0979, batch acc 0.9588
16:51:45.219   Training iter 550, batch loss 0.0951, batch acc 0.9614
16:51:47.260   Training iter 600, batch loss 0.0928, batch acc 0.9660
16:51:47.261 Training @ 87 epoch...
16:51:49.313   Training iter 50, batch loss 0.0934, batch acc 0.9632
16:51:51.360   Training iter 100, batch loss 0.0955, batch acc 0.9666
16:51:53.412   Training iter 150, batch loss 0.0934, batch acc 0.9664
16:51:55.463   Training iter 200, batch loss 0.0945, batch acc 0.9608
16:51:57.511   Training iter 250, batch loss 0.0957, batch acc 0.9632
16:51:59.562   Training iter 300, batch loss 0.0943, batch acc 0.9638
16:52:01.612   Training iter 350, batch loss 0.0970, batch acc 0.9600
16:52:03.660   Training iter 400, batch loss 0.0928, batch acc 0.9666
16:52:05.710   Training iter 450, batch loss 0.0938, batch acc 0.9628
16:52:07.756   Training iter 500, batch loss 0.0948, batch acc 0.9636
16:52:09.805   Training iter 550, batch loss 0.0964, batch acc 0.9618
16:52:11.853   Training iter 600, batch loss 0.0933, batch acc 0.9656
16:52:11.853 Training @ 88 epoch...
16:52:13.899   Training iter 50, batch loss 0.0958, batch acc 0.9650
16:52:15.941   Training iter 100, batch loss 0.0920, batch acc 0.9692
16:52:17.984   Training iter 150, batch loss 0.0934, batch acc 0.9650
16:52:20.026   Training iter 200, batch loss 0.0934, batch acc 0.9662
16:52:22.071   Training iter 250, batch loss 0.0966, batch acc 0.9624
16:52:24.114   Training iter 300, batch loss 0.0967, batch acc 0.9640
16:52:26.157   Training iter 350, batch loss 0.0936, batch acc 0.9642
16:52:28.203   Training iter 400, batch loss 0.0951, batch acc 0.9602
16:52:30.247   Training iter 450, batch loss 0.0936, batch acc 0.9632
16:52:32.290   Training iter 500, batch loss 0.0920, batch acc 0.9646
16:52:34.342   Training iter 550, batch loss 0.0956, batch acc 0.9626
16:52:36.562   Training iter 600, batch loss 0.0965, batch acc 0.9596
16:52:36.563 Training @ 89 epoch...
16:52:38.610   Training iter 50, batch loss 0.0951, batch acc 0.9644
16:52:40.662   Training iter 100, batch loss 0.0952, batch acc 0.9618
16:52:42.715   Training iter 150, batch loss 0.0964, batch acc 0.9586
16:52:44.766   Training iter 200, batch loss 0.0956, batch acc 0.9602
16:52:46.816   Training iter 250, batch loss 0.0931, batch acc 0.9684
16:52:48.866   Training iter 300, batch loss 0.0952, batch acc 0.9622
16:52:50.916   Training iter 350, batch loss 0.0934, batch acc 0.9654
16:52:52.966   Training iter 400, batch loss 0.0945, batch acc 0.9628
16:52:55.016   Training iter 450, batch loss 0.0932, batch acc 0.9672
16:52:57.066   Training iter 500, batch loss 0.0929, batch acc 0.9658
16:52:59.116   Training iter 550, batch loss 0.0959, batch acc 0.9638
16:53:01.166   Training iter 600, batch loss 0.0930, batch acc 0.9652
16:53:01.167 Training @ 90 epoch...
16:53:03.213   Training iter 50, batch loss 0.0956, batch acc 0.9658
16:53:05.259   Training iter 100, batch loss 0.0944, batch acc 0.9630
16:53:07.300   Training iter 150, batch loss 0.0968, batch acc 0.9624
16:53:09.342   Training iter 200, batch loss 0.0959, batch acc 0.9620
16:53:11.384   Training iter 250, batch loss 0.0942, batch acc 0.9668
16:53:13.427   Training iter 300, batch loss 0.0944, batch acc 0.9634
16:53:15.472   Training iter 350, batch loss 0.0942, batch acc 0.9640
16:53:17.513   Training iter 400, batch loss 0.0951, batch acc 0.9618
16:53:19.555   Training iter 450, batch loss 0.0938, batch acc 0.9632
16:53:21.597   Training iter 500, batch loss 0.0940, batch acc 0.9628
16:53:23.640   Training iter 550, batch loss 0.0943, batch acc 0.9614
16:53:25.687   Training iter 600, batch loss 0.0904, batch acc 0.9710
16:53:25.688 Testing @ 90 epoch...
16:53:26.874     Testing, total mean loss 0.09204, total acc 0.96770
16:53:26.874 Training @ 91 epoch...
16:53:28.920   Training iter 50, batch loss 0.0954, batch acc 0.9622
16:53:30.960   Training iter 100, batch loss 0.0926, batch acc 0.9662
16:53:33.010   Training iter 150, batch loss 0.0950, batch acc 0.9656
16:53:35.060   Training iter 200, batch loss 0.0929, batch acc 0.9660
16:53:37.109   Training iter 250, batch loss 0.0932, batch acc 0.9644
16:53:39.158   Training iter 300, batch loss 0.0938, batch acc 0.9618
16:53:41.208   Training iter 350, batch loss 0.0971, batch acc 0.9608
16:53:43.258   Training iter 400, batch loss 0.0948, batch acc 0.9612
16:53:45.308   Training iter 450, batch loss 0.0946, batch acc 0.9662
16:53:47.357   Training iter 500, batch loss 0.0935, batch acc 0.9636
16:53:49.407   Training iter 550, batch loss 0.0946, batch acc 0.9662
16:53:51.456   Training iter 600, batch loss 0.0952, batch acc 0.9644
16:53:51.457 Training @ 92 epoch...
16:53:53.505   Training iter 50, batch loss 0.0934, batch acc 0.9644
16:53:55.548   Training iter 100, batch loss 0.0942, batch acc 0.9682
16:53:57.584   Training iter 150, batch loss 0.0933, batch acc 0.9652
16:53:59.621   Training iter 200, batch loss 0.0925, batch acc 0.9652
16:54:01.659   Training iter 250, batch loss 0.0947, batch acc 0.9616
16:54:03.699   Training iter 300, batch loss 0.0956, batch acc 0.9612
16:54:05.736   Training iter 350, batch loss 0.0957, batch acc 0.9610
16:54:07.775   Training iter 400, batch loss 0.0948, batch acc 0.9626
16:54:09.814   Training iter 450, batch loss 0.0952, batch acc 0.9614
16:54:11.853   Training iter 500, batch loss 0.0933, batch acc 0.9634
16:54:13.891   Training iter 550, batch loss 0.0933, batch acc 0.9642
16:54:15.931   Training iter 600, batch loss 0.0940, batch acc 0.9668
16:54:15.932 Training @ 93 epoch...
16:54:17.983   Training iter 50, batch loss 0.0933, batch acc 0.9640
16:54:20.025   Training iter 100, batch loss 0.0948, batch acc 0.9684
16:54:22.069   Training iter 150, batch loss 0.0930, batch acc 0.9662
16:54:24.111   Training iter 200, batch loss 0.0963, batch acc 0.9612
16:54:26.150   Training iter 250, batch loss 0.0933, batch acc 0.9660
16:54:28.198   Training iter 300, batch loss 0.0945, batch acc 0.9644
16:54:30.246   Training iter 350, batch loss 0.0927, batch acc 0.9660
16:54:32.287   Training iter 400, batch loss 0.0939, batch acc 0.9640
16:54:34.330   Training iter 450, batch loss 0.0936, batch acc 0.9644
16:54:36.370   Training iter 500, batch loss 0.0954, batch acc 0.9620
16:54:38.411   Training iter 550, batch loss 0.0936, batch acc 0.9636
16:54:40.453   Training iter 600, batch loss 0.0958, batch acc 0.9600
16:54:40.454 Training @ 94 epoch...
16:54:42.500   Training iter 50, batch loss 0.0935, batch acc 0.9672
16:54:44.540   Training iter 100, batch loss 0.0919, batch acc 0.9626
16:54:46.585   Training iter 150, batch loss 0.0935, batch acc 0.9664
16:54:48.629   Training iter 200, batch loss 0.0946, batch acc 0.9656
16:54:50.671   Training iter 250, batch loss 0.0952, batch acc 0.9654
16:54:52.719   Training iter 300, batch loss 0.0955, batch acc 0.9612
16:54:54.761   Training iter 350, batch loss 0.0936, batch acc 0.9650
16:54:56.808   Training iter 400, batch loss 0.0998, batch acc 0.9528
16:54:58.855   Training iter 450, batch loss 0.0921, batch acc 0.9678
16:55:00.897   Training iter 500, batch loss 0.0928, batch acc 0.9690
16:55:02.939   Training iter 550, batch loss 0.0948, batch acc 0.9634
16:55:04.981   Training iter 600, batch loss 0.0930, batch acc 0.9666
16:55:04.982 Training @ 95 epoch...
16:55:07.027   Training iter 50, batch loss 0.0927, batch acc 0.9658
16:55:09.068   Training iter 100, batch loss 0.0961, batch acc 0.9634
16:55:11.110   Training iter 150, batch loss 0.0936, batch acc 0.9686
16:55:13.150   Training iter 200, batch loss 0.0952, batch acc 0.9646
16:55:15.191   Training iter 250, batch loss 0.0948, batch acc 0.9608
16:55:17.235   Training iter 300, batch loss 0.0958, batch acc 0.9610
16:55:19.277   Training iter 350, batch loss 0.0925, batch acc 0.9664
16:55:21.317   Training iter 400, batch loss 0.0945, batch acc 0.9632
16:55:23.357   Training iter 450, batch loss 0.0934, batch acc 0.9616
16:55:25.396   Training iter 500, batch loss 0.0924, batch acc 0.9674
16:55:27.435   Training iter 550, batch loss 0.0929, batch acc 0.9632
16:55:29.471   Training iter 600, batch loss 0.0949, batch acc 0.9626
16:55:29.472 Testing @ 95 epoch...
16:55:30.655     Testing, total mean loss 0.09120, total acc 0.96760
16:55:30.655 Training @ 96 epoch...
16:55:32.705   Training iter 50, batch loss 0.0960, batch acc 0.9588
16:55:34.743   Training iter 100, batch loss 0.0957, batch acc 0.9624
16:55:36.780   Training iter 150, batch loss 0.0955, batch acc 0.9580
16:55:38.819   Training iter 200, batch loss 0.0950, batch acc 0.9610
16:55:40.857   Training iter 250, batch loss 0.0920, batch acc 0.9662
16:55:42.895   Training iter 300, batch loss 0.0959, batch acc 0.9606
16:55:44.933   Training iter 350, batch loss 0.0926, batch acc 0.9662
16:55:46.973   Training iter 400, batch loss 0.0924, batch acc 0.9672
16:55:49.012   Training iter 450, batch loss 0.0966, batch acc 0.9608
16:55:51.051   Training iter 500, batch loss 0.0928, batch acc 0.9624
16:55:53.092   Training iter 550, batch loss 0.0936, batch acc 0.9664
16:55:55.138   Training iter 600, batch loss 0.0917, batch acc 0.9676
16:55:55.139 Training @ 97 epoch...
16:55:57.182   Training iter 50, batch loss 0.0947, batch acc 0.9638
16:55:59.224   Training iter 100, batch loss 0.0947, batch acc 0.9642
16:56:01.267   Training iter 150, batch loss 0.0941, batch acc 0.9624
16:56:03.309   Training iter 200, batch loss 0.0930, batch acc 0.9638
16:56:05.351   Training iter 250, batch loss 0.0938, batch acc 0.9654
16:56:07.390   Training iter 300, batch loss 0.0940, batch acc 0.9632
16:56:09.429   Training iter 350, batch loss 0.0955, batch acc 0.9636
16:56:11.469   Training iter 400, batch loss 0.0948, batch acc 0.9634
16:56:13.511   Training iter 450, batch loss 0.0949, batch acc 0.9632
16:56:15.556   Training iter 500, batch loss 0.0953, batch acc 0.9634
16:56:17.596   Training iter 550, batch loss 0.0914, batch acc 0.9674
16:56:19.637   Training iter 600, batch loss 0.0932, batch acc 0.9616
16:56:19.638 Training @ 98 epoch...
16:56:21.680   Training iter 50, batch loss 0.0950, batch acc 0.9640
16:56:23.719   Training iter 100, batch loss 0.0961, batch acc 0.9616
16:56:25.764   Training iter 150, batch loss 0.0946, batch acc 0.9668
16:56:27.806   Training iter 200, batch loss 0.0922, batch acc 0.9614
16:56:29.847   Training iter 250, batch loss 0.0960, batch acc 0.9614
16:56:31.889   Training iter 300, batch loss 0.0933, batch acc 0.9656
16:56:33.930   Training iter 350, batch loss 0.0947, batch acc 0.9644
16:56:35.973   Training iter 400, batch loss 0.0937, batch acc 0.9614
16:56:38.014   Training iter 450, batch loss 0.0962, batch acc 0.9592
16:56:40.056   Training iter 500, batch loss 0.0908, batch acc 0.9664
16:56:42.099   Training iter 550, batch loss 0.0927, batch acc 0.9668
16:56:44.140   Training iter 600, batch loss 0.0940, batch acc 0.9658
16:56:44.141 Training @ 99 epoch...
16:56:46.180   Training iter 50, batch loss 0.0950, batch acc 0.9638
16:56:48.227   Training iter 100, batch loss 0.0949, batch acc 0.9606
16:56:50.269   Training iter 150, batch loss 0.0944, batch acc 0.9612
16:56:52.312   Training iter 200, batch loss 0.0940, batch acc 0.9658
16:56:54.351   Training iter 250, batch loss 0.0925, batch acc 0.9650
16:56:56.394   Training iter 300, batch loss 0.0955, batch acc 0.9630
16:56:58.435   Training iter 350, batch loss 0.0927, batch acc 0.9656
16:57:00.473   Training iter 400, batch loss 0.0956, batch acc 0.9634
16:57:02.515   Training iter 450, batch loss 0.0930, batch acc 0.9634
16:57:04.555   Training iter 500, batch loss 0.0925, batch acc 0.9664
16:57:06.595   Training iter 550, batch loss 0.0935, batch acc 0.9664
16:57:08.637   Training iter 600, batch loss 0.0938, batch acc 0.9658
