11:02:33.108 Training @ 0 epoch...
11:02:35.231   Training iter 50, batch loss 1.3838, batch acc 0.5778
11:02:37.469   Training iter 100, batch loss 0.5985, batch acc 0.8182
11:02:39.619   Training iter 150, batch loss 0.4043, batch acc 0.8776
11:02:41.732   Training iter 200, batch loss 0.3361, batch acc 0.8954
11:02:43.832   Training iter 250, batch loss 0.2873, batch acc 0.9128
11:02:45.932   Training iter 300, batch loss 0.2738, batch acc 0.9202
11:02:48.027   Training iter 350, batch loss 0.2470, batch acc 0.9270
11:02:50.119   Training iter 400, batch loss 0.2353, batch acc 0.9370
11:02:52.205   Training iter 450, batch loss 0.2120, batch acc 0.9374
11:02:54.292   Training iter 500, batch loss 0.2060, batch acc 0.9392
11:02:56.388   Training iter 550, batch loss 0.1976, batch acc 0.9424
11:02:58.474   Training iter 600, batch loss 0.1941, batch acc 0.9408
11:02:58.476 Testing @ 0 epoch...
11:02:59.687     Testing, total mean loss 0.16108, total acc 0.95440
11:02:59.687 Training @ 1 epoch...
11:03:01.776   Training iter 50, batch loss 0.1735, batch acc 0.9470
11:03:03.862   Training iter 100, batch loss 0.1588, batch acc 0.9560
11:03:05.950   Training iter 150, batch loss 0.1526, batch acc 0.9528
11:03:08.044   Training iter 200, batch loss 0.1467, batch acc 0.9592
11:03:10.134   Training iter 250, batch loss 0.1427, batch acc 0.9558
11:03:12.223   Training iter 300, batch loss 0.1413, batch acc 0.9586
11:03:14.312   Training iter 350, batch loss 0.1268, batch acc 0.9624
11:03:16.399   Training iter 400, batch loss 0.1374, batch acc 0.9630
11:03:18.482   Training iter 450, batch loss 0.1408, batch acc 0.9578
11:03:20.565   Training iter 500, batch loss 0.1411, batch acc 0.9550
11:03:22.651   Training iter 550, batch loss 0.1512, batch acc 0.9546
11:03:24.740   Training iter 600, batch loss 0.1322, batch acc 0.9586
11:03:24.742 Training @ 2 epoch...
11:03:26.831   Training iter 50, batch loss 0.1342, batch acc 0.9604
11:03:28.917   Training iter 100, batch loss 0.1080, batch acc 0.9648
11:03:31.002   Training iter 150, batch loss 0.1272, batch acc 0.9578
11:03:33.086   Training iter 200, batch loss 0.1066, batch acc 0.9680
11:03:35.171   Training iter 250, batch loss 0.1086, batch acc 0.9694
11:03:37.253   Training iter 300, batch loss 0.1068, batch acc 0.9678
11:03:39.339   Training iter 350, batch loss 0.1078, batch acc 0.9686
11:03:41.426   Training iter 400, batch loss 0.1120, batch acc 0.9676
11:03:43.510   Training iter 450, batch loss 0.1215, batch acc 0.9650
11:03:45.595   Training iter 500, batch loss 0.1077, batch acc 0.9666
11:03:47.686   Training iter 550, batch loss 0.1026, batch acc 0.9680
11:03:49.772   Training iter 600, batch loss 0.1164, batch acc 0.9674
11:03:49.773 Training @ 3 epoch...
11:03:51.860   Training iter 50, batch loss 0.0997, batch acc 0.9708
11:03:53.941   Training iter 100, batch loss 0.1119, batch acc 0.9660
11:03:56.023   Training iter 150, batch loss 0.0908, batch acc 0.9728
11:03:58.110   Training iter 200, batch loss 0.0992, batch acc 0.9696
11:04:00.195   Training iter 250, batch loss 0.0967, batch acc 0.9702
11:04:02.276   Training iter 300, batch loss 0.1026, batch acc 0.9680
11:04:04.361   Training iter 350, batch loss 0.1040, batch acc 0.9696
11:04:06.443   Training iter 400, batch loss 0.1061, batch acc 0.9684
11:04:08.529   Training iter 450, batch loss 0.0860, batch acc 0.9760
11:04:10.612   Training iter 500, batch loss 0.0987, batch acc 0.9696
11:04:12.702   Training iter 550, batch loss 0.0910, batch acc 0.9700
11:04:14.782   Training iter 600, batch loss 0.0883, batch acc 0.9732
11:04:14.783 Training @ 4 epoch...
11:04:16.873   Training iter 50, batch loss 0.0985, batch acc 0.9706
11:04:18.959   Training iter 100, batch loss 0.0905, batch acc 0.9734
11:04:21.043   Training iter 150, batch loss 0.0865, batch acc 0.9730
11:04:23.127   Training iter 200, batch loss 0.0849, batch acc 0.9746
11:04:25.211   Training iter 250, batch loss 0.0908, batch acc 0.9748
11:04:27.303   Training iter 300, batch loss 0.0930, batch acc 0.9732
11:04:29.390   Training iter 350, batch loss 0.0860, batch acc 0.9712
11:04:31.472   Training iter 400, batch loss 0.0925, batch acc 0.9704
11:04:33.557   Training iter 450, batch loss 0.0885, batch acc 0.9730
11:04:35.648   Training iter 500, batch loss 0.0933, batch acc 0.9698
11:04:37.742   Training iter 550, batch loss 0.0826, batch acc 0.9742
11:04:39.827   Training iter 600, batch loss 0.0890, batch acc 0.9746
11:04:39.829 Training @ 5 epoch...
11:04:41.914   Training iter 50, batch loss 0.0833, batch acc 0.9740
11:04:43.989   Training iter 100, batch loss 0.0959, batch acc 0.9724
11:04:46.070   Training iter 150, batch loss 0.0845, batch acc 0.9764
11:04:48.140   Training iter 200, batch loss 0.0740, batch acc 0.9752
11:04:50.205   Training iter 250, batch loss 0.0828, batch acc 0.9726
11:04:52.267   Training iter 300, batch loss 0.1020, batch acc 0.9708
11:04:54.327   Training iter 350, batch loss 0.0724, batch acc 0.9778
11:04:56.389   Training iter 400, batch loss 0.0670, batch acc 0.9784
11:04:58.450   Training iter 450, batch loss 0.0687, batch acc 0.9778
11:05:00.507   Training iter 500, batch loss 0.0781, batch acc 0.9754
11:05:02.564   Training iter 550, batch loss 0.1006, batch acc 0.9702
11:05:04.623   Training iter 600, batch loss 0.0903, batch acc 0.9726
11:05:04.624 Testing @ 5 epoch...
11:05:05.884     Testing, total mean loss 0.06834, total acc 0.97940
11:05:05.884 Training @ 6 epoch...
11:05:07.977   Training iter 50, batch loss 0.0779, batch acc 0.9778
11:05:10.050   Training iter 100, batch loss 0.0874, batch acc 0.9732
11:05:12.127   Training iter 150, batch loss 0.0660, batch acc 0.9800
11:05:14.202   Training iter 200, batch loss 0.0770, batch acc 0.9748
11:05:16.274   Training iter 250, batch loss 0.0894, batch acc 0.9738
11:05:18.358   Training iter 300, batch loss 0.0681, batch acc 0.9794
11:05:20.432   Training iter 350, batch loss 0.0834, batch acc 0.9728
11:05:22.505   Training iter 400, batch loss 0.0790, batch acc 0.9768
11:05:24.582   Training iter 450, batch loss 0.0868, batch acc 0.9742
11:05:26.656   Training iter 500, batch loss 0.0702, batch acc 0.9798
11:05:28.731   Training iter 550, batch loss 0.0799, batch acc 0.9758
11:05:30.810   Training iter 600, batch loss 0.0818, batch acc 0.9756
11:05:30.811 Training @ 7 epoch...
11:05:32.894   Training iter 50, batch loss 0.0747, batch acc 0.9774
11:05:34.972   Training iter 100, batch loss 0.0661, batch acc 0.9786
11:05:37.046   Training iter 150, batch loss 0.0687, batch acc 0.9770
11:05:39.122   Training iter 200, batch loss 0.0701, batch acc 0.9774
11:05:41.194   Training iter 250, batch loss 0.0739, batch acc 0.9790
11:05:43.266   Training iter 300, batch loss 0.0779, batch acc 0.9772
11:05:45.341   Training iter 350, batch loss 0.0822, batch acc 0.9762
11:05:47.414   Training iter 400, batch loss 0.0883, batch acc 0.9732
11:05:49.487   Training iter 450, batch loss 0.0787, batch acc 0.9770
11:05:51.562   Training iter 500, batch loss 0.0680, batch acc 0.9802
11:05:53.636   Training iter 550, batch loss 0.0820, batch acc 0.9746
11:05:55.708   Training iter 600, batch loss 0.0737, batch acc 0.9778
11:05:55.709 Training @ 8 epoch...
11:05:57.782   Training iter 50, batch loss 0.0641, batch acc 0.9816
11:05:59.853   Training iter 100, batch loss 0.0694, batch acc 0.9780
11:06:01.928   Training iter 150, batch loss 0.0712, batch acc 0.9798
11:06:04.000   Training iter 200, batch loss 0.0801, batch acc 0.9764
11:06:06.074   Training iter 250, batch loss 0.0697, batch acc 0.9782
11:06:08.148   Training iter 300, batch loss 0.0734, batch acc 0.9774
11:06:10.218   Training iter 350, batch loss 0.0865, batch acc 0.9754
11:06:12.371   Training iter 400, batch loss 0.0852, batch acc 0.9756
11:06:14.441   Training iter 450, batch loss 0.0691, batch acc 0.9798
11:06:16.513   Training iter 500, batch loss 0.0666, batch acc 0.9788
11:06:18.589   Training iter 550, batch loss 0.0660, batch acc 0.9794
11:06:20.666   Training iter 600, batch loss 0.0615, batch acc 0.9804
11:06:20.667 Training @ 9 epoch...
11:06:22.749   Training iter 50, batch loss 0.0622, batch acc 0.9826
11:06:24.830   Training iter 100, batch loss 0.0795, batch acc 0.9770
11:06:26.908   Training iter 150, batch loss 0.0710, batch acc 0.9798
11:06:28.987   Training iter 200, batch loss 0.0737, batch acc 0.9774
11:06:31.080   Training iter 250, batch loss 0.0565, batch acc 0.9838
11:06:33.160   Training iter 300, batch loss 0.0609, batch acc 0.9812
11:06:35.244   Training iter 350, batch loss 0.0632, batch acc 0.9804
11:06:37.324   Training iter 400, batch loss 0.0761, batch acc 0.9746
11:06:39.407   Training iter 450, batch loss 0.0724, batch acc 0.9788
11:06:41.484   Training iter 500, batch loss 0.0678, batch acc 0.9788
11:06:43.556   Training iter 550, batch loss 0.0684, batch acc 0.9768
11:06:45.632   Training iter 600, batch loss 0.0759, batch acc 0.9762
11:06:45.634 Training @ 10 epoch...
11:06:47.717   Training iter 50, batch loss 0.0708, batch acc 0.9782
11:06:49.801   Training iter 100, batch loss 0.0711, batch acc 0.9798
11:06:51.877   Training iter 150, batch loss 0.0666, batch acc 0.9802
11:06:53.960   Training iter 200, batch loss 0.0603, batch acc 0.9814
11:06:56.049   Training iter 250, batch loss 0.0705, batch acc 0.9778
11:06:58.128   Training iter 300, batch loss 0.0750, batch acc 0.9798
11:07:00.210   Training iter 350, batch loss 0.0649, batch acc 0.9796
11:07:02.296   Training iter 400, batch loss 0.0657, batch acc 0.9788
11:07:04.381   Training iter 450, batch loss 0.0700, batch acc 0.9788
11:07:06.457   Training iter 500, batch loss 0.0618, batch acc 0.9772
11:07:08.534   Training iter 550, batch loss 0.0705, batch acc 0.9776
11:07:10.613   Training iter 600, batch loss 0.0608, batch acc 0.9810
11:07:10.614 Testing @ 10 epoch...
11:07:11.874     Testing, total mean loss 0.06514, total acc 0.97950
11:07:11.874 Training @ 11 epoch...
11:07:13.958   Training iter 50, batch loss 0.0616, batch acc 0.9816
11:07:16.028   Training iter 100, batch loss 0.0620, batch acc 0.9792
11:07:18.097   Training iter 150, batch loss 0.0759, batch acc 0.9768
11:07:20.171   Training iter 200, batch loss 0.0633, batch acc 0.9804
11:07:22.240   Training iter 250, batch loss 0.0756, batch acc 0.9768
11:07:24.317   Training iter 300, batch loss 0.0656, batch acc 0.9800
11:07:26.396   Training iter 350, batch loss 0.0670, batch acc 0.9810
11:07:28.473   Training iter 400, batch loss 0.0654, batch acc 0.9796
11:07:30.550   Training iter 450, batch loss 0.0658, batch acc 0.9808
11:07:32.629   Training iter 500, batch loss 0.0620, batch acc 0.9824
11:07:34.710   Training iter 550, batch loss 0.0645, batch acc 0.9816
11:07:36.790   Training iter 600, batch loss 0.0633, batch acc 0.9804
11:07:36.792 Training @ 12 epoch...
11:07:38.872   Training iter 50, batch loss 0.0680, batch acc 0.9790
11:07:40.949   Training iter 100, batch loss 0.0672, batch acc 0.9798
11:07:43.033   Training iter 150, batch loss 0.0584, batch acc 0.9812
11:07:45.114   Training iter 200, batch loss 0.0686, batch acc 0.9816
11:07:47.194   Training iter 250, batch loss 0.0599, batch acc 0.9814
11:07:49.272   Training iter 300, batch loss 0.0650, batch acc 0.9796
11:07:51.351   Training iter 350, batch loss 0.0594, batch acc 0.9824
11:07:53.434   Training iter 400, batch loss 0.0594, batch acc 0.9812
11:07:55.512   Training iter 450, batch loss 0.0700, batch acc 0.9784
11:07:57.597   Training iter 500, batch loss 0.0598, batch acc 0.9788
11:07:59.676   Training iter 550, batch loss 0.0702, batch acc 0.9786
11:08:01.759   Training iter 600, batch loss 0.0640, batch acc 0.9810
11:08:01.760 Training @ 13 epoch...
11:08:03.840   Training iter 50, batch loss 0.0625, batch acc 0.9806
11:08:05.918   Training iter 100, batch loss 0.0587, batch acc 0.9816
11:08:07.997   Training iter 150, batch loss 0.0615, batch acc 0.9780
11:08:10.072   Training iter 200, batch loss 0.0554, batch acc 0.9836
11:08:12.148   Training iter 250, batch loss 0.0585, batch acc 0.9820
11:08:14.225   Training iter 300, batch loss 0.0603, batch acc 0.9822
11:08:16.299   Training iter 350, batch loss 0.0731, batch acc 0.9808
11:08:18.374   Training iter 400, batch loss 0.0695, batch acc 0.9796
11:08:20.448   Training iter 450, batch loss 0.0654, batch acc 0.9794
11:08:22.523   Training iter 500, batch loss 0.0689, batch acc 0.9796
11:08:24.598   Training iter 550, batch loss 0.0629, batch acc 0.9812
11:08:26.672   Training iter 600, batch loss 0.0602, batch acc 0.9828
11:08:26.674 Training @ 14 epoch...
11:08:28.757   Training iter 50, batch loss 0.0583, batch acc 0.9814
11:08:30.835   Training iter 100, batch loss 0.0614, batch acc 0.9816
11:08:32.917   Training iter 150, batch loss 0.0507, batch acc 0.9832
11:08:34.994   Training iter 200, batch loss 0.0657, batch acc 0.9782
11:08:37.077   Training iter 250, batch loss 0.0618, batch acc 0.9810
11:08:39.156   Training iter 300, batch loss 0.0579, batch acc 0.9844
11:08:41.238   Training iter 350, batch loss 0.0684, batch acc 0.9806
11:08:43.325   Training iter 400, batch loss 0.0690, batch acc 0.9784
11:08:45.407   Training iter 450, batch loss 0.0595, batch acc 0.9816
11:08:47.485   Training iter 500, batch loss 0.0573, batch acc 0.9820
11:08:49.567   Training iter 550, batch loss 0.0612, batch acc 0.9806
11:08:51.647   Training iter 600, batch loss 0.0664, batch acc 0.9788
11:08:51.648 Training @ 15 epoch...
11:08:53.728   Training iter 50, batch loss 0.0502, batch acc 0.9854
11:08:55.807   Training iter 100, batch loss 0.0558, batch acc 0.9836
11:08:57.892   Training iter 150, batch loss 0.0605, batch acc 0.9798
11:08:59.970   Training iter 200, batch loss 0.0630, batch acc 0.9790
11:09:02.048   Training iter 250, batch loss 0.0655, batch acc 0.9808
11:09:04.126   Training iter 300, batch loss 0.0677, batch acc 0.9778
11:09:06.206   Training iter 350, batch loss 0.0671, batch acc 0.9808
11:09:08.281   Training iter 400, batch loss 0.0609, batch acc 0.9812
11:09:10.361   Training iter 450, batch loss 0.0576, batch acc 0.9838
11:09:12.438   Training iter 500, batch loss 0.0557, batch acc 0.9818
11:09:14.517   Training iter 550, batch loss 0.0617, batch acc 0.9816
11:09:16.591   Training iter 600, batch loss 0.0577, batch acc 0.9822
11:09:16.593 Testing @ 15 epoch...
11:09:17.858     Testing, total mean loss 0.05369, total acc 0.98210
11:09:17.858 Training @ 16 epoch...
11:09:19.952   Training iter 50, batch loss 0.0496, batch acc 0.9870
11:09:22.024   Training iter 100, batch loss 0.0568, batch acc 0.9822
11:09:24.092   Training iter 150, batch loss 0.0547, batch acc 0.9812
11:09:26.168   Training iter 200, batch loss 0.0572, batch acc 0.9830
11:09:28.241   Training iter 250, batch loss 0.0728, batch acc 0.9778
11:09:30.327   Training iter 300, batch loss 0.0607, batch acc 0.9832
11:09:32.409   Training iter 350, batch loss 0.0682, batch acc 0.9788
11:09:34.493   Training iter 400, batch loss 0.0598, batch acc 0.9822
11:09:36.578   Training iter 450, batch loss 0.0565, batch acc 0.9814
11:09:38.679   Training iter 500, batch loss 0.0527, batch acc 0.9846
11:09:40.773   Training iter 550, batch loss 0.0657, batch acc 0.9804
11:09:42.871   Training iter 600, batch loss 0.0554, batch acc 0.9822
11:09:42.872 Training @ 17 epoch...
11:09:44.970   Training iter 50, batch loss 0.0654, batch acc 0.9802
11:09:47.067   Training iter 100, batch loss 0.0528, batch acc 0.9850
11:09:49.166   Training iter 150, batch loss 0.0621, batch acc 0.9818
11:09:51.266   Training iter 200, batch loss 0.0556, batch acc 0.9844
11:09:53.361   Training iter 250, batch loss 0.0653, batch acc 0.9816
11:09:55.458   Training iter 300, batch loss 0.0544, batch acc 0.9832
11:09:57.562   Training iter 350, batch loss 0.0659, batch acc 0.9786
11:09:59.661   Training iter 400, batch loss 0.0570, batch acc 0.9818
11:10:01.794   Training iter 450, batch loss 0.0567, batch acc 0.9826
11:10:03.930   Training iter 500, batch loss 0.0580, batch acc 0.9828
11:10:06.010   Training iter 550, batch loss 0.0565, batch acc 0.9828
11:10:08.095   Training iter 600, batch loss 0.0490, batch acc 0.9854
11:10:08.096 Training @ 18 epoch...
11:10:10.183   Training iter 50, batch loss 0.0501, batch acc 0.9842
11:10:12.270   Training iter 100, batch loss 0.0558, batch acc 0.9818
11:10:14.361   Training iter 150, batch loss 0.0526, batch acc 0.9820
11:10:16.445   Training iter 200, batch loss 0.0483, batch acc 0.9872
11:10:18.534   Training iter 250, batch loss 0.0569, batch acc 0.9844
11:10:20.620   Training iter 300, batch loss 0.0658, batch acc 0.9814
11:10:22.712   Training iter 350, batch loss 0.0609, batch acc 0.9838
11:10:24.803   Training iter 400, batch loss 0.0560, batch acc 0.9822
11:10:26.890   Training iter 450, batch loss 0.0682, batch acc 0.9778
11:10:28.977   Training iter 500, batch loss 0.0563, batch acc 0.9826
11:10:31.064   Training iter 550, batch loss 0.0598, batch acc 0.9808
11:10:33.150   Training iter 600, batch loss 0.0615, batch acc 0.9812
11:10:33.152 Training @ 19 epoch...
11:10:35.243   Training iter 50, batch loss 0.0532, batch acc 0.9854
11:10:37.332   Training iter 100, batch loss 0.0478, batch acc 0.9854
11:10:39.419   Training iter 150, batch loss 0.0643, batch acc 0.9800
11:10:41.509   Training iter 200, batch loss 0.0559, batch acc 0.9828
11:10:43.595   Training iter 250, batch loss 0.0724, batch acc 0.9792
11:10:45.681   Training iter 300, batch loss 0.0501, batch acc 0.9844
11:10:47.764   Training iter 350, batch loss 0.0509, batch acc 0.9848
11:10:49.846   Training iter 400, batch loss 0.0585, batch acc 0.9806
11:10:51.931   Training iter 450, batch loss 0.0629, batch acc 0.9800
11:10:54.017   Training iter 500, batch loss 0.0549, batch acc 0.9828
11:10:56.106   Training iter 550, batch loss 0.0572, batch acc 0.9836
11:10:58.190   Training iter 600, batch loss 0.0525, batch acc 0.9844
11:10:58.192 Training @ 20 epoch...
11:11:00.280   Training iter 50, batch loss 0.0581, batch acc 0.9824
11:11:02.368   Training iter 100, batch loss 0.0482, batch acc 0.9862
11:11:04.458   Training iter 150, batch loss 0.0613, batch acc 0.9840
11:11:06.541   Training iter 200, batch loss 0.0524, batch acc 0.9836
11:11:08.630   Training iter 250, batch loss 0.0478, batch acc 0.9854
11:11:10.720   Training iter 300, batch loss 0.0554, batch acc 0.9836
11:11:12.802   Training iter 350, batch loss 0.0574, batch acc 0.9826
11:11:14.892   Training iter 400, batch loss 0.0603, batch acc 0.9790
11:11:16.983   Training iter 450, batch loss 0.0624, batch acc 0.9806
11:11:19.070   Training iter 500, batch loss 0.0626, batch acc 0.9796
11:11:21.156   Training iter 550, batch loss 0.0572, batch acc 0.9820
11:11:23.246   Training iter 600, batch loss 0.0523, batch acc 0.9860
11:11:23.247 Testing @ 20 epoch...
11:11:24.512     Testing, total mean loss 0.05442, total acc 0.98340
11:11:24.512 Training @ 21 epoch...
11:11:26.588   Training iter 50, batch loss 0.0451, batch acc 0.9888
11:11:28.628   Training iter 100, batch loss 0.0485, batch acc 0.9854
11:11:30.667   Training iter 150, batch loss 0.0554, batch acc 0.9822
11:11:32.708   Training iter 200, batch loss 0.0583, batch acc 0.9810
11:11:34.746   Training iter 250, batch loss 0.0517, batch acc 0.9844
11:11:36.797   Training iter 300, batch loss 0.0482, batch acc 0.9838
11:11:38.846   Training iter 350, batch loss 0.0616, batch acc 0.9810
11:11:40.896   Training iter 400, batch loss 0.0671, batch acc 0.9792
11:11:42.945   Training iter 450, batch loss 0.0525, batch acc 0.9842
11:11:44.994   Training iter 500, batch loss 0.0525, batch acc 0.9858
11:11:47.043   Training iter 550, batch loss 0.0677, batch acc 0.9808
11:11:49.088   Training iter 600, batch loss 0.0588, batch acc 0.9832
11:11:49.089 Training @ 22 epoch...
11:11:51.145   Training iter 50, batch loss 0.0586, batch acc 0.9826
11:11:53.195   Training iter 100, batch loss 0.0650, batch acc 0.9802
11:11:55.250   Training iter 150, batch loss 0.0508, batch acc 0.9838
11:11:57.304   Training iter 200, batch loss 0.0656, batch acc 0.9796
11:11:59.355   Training iter 250, batch loss 0.0454, batch acc 0.9858
11:12:01.407   Training iter 300, batch loss 0.0529, batch acc 0.9826
11:12:03.456   Training iter 350, batch loss 0.0543, batch acc 0.9828
11:12:05.489   Training iter 400, batch loss 0.0596, batch acc 0.9806
11:12:07.512   Training iter 450, batch loss 0.0447, batch acc 0.9860
11:12:09.537   Training iter 500, batch loss 0.0504, batch acc 0.9848
11:12:11.568   Training iter 550, batch loss 0.0561, batch acc 0.9834
11:12:13.575   Training iter 600, batch loss 0.0532, batch acc 0.9852
11:12:13.576 Training @ 23 epoch...
11:12:15.609   Training iter 50, batch loss 0.0519, batch acc 0.9838
11:12:17.640   Training iter 100, batch loss 0.0568, batch acc 0.9852
11:12:19.668   Training iter 150, batch loss 0.0539, batch acc 0.9816
11:12:21.698   Training iter 200, batch loss 0.0607, batch acc 0.9808
11:12:23.726   Training iter 250, batch loss 0.0425, batch acc 0.9876
11:12:25.769   Training iter 300, batch loss 0.0614, batch acc 0.9810
11:12:27.801   Training iter 350, batch loss 0.0637, batch acc 0.9834
11:12:29.835   Training iter 400, batch loss 0.0482, batch acc 0.9846
11:12:31.865   Training iter 450, batch loss 0.0517, batch acc 0.9840
11:12:33.900   Training iter 500, batch loss 0.0551, batch acc 0.9828
11:12:35.933   Training iter 550, batch loss 0.0598, batch acc 0.9818
11:12:37.971   Training iter 600, batch loss 0.0484, batch acc 0.9856
11:12:37.972 Training @ 24 epoch...
11:12:40.015   Training iter 50, batch loss 0.0633, batch acc 0.9802
11:12:42.053   Training iter 100, batch loss 0.0467, batch acc 0.9860
11:12:44.083   Training iter 150, batch loss 0.0486, batch acc 0.9836
11:12:46.123   Training iter 200, batch loss 0.0471, batch acc 0.9832
11:12:48.162   Training iter 250, batch loss 0.0631, batch acc 0.9804
11:12:50.201   Training iter 300, batch loss 0.0474, batch acc 0.9870
11:12:52.235   Training iter 350, batch loss 0.0547, batch acc 0.9838
11:12:54.267   Training iter 400, batch loss 0.0544, batch acc 0.9822
11:12:56.297   Training iter 450, batch loss 0.0496, batch acc 0.9832
11:12:58.323   Training iter 500, batch loss 0.0610, batch acc 0.9820
11:13:00.351   Training iter 550, batch loss 0.0535, batch acc 0.9832
11:13:02.381   Training iter 600, batch loss 0.0533, batch acc 0.9852
11:13:02.382 Training @ 25 epoch...
11:13:04.416   Training iter 50, batch loss 0.0555, batch acc 0.9820
11:13:06.446   Training iter 100, batch loss 0.0536, batch acc 0.9836
11:13:08.480   Training iter 150, batch loss 0.0503, batch acc 0.9842
11:13:10.517   Training iter 200, batch loss 0.0634, batch acc 0.9832
11:13:12.544   Training iter 250, batch loss 0.0502, batch acc 0.9844
11:13:14.570   Training iter 300, batch loss 0.0544, batch acc 0.9824
11:13:16.594   Training iter 350, batch loss 0.0568, batch acc 0.9824
11:13:18.625   Training iter 400, batch loss 0.0525, batch acc 0.9852
11:13:20.656   Training iter 450, batch loss 0.0495, batch acc 0.9846
11:13:22.694   Training iter 500, batch loss 0.0507, batch acc 0.9844
11:13:24.721   Training iter 550, batch loss 0.0589, batch acc 0.9840
11:13:26.752   Training iter 600, batch loss 0.0400, batch acc 0.9862
11:13:26.753 Testing @ 25 epoch...
11:13:27.932     Testing, total mean loss 0.05319, total acc 0.98350
11:13:27.932 Training @ 26 epoch...
11:13:29.971   Training iter 50, batch loss 0.0459, batch acc 0.9864
11:13:31.998   Training iter 100, batch loss 0.0494, batch acc 0.9864
11:13:34.028   Training iter 150, batch loss 0.0501, batch acc 0.9832
11:13:36.053   Training iter 200, batch loss 0.0577, batch acc 0.9834
11:13:38.083   Training iter 250, batch loss 0.0552, batch acc 0.9842
11:13:40.110   Training iter 300, batch loss 0.0487, batch acc 0.9842
11:13:42.138   Training iter 350, batch loss 0.0565, batch acc 0.9828
11:13:44.167   Training iter 400, batch loss 0.0514, batch acc 0.9862
11:13:46.186   Training iter 450, batch loss 0.0600, batch acc 0.9812
11:13:48.224   Training iter 500, batch loss 0.0493, batch acc 0.9858
11:13:50.253   Training iter 550, batch loss 0.0533, batch acc 0.9816
11:13:52.280   Training iter 600, batch loss 0.0538, batch acc 0.9836
11:13:52.281 Training @ 27 epoch...
11:13:54.311   Training iter 50, batch loss 0.0445, batch acc 0.9846
11:13:56.342   Training iter 100, batch loss 0.0450, batch acc 0.9856
11:13:58.374   Training iter 150, batch loss 0.0484, batch acc 0.9862
11:14:00.410   Training iter 200, batch loss 0.0413, batch acc 0.9884
11:14:02.432   Training iter 250, batch loss 0.0459, batch acc 0.9854
11:14:04.471   Training iter 300, batch loss 0.0552, batch acc 0.9828
11:14:06.496   Training iter 350, batch loss 0.0592, batch acc 0.9828
11:14:08.532   Training iter 400, batch loss 0.0577, batch acc 0.9826
11:14:10.558   Training iter 450, batch loss 0.0557, batch acc 0.9830
11:14:12.588   Training iter 500, batch loss 0.0529, batch acc 0.9842
11:14:14.618   Training iter 550, batch loss 0.0684, batch acc 0.9820
11:14:16.643   Training iter 600, batch loss 0.0570, batch acc 0.9850
11:14:16.644 Training @ 28 epoch...
11:14:18.680   Training iter 50, batch loss 0.0484, batch acc 0.9864
11:14:20.712   Training iter 100, batch loss 0.0432, batch acc 0.9886
11:14:22.738   Training iter 150, batch loss 0.0587, batch acc 0.9820
11:14:24.770   Training iter 200, batch loss 0.0583, batch acc 0.9824
11:14:26.797   Training iter 250, batch loss 0.0531, batch acc 0.9840
11:14:28.826   Training iter 300, batch loss 0.0462, batch acc 0.9854
11:14:30.857   Training iter 350, batch loss 0.0517, batch acc 0.9842
11:14:32.891   Training iter 400, batch loss 0.0519, batch acc 0.9844
11:14:34.924   Training iter 450, batch loss 0.0460, batch acc 0.9862
11:14:36.952   Training iter 500, batch loss 0.0529, batch acc 0.9816
11:14:38.981   Training iter 550, batch loss 0.0564, batch acc 0.9830
11:14:41.015   Training iter 600, batch loss 0.0613, batch acc 0.9788
11:14:41.016 Training @ 29 epoch...
11:14:43.047   Training iter 50, batch loss 0.0472, batch acc 0.9860
11:14:45.075   Training iter 100, batch loss 0.0473, batch acc 0.9838
11:14:47.105   Training iter 150, batch loss 0.0571, batch acc 0.9850
11:14:49.131   Training iter 200, batch loss 0.0493, batch acc 0.9840
11:14:51.161   Training iter 250, batch loss 0.0505, batch acc 0.9836
11:14:53.195   Training iter 300, batch loss 0.0413, batch acc 0.9870
11:14:55.223   Training iter 350, batch loss 0.0572, batch acc 0.9840
11:14:57.252   Training iter 400, batch loss 0.0491, batch acc 0.9846
11:14:59.286   Training iter 450, batch loss 0.0542, batch acc 0.9834
11:15:01.319   Training iter 500, batch loss 0.0604, batch acc 0.9806
11:15:03.345   Training iter 550, batch loss 0.0603, batch acc 0.9836
11:15:05.378   Training iter 600, batch loss 0.0469, batch acc 0.9874
11:15:05.379 Training @ 30 epoch...
11:15:07.416   Training iter 50, batch loss 0.0404, batch acc 0.9874
11:15:09.452   Training iter 100, batch loss 0.0516, batch acc 0.9830
11:15:11.480   Training iter 150, batch loss 0.0556, batch acc 0.9842
11:15:13.506   Training iter 200, batch loss 0.0524, batch acc 0.9836
11:15:15.529   Training iter 250, batch loss 0.0530, batch acc 0.9840
11:15:17.561   Training iter 300, batch loss 0.0441, batch acc 0.9866
11:15:19.584   Training iter 350, batch loss 0.0526, batch acc 0.9844
11:15:21.607   Training iter 400, batch loss 0.0441, batch acc 0.9852
11:15:23.626   Training iter 450, batch loss 0.0494, batch acc 0.9848
11:15:25.649   Training iter 500, batch loss 0.0574, batch acc 0.9810
11:15:27.662   Training iter 550, batch loss 0.0558, batch acc 0.9832
11:15:29.691   Training iter 600, batch loss 0.0599, batch acc 0.9826
11:15:29.692 Testing @ 30 epoch...
11:15:30.871     Testing, total mean loss 0.05391, total acc 0.98250
11:15:30.871 Training @ 31 epoch...
11:15:32.900   Training iter 50, batch loss 0.0523, batch acc 0.9848
11:15:34.923   Training iter 100, batch loss 0.0563, batch acc 0.9846
11:15:36.950   Training iter 150, batch loss 0.0568, batch acc 0.9840
11:15:38.974   Training iter 200, batch loss 0.0479, batch acc 0.9866
11:15:41.000   Training iter 250, batch loss 0.0455, batch acc 0.9864
11:15:43.030   Training iter 300, batch loss 0.0502, batch acc 0.9842
11:15:45.055   Training iter 350, batch loss 0.0533, batch acc 0.9832
11:15:47.083   Training iter 400, batch loss 0.0406, batch acc 0.9858
11:15:49.108   Training iter 450, batch loss 0.0422, batch acc 0.9866
11:15:51.119   Training iter 500, batch loss 0.0576, batch acc 0.9814
11:15:53.132   Training iter 550, batch loss 0.0488, batch acc 0.9842
11:15:55.149   Training iter 600, batch loss 0.0522, batch acc 0.9856
11:15:55.150 Training @ 32 epoch...
11:15:57.181   Training iter 50, batch loss 0.0454, batch acc 0.9874
11:15:59.212   Training iter 100, batch loss 0.0484, batch acc 0.9856
11:16:01.245   Training iter 150, batch loss 0.0484, batch acc 0.9836
11:16:03.276   Training iter 200, batch loss 0.0504, batch acc 0.9844
11:16:05.308   Training iter 250, batch loss 0.0533, batch acc 0.9838
11:16:07.340   Training iter 300, batch loss 0.0477, batch acc 0.9864
11:16:09.371   Training iter 350, batch loss 0.0526, batch acc 0.9832
11:16:11.406   Training iter 400, batch loss 0.0473, batch acc 0.9848
11:16:13.441   Training iter 450, batch loss 0.0610, batch acc 0.9820
11:16:15.473   Training iter 500, batch loss 0.0573, batch acc 0.9808
11:16:17.507   Training iter 550, batch loss 0.0524, batch acc 0.9836
11:16:19.541   Training iter 600, batch loss 0.0421, batch acc 0.9872
11:16:19.542 Training @ 33 epoch...
11:16:21.574   Training iter 50, batch loss 0.0470, batch acc 0.9856
11:16:23.605   Training iter 100, batch loss 0.0471, batch acc 0.9842
11:16:25.642   Training iter 150, batch loss 0.0501, batch acc 0.9816
11:16:27.672   Training iter 200, batch loss 0.0480, batch acc 0.9872
11:16:29.704   Training iter 250, batch loss 0.0486, batch acc 0.9832
11:16:31.738   Training iter 300, batch loss 0.0581, batch acc 0.9836
11:16:33.771   Training iter 350, batch loss 0.0471, batch acc 0.9854
11:16:35.804   Training iter 400, batch loss 0.0443, batch acc 0.9842
11:16:37.837   Training iter 450, batch loss 0.0542, batch acc 0.9834
11:16:39.865   Training iter 500, batch loss 0.0552, batch acc 0.9830
11:16:41.902   Training iter 550, batch loss 0.0484, batch acc 0.9848
11:16:43.939   Training iter 600, batch loss 0.0555, batch acc 0.9860
11:16:43.940 Training @ 34 epoch...
11:16:45.979   Training iter 50, batch loss 0.0404, batch acc 0.9874
11:16:48.010   Training iter 100, batch loss 0.0538, batch acc 0.9846
11:16:50.041   Training iter 150, batch loss 0.0378, batch acc 0.9888
11:16:52.072   Training iter 200, batch loss 0.0579, batch acc 0.9824
11:16:54.109   Training iter 250, batch loss 0.0460, batch acc 0.9866
11:16:56.138   Training iter 300, batch loss 0.0602, batch acc 0.9812
11:16:58.167   Training iter 350, batch loss 0.0537, batch acc 0.9838
11:17:00.195   Training iter 400, batch loss 0.0459, batch acc 0.9842
11:17:02.226   Training iter 450, batch loss 0.0540, batch acc 0.9830
11:17:04.256   Training iter 500, batch loss 0.0513, batch acc 0.9856
11:17:06.285   Training iter 550, batch loss 0.0532, batch acc 0.9838
11:17:08.314   Training iter 600, batch loss 0.0402, batch acc 0.9852
11:17:08.315 Training @ 35 epoch...
11:17:10.349   Training iter 50, batch loss 0.0546, batch acc 0.9834
11:17:12.371   Training iter 100, batch loss 0.0449, batch acc 0.9842
11:17:14.395   Training iter 150, batch loss 0.0452, batch acc 0.9860
11:17:16.409   Training iter 200, batch loss 0.0458, batch acc 0.9868
11:17:18.437   Training iter 250, batch loss 0.0485, batch acc 0.9840
11:17:20.464   Training iter 300, batch loss 0.0575, batch acc 0.9824
11:17:22.493   Training iter 350, batch loss 0.0519, batch acc 0.9832
11:17:24.518   Training iter 400, batch loss 0.0525, batch acc 0.9842
11:17:26.545   Training iter 450, batch loss 0.0430, batch acc 0.9870
11:17:28.573   Training iter 500, batch loss 0.0503, batch acc 0.9848
11:17:30.601   Training iter 550, batch loss 0.0514, batch acc 0.9848
11:17:32.622   Training iter 600, batch loss 0.0444, batch acc 0.9874
11:17:32.623 Testing @ 35 epoch...
11:17:33.800     Testing, total mean loss 0.04849, total acc 0.98440
11:17:33.800 Training @ 36 epoch...
11:17:35.831   Training iter 50, batch loss 0.0367, batch acc 0.9894
11:17:37.856   Training iter 100, batch loss 0.0537, batch acc 0.9836
11:17:39.875   Training iter 150, batch loss 0.0570, batch acc 0.9824
11:17:41.901   Training iter 200, batch loss 0.0465, batch acc 0.9854
11:17:43.923   Training iter 250, batch loss 0.0546, batch acc 0.9842
11:17:45.947   Training iter 300, batch loss 0.0463, batch acc 0.9866
11:17:47.976   Training iter 350, batch loss 0.0439, batch acc 0.9864
11:17:50.000   Training iter 400, batch loss 0.0498, batch acc 0.9842
11:17:52.023   Training iter 450, batch loss 0.0485, batch acc 0.9860
11:17:54.051   Training iter 500, batch loss 0.0497, batch acc 0.9844
11:17:56.073   Training iter 550, batch loss 0.0429, batch acc 0.9864
11:17:58.094   Training iter 600, batch loss 0.0483, batch acc 0.9856
11:17:58.095 Training @ 37 epoch...
11:18:00.124   Training iter 50, batch loss 0.0461, batch acc 0.9870
11:18:02.152   Training iter 100, batch loss 0.0510, batch acc 0.9848
11:18:04.177   Training iter 150, batch loss 0.0555, batch acc 0.9846
11:18:06.211   Training iter 200, batch loss 0.0428, batch acc 0.9874
11:18:08.236   Training iter 250, batch loss 0.0458, batch acc 0.9842
11:18:10.256   Training iter 300, batch loss 0.0557, batch acc 0.9820
11:18:12.287   Training iter 350, batch loss 0.0474, batch acc 0.9854
11:18:14.311   Training iter 400, batch loss 0.0503, batch acc 0.9842
11:18:16.333   Training iter 450, batch loss 0.0448, batch acc 0.9856
11:18:18.360   Training iter 500, batch loss 0.0487, batch acc 0.9852
11:18:20.384   Training iter 550, batch loss 0.0469, batch acc 0.9864
11:18:22.410   Training iter 600, batch loss 0.0436, batch acc 0.9868
11:18:22.411 Training @ 38 epoch...
11:18:24.434   Training iter 50, batch loss 0.0456, batch acc 0.9862
11:18:26.454   Training iter 100, batch loss 0.0518, batch acc 0.9814
11:18:28.481   Training iter 150, batch loss 0.0517, batch acc 0.9826
11:18:30.488   Training iter 200, batch loss 0.0473, batch acc 0.9876
11:18:32.510   Training iter 250, batch loss 0.0470, batch acc 0.9848
11:18:34.520   Training iter 300, batch loss 0.0501, batch acc 0.9838
11:18:36.529   Training iter 350, batch loss 0.0480, batch acc 0.9854
11:18:38.549   Training iter 400, batch loss 0.0519, batch acc 0.9842
11:18:40.573   Training iter 450, batch loss 0.0413, batch acc 0.9874
11:18:42.599   Training iter 500, batch loss 0.0425, batch acc 0.9886
11:18:44.624   Training iter 550, batch loss 0.0485, batch acc 0.9850
11:18:46.640   Training iter 600, batch loss 0.0501, batch acc 0.9856
11:18:46.641 Training @ 39 epoch...
11:18:48.669   Training iter 50, batch loss 0.0538, batch acc 0.9842
11:18:50.690   Training iter 100, batch loss 0.0484, batch acc 0.9852
11:18:52.699   Training iter 150, batch loss 0.0416, batch acc 0.9882
11:18:54.712   Training iter 200, batch loss 0.0440, batch acc 0.9872
11:18:56.737   Training iter 250, batch loss 0.0438, batch acc 0.9862
11:18:58.761   Training iter 300, batch loss 0.0550, batch acc 0.9832
11:19:00.781   Training iter 350, batch loss 0.0433, batch acc 0.9866
11:19:02.808   Training iter 400, batch loss 0.0533, batch acc 0.9832
11:19:04.831   Training iter 450, batch loss 0.0437, batch acc 0.9860
11:19:06.856   Training iter 500, batch loss 0.0420, batch acc 0.9866
11:19:08.858   Training iter 550, batch loss 0.0576, batch acc 0.9850
11:19:10.872   Training iter 600, batch loss 0.0427, batch acc 0.9864
11:19:10.872 Training @ 40 epoch...
11:19:12.898   Training iter 50, batch loss 0.0396, batch acc 0.9880
11:19:14.922   Training iter 100, batch loss 0.0437, batch acc 0.9848
11:19:16.948   Training iter 150, batch loss 0.0444, batch acc 0.9872
11:19:18.974   Training iter 200, batch loss 0.0524, batch acc 0.9862
11:19:21.001   Training iter 250, batch loss 0.0433, batch acc 0.9874
11:19:23.028   Training iter 300, batch loss 0.0463, batch acc 0.9846
11:19:25.054   Training iter 350, batch loss 0.0465, batch acc 0.9856
11:19:27.072   Training iter 400, batch loss 0.0463, batch acc 0.9860
11:19:29.102   Training iter 450, batch loss 0.0475, batch acc 0.9846
11:19:31.131   Training iter 500, batch loss 0.0437, batch acc 0.9868
11:19:33.152   Training iter 550, batch loss 0.0585, batch acc 0.9834
11:19:35.178   Training iter 600, batch loss 0.0562, batch acc 0.9848
11:19:35.179 Testing @ 40 epoch...
11:19:36.364     Testing, total mean loss 0.04771, total acc 0.98440
11:19:36.364 Training @ 41 epoch...
11:19:38.379   Training iter 50, batch loss 0.0468, batch acc 0.9840
11:19:40.388   Training iter 100, batch loss 0.0452, batch acc 0.9860
11:19:42.402   Training iter 150, batch loss 0.0427, batch acc 0.9892
11:19:44.416   Training iter 200, batch loss 0.0453, batch acc 0.9842
11:19:46.428   Training iter 250, batch loss 0.0467, batch acc 0.9856
11:19:48.444   Training iter 300, batch loss 0.0465, batch acc 0.9840
11:19:50.465   Training iter 350, batch loss 0.0491, batch acc 0.9854
11:19:52.474   Training iter 400, batch loss 0.0490, batch acc 0.9848
11:19:54.489   Training iter 450, batch loss 0.0581, batch acc 0.9816
11:19:56.501   Training iter 500, batch loss 0.0452, batch acc 0.9866
11:19:58.521   Training iter 550, batch loss 0.0397, batch acc 0.9874
11:20:00.528   Training iter 600, batch loss 0.0504, batch acc 0.9826
11:20:00.529 Training @ 42 epoch...
11:20:02.549   Training iter 50, batch loss 0.0499, batch acc 0.9848
11:20:04.549   Training iter 100, batch loss 0.0434, batch acc 0.9878
11:20:06.560   Training iter 150, batch loss 0.0476, batch acc 0.9864
11:20:08.580   Training iter 200, batch loss 0.0469, batch acc 0.9864
11:20:10.595   Training iter 250, batch loss 0.0503, batch acc 0.9856
11:20:12.611   Training iter 300, batch loss 0.0498, batch acc 0.9848
11:20:14.632   Training iter 350, batch loss 0.0389, batch acc 0.9880
11:20:16.660   Training iter 400, batch loss 0.0436, batch acc 0.9848
11:20:18.681   Training iter 450, batch loss 0.0514, batch acc 0.9844
11:20:20.701   Training iter 500, batch loss 0.0412, batch acc 0.9860
11:20:22.722   Training iter 550, batch loss 0.0476, batch acc 0.9854
11:20:24.739   Training iter 600, batch loss 0.0506, batch acc 0.9840
11:20:24.740 Training @ 43 epoch...
11:20:26.769   Training iter 50, batch loss 0.0446, batch acc 0.9872
11:20:28.779   Training iter 100, batch loss 0.0484, batch acc 0.9858
11:20:30.804   Training iter 150, batch loss 0.0440, batch acc 0.9860
11:20:32.830   Training iter 200, batch loss 0.0521, batch acc 0.9838
11:20:34.849   Training iter 250, batch loss 0.0431, batch acc 0.9854
11:20:36.871   Training iter 300, batch loss 0.0408, batch acc 0.9866
11:20:38.897   Training iter 350, batch loss 0.0573, batch acc 0.9836
11:20:40.929   Training iter 400, batch loss 0.0499, batch acc 0.9868
11:20:42.950   Training iter 450, batch loss 0.0391, batch acc 0.9878
11:20:44.977   Training iter 500, batch loss 0.0423, batch acc 0.9852
11:20:47.002   Training iter 550, batch loss 0.0500, batch acc 0.9846
11:20:49.031   Training iter 600, batch loss 0.0464, batch acc 0.9862
11:20:49.032 Training @ 44 epoch...
11:20:51.052   Training iter 50, batch loss 0.0440, batch acc 0.9886
11:20:53.077   Training iter 100, batch loss 0.0455, batch acc 0.9842
11:20:55.095   Training iter 150, batch loss 0.0494, batch acc 0.9846
11:20:57.133   Training iter 200, batch loss 0.0486, batch acc 0.9836
11:20:59.160   Training iter 250, batch loss 0.0498, batch acc 0.9852
11:21:01.194   Training iter 300, batch loss 0.0456, batch acc 0.9854
11:21:03.230   Training iter 350, batch loss 0.0458, batch acc 0.9874
11:21:05.263   Training iter 400, batch loss 0.0469, batch acc 0.9852
11:21:07.290   Training iter 450, batch loss 0.0508, batch acc 0.9840
11:21:09.320   Training iter 500, batch loss 0.0517, batch acc 0.9840
11:21:11.352   Training iter 550, batch loss 0.0404, batch acc 0.9878
11:21:13.388   Training iter 600, batch loss 0.0368, batch acc 0.9882
11:21:13.389 Training @ 45 epoch...
11:21:15.422   Training iter 50, batch loss 0.0462, batch acc 0.9868
11:21:17.452   Training iter 100, batch loss 0.0476, batch acc 0.9854
11:21:19.487   Training iter 150, batch loss 0.0445, batch acc 0.9852
11:21:21.524   Training iter 200, batch loss 0.0506, batch acc 0.9842
11:21:23.562   Training iter 250, batch loss 0.0423, batch acc 0.9852
11:21:25.591   Training iter 300, batch loss 0.0492, batch acc 0.9864
11:21:27.622   Training iter 350, batch loss 0.0521, batch acc 0.9832
11:21:29.649   Training iter 400, batch loss 0.0533, batch acc 0.9850
11:21:31.682   Training iter 450, batch loss 0.0445, batch acc 0.9862
11:21:33.716   Training iter 500, batch loss 0.0321, batch acc 0.9902
11:21:35.733   Training iter 550, batch loss 0.0408, batch acc 0.9854
11:21:37.764   Training iter 600, batch loss 0.0450, batch acc 0.9876
11:21:37.765 Testing @ 45 epoch...
11:21:38.942     Testing, total mean loss 0.04858, total acc 0.98490
11:21:38.942 Training @ 46 epoch...
11:21:40.973   Training iter 50, batch loss 0.0402, batch acc 0.9872
11:21:43.003   Training iter 100, batch loss 0.0381, batch acc 0.9886
11:21:45.030   Training iter 150, batch loss 0.0461, batch acc 0.9864
11:21:47.061   Training iter 200, batch loss 0.0421, batch acc 0.9850
11:21:49.082   Training iter 250, batch loss 0.0432, batch acc 0.9882
11:21:51.123   Training iter 300, batch loss 0.0382, batch acc 0.9882
11:21:53.158   Training iter 350, batch loss 0.0525, batch acc 0.9834
11:21:55.194   Training iter 400, batch loss 0.0389, batch acc 0.9852
11:21:57.225   Training iter 450, batch loss 0.0460, batch acc 0.9862
11:21:59.261   Training iter 500, batch loss 0.0525, batch acc 0.9852
11:22:01.291   Training iter 550, batch loss 0.0513, batch acc 0.9856
11:22:03.332   Training iter 600, batch loss 0.0587, batch acc 0.9840
11:22:03.333 Training @ 47 epoch...
11:22:05.371   Training iter 50, batch loss 0.0391, batch acc 0.9890
11:22:07.403   Training iter 100, batch loss 0.0442, batch acc 0.9858
11:22:09.431   Training iter 150, batch loss 0.0533, batch acc 0.9852
11:22:11.460   Training iter 200, batch loss 0.0403, batch acc 0.9864
11:22:13.493   Training iter 250, batch loss 0.0475, batch acc 0.9850
11:22:15.519   Training iter 300, batch loss 0.0365, batch acc 0.9882
11:22:17.558   Training iter 350, batch loss 0.0517, batch acc 0.9848
11:22:19.591   Training iter 400, batch loss 0.0534, batch acc 0.9850
11:22:21.621   Training iter 450, batch loss 0.0412, batch acc 0.9866
11:22:23.653   Training iter 500, batch loss 0.0420, batch acc 0.9860
11:22:25.682   Training iter 550, batch loss 0.0465, batch acc 0.9868
11:22:27.711   Training iter 600, batch loss 0.0445, batch acc 0.9856
11:22:27.712 Training @ 48 epoch...
11:22:29.743   Training iter 50, batch loss 0.0431, batch acc 0.9874
11:22:31.777   Training iter 100, batch loss 0.0458, batch acc 0.9834
11:22:33.811   Training iter 150, batch loss 0.0506, batch acc 0.9844
11:22:35.836   Training iter 200, batch loss 0.0525, batch acc 0.9834
11:22:37.864   Training iter 250, batch loss 0.0396, batch acc 0.9886
11:22:39.896   Training iter 300, batch loss 0.0458, batch acc 0.9846
11:22:41.925   Training iter 350, batch loss 0.0332, batch acc 0.9882
11:22:43.961   Training iter 400, batch loss 0.0440, batch acc 0.9874
11:22:45.991   Training iter 450, batch loss 0.0481, batch acc 0.9846
11:22:48.024   Training iter 500, batch loss 0.0467, batch acc 0.9856
11:22:50.058   Training iter 550, batch loss 0.0455, batch acc 0.9870
11:22:52.091   Training iter 600, batch loss 0.0458, batch acc 0.9834
11:22:52.091 Training @ 49 epoch...
11:22:54.128   Training iter 50, batch loss 0.0463, batch acc 0.9848
11:22:56.163   Training iter 100, batch loss 0.0367, batch acc 0.9882
11:22:58.202   Training iter 150, batch loss 0.0410, batch acc 0.9884
11:23:00.233   Training iter 200, batch loss 0.0471, batch acc 0.9854
11:23:02.266   Training iter 250, batch loss 0.0436, batch acc 0.9890
11:23:04.298   Training iter 300, batch loss 0.0464, batch acc 0.9880
11:23:06.327   Training iter 350, batch loss 0.0395, batch acc 0.9882
11:23:08.354   Training iter 400, batch loss 0.0439, batch acc 0.9874
11:23:10.389   Training iter 450, batch loss 0.0487, batch acc 0.9868
11:23:12.417   Training iter 500, batch loss 0.0499, batch acc 0.9836
11:23:14.449   Training iter 550, batch loss 0.0474, batch acc 0.9872
11:23:16.482   Training iter 600, batch loss 0.0419, batch acc 0.9856
11:23:16.483 Training @ 50 epoch...
11:23:18.486   Training iter 50, batch loss 0.0511, batch acc 0.9854
11:23:20.491   Training iter 100, batch loss 0.0368, batch acc 0.9888
11:23:22.519   Training iter 150, batch loss 0.0385, batch acc 0.9882
11:23:24.548   Training iter 200, batch loss 0.0431, batch acc 0.9884
11:23:26.576   Training iter 250, batch loss 0.0434, batch acc 0.9862
11:23:28.603   Training iter 300, batch loss 0.0488, batch acc 0.9846
11:23:30.634   Training iter 350, batch loss 0.0394, batch acc 0.9882
11:23:32.662   Training iter 400, batch loss 0.0414, batch acc 0.9864
11:23:34.691   Training iter 450, batch loss 0.0480, batch acc 0.9846
11:23:36.717   Training iter 500, batch loss 0.0457, batch acc 0.9856
11:23:38.746   Training iter 550, batch loss 0.0507, batch acc 0.9850
11:23:40.773   Training iter 600, batch loss 0.0531, batch acc 0.9832
11:23:40.774 Testing @ 50 epoch...
11:23:41.950     Testing, total mean loss 0.05110, total acc 0.98350
11:23:41.950 Training @ 51 epoch...
11:23:43.985   Training iter 50, batch loss 0.0354, batch acc 0.9916
11:23:46.017   Training iter 100, batch loss 0.0356, batch acc 0.9880
11:23:48.050   Training iter 150, batch loss 0.0432, batch acc 0.9854
11:23:50.080   Training iter 200, batch loss 0.0527, batch acc 0.9856
11:23:52.112   Training iter 250, batch loss 0.0492, batch acc 0.9852
11:23:54.140   Training iter 300, batch loss 0.0381, batch acc 0.9876
11:23:56.166   Training iter 350, batch loss 0.0512, batch acc 0.9834
11:23:58.195   Training iter 400, batch loss 0.0409, batch acc 0.9860
11:24:00.224   Training iter 450, batch loss 0.0415, batch acc 0.9862
11:24:02.256   Training iter 500, batch loss 0.0404, batch acc 0.9870
11:24:04.288   Training iter 550, batch loss 0.0463, batch acc 0.9856
11:24:06.316   Training iter 600, batch loss 0.0596, batch acc 0.9820
11:24:06.317 Training @ 52 epoch...
11:24:08.351   Training iter 50, batch loss 0.0502, batch acc 0.9864
11:24:10.382   Training iter 100, batch loss 0.0494, batch acc 0.9864
11:24:12.412   Training iter 150, batch loss 0.0384, batch acc 0.9874
11:24:14.447   Training iter 200, batch loss 0.0421, batch acc 0.9868
11:24:16.480   Training iter 250, batch loss 0.0432, batch acc 0.9860
11:24:18.499   Training iter 300, batch loss 0.0433, batch acc 0.9866
11:24:20.529   Training iter 350, batch loss 0.0370, batch acc 0.9882
11:24:22.561   Training iter 400, batch loss 0.0512, batch acc 0.9830
11:24:24.591   Training iter 450, batch loss 0.0426, batch acc 0.9866
11:24:26.621   Training iter 500, batch loss 0.0525, batch acc 0.9852
11:24:28.650   Training iter 550, batch loss 0.0426, batch acc 0.9852
11:24:30.680   Training iter 600, batch loss 0.0377, batch acc 0.9862
11:24:30.681 Training @ 53 epoch...
11:24:32.718   Training iter 50, batch loss 0.0425, batch acc 0.9874
11:24:34.748   Training iter 100, batch loss 0.0428, batch acc 0.9872
11:24:36.770   Training iter 150, batch loss 0.0486, batch acc 0.9830
11:24:38.795   Training iter 200, batch loss 0.0349, batch acc 0.9890
11:24:40.826   Training iter 250, batch loss 0.0417, batch acc 0.9878
11:24:42.861   Training iter 300, batch loss 0.0463, batch acc 0.9868
11:24:44.891   Training iter 350, batch loss 0.0456, batch acc 0.9858
11:24:46.922   Training iter 400, batch loss 0.0517, batch acc 0.9842
11:24:48.954   Training iter 450, batch loss 0.0417, batch acc 0.9858
11:24:50.988   Training iter 500, batch loss 0.0427, batch acc 0.9874
11:24:53.019   Training iter 550, batch loss 0.0419, batch acc 0.9880
11:24:55.055   Training iter 600, batch loss 0.0467, batch acc 0.9892
11:24:55.056 Training @ 54 epoch...
11:24:57.082   Training iter 50, batch loss 0.0409, batch acc 0.9870
11:24:59.114   Training iter 100, batch loss 0.0401, batch acc 0.9872
11:25:01.149   Training iter 150, batch loss 0.0478, batch acc 0.9836
11:25:03.181   Training iter 200, batch loss 0.0386, batch acc 0.9888
11:25:05.219   Training iter 250, batch loss 0.0418, batch acc 0.9888
11:25:07.251   Training iter 300, batch loss 0.0350, batch acc 0.9888
11:25:09.284   Training iter 350, batch loss 0.0472, batch acc 0.9866
11:25:11.310   Training iter 400, batch loss 0.0465, batch acc 0.9860
11:25:13.342   Training iter 450, batch loss 0.0524, batch acc 0.9850
11:25:15.378   Training iter 500, batch loss 0.0425, batch acc 0.9856
11:25:17.407   Training iter 550, batch loss 0.0424, batch acc 0.9848
11:25:19.442   Training iter 600, batch loss 0.0546, batch acc 0.9824
11:25:19.443 Training @ 55 epoch...
11:25:21.475   Training iter 50, batch loss 0.0437, batch acc 0.9856
11:25:23.505   Training iter 100, batch loss 0.0355, batch acc 0.9908
11:25:25.533   Training iter 150, batch loss 0.0418, batch acc 0.9874
11:25:27.561   Training iter 200, batch loss 0.0397, batch acc 0.9874
11:25:29.590   Training iter 250, batch loss 0.0550, batch acc 0.9822
11:25:31.622   Training iter 300, batch loss 0.0324, batch acc 0.9898
11:25:33.646   Training iter 350, batch loss 0.0463, batch acc 0.9860
11:25:35.679   Training iter 400, batch loss 0.0430, batch acc 0.9876
11:25:37.703   Training iter 450, batch loss 0.0398, batch acc 0.9874
11:25:39.730   Training iter 500, batch loss 0.0493, batch acc 0.9858
11:25:41.761   Training iter 550, batch loss 0.0552, batch acc 0.9828
11:25:43.786   Training iter 600, batch loss 0.0399, batch acc 0.9880
11:25:43.787 Testing @ 55 epoch...
11:25:44.967     Testing, total mean loss 0.04726, total acc 0.98430
11:25:44.967 Training @ 56 epoch...
11:25:47.002   Training iter 50, batch loss 0.0488, batch acc 0.9852
11:25:49.024   Training iter 100, batch loss 0.0469, batch acc 0.9866
11:25:51.052   Training iter 150, batch loss 0.0406, batch acc 0.9890
11:25:53.081   Training iter 200, batch loss 0.0476, batch acc 0.9864
11:25:55.112   Training iter 250, batch loss 0.0400, batch acc 0.9890
11:25:57.139   Training iter 300, batch loss 0.0377, batch acc 0.9882
11:25:59.176   Training iter 350, batch loss 0.0462, batch acc 0.9868
11:26:01.201   Training iter 400, batch loss 0.0444, batch acc 0.9862
11:26:03.230   Training iter 450, batch loss 0.0518, batch acc 0.9862
11:26:05.260   Training iter 500, batch loss 0.0379, batch acc 0.9882
11:26:07.273   Training iter 550, batch loss 0.0375, batch acc 0.9860
11:26:09.300   Training iter 600, batch loss 0.0399, batch acc 0.9870
11:26:09.301 Training @ 57 epoch...
11:26:11.330   Training iter 50, batch loss 0.0376, batch acc 0.9898
11:26:13.352   Training iter 100, batch loss 0.0388, batch acc 0.9874
11:26:15.384   Training iter 150, batch loss 0.0422, batch acc 0.9874
11:26:17.410   Training iter 200, batch loss 0.0363, batch acc 0.9884
11:26:19.438   Training iter 250, batch loss 0.0432, batch acc 0.9874
11:26:21.461   Training iter 300, batch loss 0.0449, batch acc 0.9872
11:26:23.482   Training iter 350, batch loss 0.0527, batch acc 0.9844
11:26:25.510   Training iter 400, batch loss 0.0506, batch acc 0.9824
11:26:27.542   Training iter 450, batch loss 0.0442, batch acc 0.9850
11:26:29.569   Training iter 500, batch loss 0.0446, batch acc 0.9846
11:26:31.599   Training iter 550, batch loss 0.0408, batch acc 0.9848
11:26:33.633   Training iter 600, batch loss 0.0415, batch acc 0.9878
11:26:33.634 Training @ 58 epoch...
11:26:35.668   Training iter 50, batch loss 0.0401, batch acc 0.9864
11:26:37.697   Training iter 100, batch loss 0.0416, batch acc 0.9846
11:26:39.724   Training iter 150, batch loss 0.0454, batch acc 0.9874
11:26:41.751   Training iter 200, batch loss 0.0452, batch acc 0.9864
11:26:43.783   Training iter 250, batch loss 0.0443, batch acc 0.9872
11:26:45.809   Training iter 300, batch loss 0.0472, batch acc 0.9850
11:26:47.840   Training iter 350, batch loss 0.0432, batch acc 0.9876
11:26:49.872   Training iter 400, batch loss 0.0401, batch acc 0.9872
11:26:51.900   Training iter 450, batch loss 0.0427, batch acc 0.9882
11:26:53.930   Training iter 500, batch loss 0.0384, batch acc 0.9882
11:26:55.959   Training iter 550, batch loss 0.0396, batch acc 0.9874
11:26:57.986   Training iter 600, batch loss 0.0495, batch acc 0.9874
11:26:57.987 Training @ 59 epoch...
11:27:00.015   Training iter 50, batch loss 0.0404, batch acc 0.9886
11:27:02.041   Training iter 100, batch loss 0.0426, batch acc 0.9860
11:27:04.072   Training iter 150, batch loss 0.0369, batch acc 0.9882
11:27:06.107   Training iter 200, batch loss 0.0425, batch acc 0.9862
11:27:08.136   Training iter 250, batch loss 0.0510, batch acc 0.9846
11:27:10.170   Training iter 300, batch loss 0.0425, batch acc 0.9858
11:27:12.193   Training iter 350, batch loss 0.0460, batch acc 0.9866
11:27:14.219   Training iter 400, batch loss 0.0440, batch acc 0.9864
11:27:16.247   Training iter 450, batch loss 0.0390, batch acc 0.9872
11:27:18.278   Training iter 500, batch loss 0.0414, batch acc 0.9876
11:27:20.306   Training iter 550, batch loss 0.0468, batch acc 0.9858
11:27:22.339   Training iter 600, batch loss 0.0420, batch acc 0.9854
11:27:22.340 Training @ 60 epoch...
11:27:24.374   Training iter 50, batch loss 0.0373, batch acc 0.9906
11:27:26.409   Training iter 100, batch loss 0.0494, batch acc 0.9842
11:27:28.432   Training iter 150, batch loss 0.0477, batch acc 0.9856
11:27:30.461   Training iter 200, batch loss 0.0450, batch acc 0.9852
11:27:32.483   Training iter 250, batch loss 0.0396, batch acc 0.9880
11:27:34.516   Training iter 300, batch loss 0.0373, batch acc 0.9884
11:27:36.549   Training iter 350, batch loss 0.0424, batch acc 0.9876
11:27:38.553   Training iter 400, batch loss 0.0397, batch acc 0.9872
11:27:40.578   Training iter 450, batch loss 0.0399, batch acc 0.9884
11:27:42.600   Training iter 500, batch loss 0.0437, batch acc 0.9870
11:27:44.631   Training iter 550, batch loss 0.0496, batch acc 0.9852
11:27:46.657   Training iter 600, batch loss 0.0411, batch acc 0.9858
11:27:46.658 Testing @ 60 epoch...
11:27:47.834     Testing, total mean loss 0.04574, total acc 0.98520
11:27:47.834 Training @ 61 epoch...
11:27:49.860   Training iter 50, batch loss 0.0430, batch acc 0.9866
11:27:51.884   Training iter 100, batch loss 0.0324, batch acc 0.9892
11:27:53.916   Training iter 150, batch loss 0.0460, batch acc 0.9870
11:27:55.943   Training iter 200, batch loss 0.0355, batch acc 0.9876
11:27:57.970   Training iter 250, batch loss 0.0427, batch acc 0.9854
11:28:00.000   Training iter 300, batch loss 0.0418, batch acc 0.9872
11:28:02.032   Training iter 350, batch loss 0.0397, batch acc 0.9878
11:28:04.057   Training iter 400, batch loss 0.0472, batch acc 0.9862
11:28:06.082   Training iter 450, batch loss 0.0404, batch acc 0.9874
11:28:08.111   Training iter 500, batch loss 0.0532, batch acc 0.9842
11:28:10.136   Training iter 550, batch loss 0.0457, batch acc 0.9862
11:28:12.162   Training iter 600, batch loss 0.0419, batch acc 0.9858
11:28:12.163 Training @ 62 epoch...
11:28:14.181   Training iter 50, batch loss 0.0475, batch acc 0.9852
11:28:16.207   Training iter 100, batch loss 0.0341, batch acc 0.9902
11:28:18.237   Training iter 150, batch loss 0.0503, batch acc 0.9846
11:28:20.264   Training iter 200, batch loss 0.0383, batch acc 0.9870
11:28:22.297   Training iter 250, batch loss 0.0363, batch acc 0.9886
11:28:24.322   Training iter 300, batch loss 0.0444, batch acc 0.9850
11:28:26.355   Training iter 350, batch loss 0.0414, batch acc 0.9866
11:28:28.384   Training iter 400, batch loss 0.0432, batch acc 0.9862
11:28:30.414   Training iter 450, batch loss 0.0471, batch acc 0.9880
11:28:32.442   Training iter 500, batch loss 0.0462, batch acc 0.9854
11:28:34.471   Training iter 550, batch loss 0.0408, batch acc 0.9888
11:28:36.501   Training iter 600, batch loss 0.0360, batch acc 0.9892
11:28:36.502 Training @ 63 epoch...
11:28:38.525   Training iter 50, batch loss 0.0548, batch acc 0.9836
11:28:40.558   Training iter 100, batch loss 0.0446, batch acc 0.9870
11:28:42.593   Training iter 150, batch loss 0.0469, batch acc 0.9844
11:28:44.621   Training iter 200, batch loss 0.0347, batch acc 0.9900
11:28:46.652   Training iter 250, batch loss 0.0491, batch acc 0.9864
11:28:48.687   Training iter 300, batch loss 0.0385, batch acc 0.9888
11:28:50.711   Training iter 350, batch loss 0.0421, batch acc 0.9856
11:28:52.745   Training iter 400, batch loss 0.0410, batch acc 0.9874
11:28:54.765   Training iter 450, batch loss 0.0426, batch acc 0.9872
11:28:56.793   Training iter 500, batch loss 0.0368, batch acc 0.9882
11:28:58.819   Training iter 550, batch loss 0.0369, batch acc 0.9896
11:29:00.855   Training iter 600, batch loss 0.0381, batch acc 0.9884
11:29:00.856 Training @ 64 epoch...
11:29:02.886   Training iter 50, batch loss 0.0365, batch acc 0.9896
11:29:04.915   Training iter 100, batch loss 0.0353, batch acc 0.9884
11:29:06.950   Training iter 150, batch loss 0.0395, batch acc 0.9882
11:29:08.979   Training iter 200, batch loss 0.0436, batch acc 0.9882
11:29:11.011   Training iter 250, batch loss 0.0505, batch acc 0.9854
11:29:13.033   Training iter 300, batch loss 0.0416, batch acc 0.9866
11:29:15.065   Training iter 350, batch loss 0.0429, batch acc 0.9864
11:29:17.098   Training iter 400, batch loss 0.0375, batch acc 0.9890
11:29:19.129   Training iter 450, batch loss 0.0401, batch acc 0.9860
11:29:21.158   Training iter 500, batch loss 0.0459, batch acc 0.9848
11:29:23.194   Training iter 550, batch loss 0.0459, batch acc 0.9854
11:29:25.221   Training iter 600, batch loss 0.0442, batch acc 0.9876
11:29:25.222 Training @ 65 epoch...
11:29:27.254   Training iter 50, batch loss 0.0381, batch acc 0.9892
11:29:29.288   Training iter 100, batch loss 0.0472, batch acc 0.9852
11:29:31.313   Training iter 150, batch loss 0.0448, batch acc 0.9864
11:29:33.341   Training iter 200, batch loss 0.0400, batch acc 0.9876
11:29:35.370   Training iter 250, batch loss 0.0404, batch acc 0.9868
11:29:37.409   Training iter 300, batch loss 0.0467, batch acc 0.9858
11:29:39.436   Training iter 350, batch loss 0.0412, batch acc 0.9870
11:29:41.473   Training iter 400, batch loss 0.0373, batch acc 0.9882
11:29:43.503   Training iter 450, batch loss 0.0423, batch acc 0.9880
11:29:45.540   Training iter 500, batch loss 0.0372, batch acc 0.9860
11:29:47.572   Training iter 550, batch loss 0.0380, batch acc 0.9874
11:29:49.606   Training iter 600, batch loss 0.0483, batch acc 0.9858
11:29:49.607 Testing @ 65 epoch...
11:29:50.786     Testing, total mean loss 0.04574, total acc 0.98520
11:29:50.786 Training @ 66 epoch...
11:29:52.822   Training iter 50, batch loss 0.0337, batch acc 0.9900
11:29:54.859   Training iter 100, batch loss 0.0401, batch acc 0.9862
11:29:56.885   Training iter 150, batch loss 0.0484, batch acc 0.9846
11:29:58.917   Training iter 200, batch loss 0.0446, batch acc 0.9868
11:30:00.948   Training iter 250, batch loss 0.0423, batch acc 0.9878
11:30:02.981   Training iter 300, batch loss 0.0401, batch acc 0.9864
11:30:05.010   Training iter 350, batch loss 0.0366, batch acc 0.9874
11:30:07.041   Training iter 400, batch loss 0.0442, batch acc 0.9870
11:30:09.076   Training iter 450, batch loss 0.0404, batch acc 0.9888
11:30:11.105   Training iter 500, batch loss 0.0435, batch acc 0.9864
11:30:13.130   Training iter 550, batch loss 0.0410, batch acc 0.9860
11:30:15.163   Training iter 600, batch loss 0.0436, batch acc 0.9860
11:30:15.164 Training @ 67 epoch...
11:30:17.199   Training iter 50, batch loss 0.0412, batch acc 0.9868
11:30:19.238   Training iter 100, batch loss 0.0398, batch acc 0.9862
11:30:21.270   Training iter 150, batch loss 0.0354, batch acc 0.9886
11:30:23.302   Training iter 200, batch loss 0.0395, batch acc 0.9872
11:30:25.333   Training iter 250, batch loss 0.0496, batch acc 0.9882
11:30:27.360   Training iter 300, batch loss 0.0395, batch acc 0.9868
11:30:29.391   Training iter 350, batch loss 0.0353, batch acc 0.9896
11:30:31.414   Training iter 400, batch loss 0.0388, batch acc 0.9890
11:30:33.445   Training iter 450, batch loss 0.0464, batch acc 0.9864
11:30:35.481   Training iter 500, batch loss 0.0436, batch acc 0.9858
11:30:37.509   Training iter 550, batch loss 0.0494, batch acc 0.9858
11:30:39.536   Training iter 600, batch loss 0.0395, batch acc 0.9874
11:30:39.537 Training @ 68 epoch...
11:30:41.573   Training iter 50, batch loss 0.0303, batch acc 0.9910
11:30:43.607   Training iter 100, batch loss 0.0426, batch acc 0.9860
11:30:45.632   Training iter 150, batch loss 0.0365, batch acc 0.9882
11:30:47.668   Training iter 200, batch loss 0.0368, batch acc 0.9890
11:30:49.702   Training iter 250, batch loss 0.0368, batch acc 0.9872
11:30:51.732   Training iter 300, batch loss 0.0385, batch acc 0.9858
11:30:53.763   Training iter 350, batch loss 0.0455, batch acc 0.9862
11:30:55.799   Training iter 400, batch loss 0.0423, batch acc 0.9868
11:30:57.829   Training iter 450, batch loss 0.0489, batch acc 0.9848
11:30:59.859   Training iter 500, batch loss 0.0432, batch acc 0.9860
11:31:01.891   Training iter 550, batch loss 0.0496, batch acc 0.9866
11:31:03.922   Training iter 600, batch loss 0.0444, batch acc 0.9884
11:31:03.923 Training @ 69 epoch...
11:31:05.947   Training iter 50, batch loss 0.0434, batch acc 0.9882
11:31:07.980   Training iter 100, batch loss 0.0436, batch acc 0.9858
11:31:10.014   Training iter 150, batch loss 0.0460, batch acc 0.9862
11:31:12.048   Training iter 200, batch loss 0.0362, batch acc 0.9890
11:31:14.086   Training iter 250, batch loss 0.0421, batch acc 0.9858
11:31:16.109   Training iter 300, batch loss 0.0332, batch acc 0.9912
11:31:18.145   Training iter 350, batch loss 0.0426, batch acc 0.9866
11:31:20.179   Training iter 400, batch loss 0.0418, batch acc 0.9880
11:31:22.212   Training iter 450, batch loss 0.0394, batch acc 0.9864
11:31:24.248   Training iter 500, batch loss 0.0373, batch acc 0.9882
11:31:26.281   Training iter 550, batch loss 0.0422, batch acc 0.9856
11:31:28.305   Training iter 600, batch loss 0.0455, batch acc 0.9838
11:31:28.306 Training @ 70 epoch...
11:31:30.332   Training iter 50, batch loss 0.0439, batch acc 0.9880
11:31:32.366   Training iter 100, batch loss 0.0397, batch acc 0.9878
11:31:34.397   Training iter 150, batch loss 0.0390, batch acc 0.9872
11:31:36.430   Training iter 200, batch loss 0.0520, batch acc 0.9834
11:31:38.452   Training iter 250, batch loss 0.0390, batch acc 0.9848
11:31:40.472   Training iter 300, batch loss 0.0408, batch acc 0.9862
11:31:42.500   Training iter 350, batch loss 0.0420, batch acc 0.9892
11:31:44.529   Training iter 400, batch loss 0.0362, batch acc 0.9884
11:31:46.551   Training iter 450, batch loss 0.0402, batch acc 0.9864
11:31:48.581   Training iter 500, batch loss 0.0486, batch acc 0.9856
11:31:50.608   Training iter 550, batch loss 0.0363, batch acc 0.9884
11:31:52.638   Training iter 600, batch loss 0.0342, batch acc 0.9886
11:31:52.639 Testing @ 70 epoch...
11:31:53.814     Testing, total mean loss 0.04555, total acc 0.98560
11:31:53.814 Training @ 71 epoch...
11:31:55.857   Training iter 50, batch loss 0.0428, batch acc 0.9856
11:31:57.889   Training iter 100, batch loss 0.0445, batch acc 0.9864
11:31:59.923   Training iter 150, batch loss 0.0408, batch acc 0.9894
11:32:01.958   Training iter 200, batch loss 0.0392, batch acc 0.9876
11:32:03.996   Training iter 250, batch loss 0.0346, batch acc 0.9880
11:32:06.031   Training iter 300, batch loss 0.0367, batch acc 0.9904
11:32:08.066   Training iter 350, batch loss 0.0385, batch acc 0.9882
11:32:10.095   Training iter 400, batch loss 0.0365, batch acc 0.9892
11:32:12.128   Training iter 450, batch loss 0.0443, batch acc 0.9848
11:32:14.166   Training iter 500, batch loss 0.0509, batch acc 0.9828
11:32:16.193   Training iter 550, batch loss 0.0370, batch acc 0.9880
11:32:18.231   Training iter 600, batch loss 0.0404, batch acc 0.9874
11:32:18.232 Training @ 72 epoch...
11:32:20.248   Training iter 50, batch loss 0.0472, batch acc 0.9866
11:32:22.275   Training iter 100, batch loss 0.0381, batch acc 0.9860
11:32:24.309   Training iter 150, batch loss 0.0407, batch acc 0.9856
11:32:26.337   Training iter 200, batch loss 0.0413, batch acc 0.9880
11:32:28.369   Training iter 250, batch loss 0.0482, batch acc 0.9858
11:32:30.395   Training iter 300, batch loss 0.0366, batch acc 0.9898
11:32:32.422   Training iter 350, batch loss 0.0384, batch acc 0.9874
11:32:34.449   Training iter 400, batch loss 0.0476, batch acc 0.9870
11:32:36.481   Training iter 450, batch loss 0.0351, batch acc 0.9884
11:32:38.510   Training iter 500, batch loss 0.0438, batch acc 0.9856
11:32:40.541   Training iter 550, batch loss 0.0364, batch acc 0.9896
11:32:42.572   Training iter 600, batch loss 0.0373, batch acc 0.9896
11:32:42.572 Training @ 73 epoch...
11:32:44.601   Training iter 50, batch loss 0.0362, batch acc 0.9878
11:32:46.641   Training iter 100, batch loss 0.0413, batch acc 0.9874
11:32:48.682   Training iter 150, batch loss 0.0404, batch acc 0.9848
11:32:50.717   Training iter 200, batch loss 0.0500, batch acc 0.9830
11:32:52.750   Training iter 250, batch loss 0.0391, batch acc 0.9898
11:32:54.774   Training iter 300, batch loss 0.0346, batch acc 0.9906
11:32:56.803   Training iter 350, batch loss 0.0370, batch acc 0.9874
11:32:58.835   Training iter 400, batch loss 0.0402, batch acc 0.9890
11:33:00.866   Training iter 450, batch loss 0.0428, batch acc 0.9848
11:33:02.896   Training iter 500, batch loss 0.0429, batch acc 0.9872
11:33:04.925   Training iter 550, batch loss 0.0394, batch acc 0.9878
11:33:06.957   Training iter 600, batch loss 0.0418, batch acc 0.9866
11:33:06.958 Training @ 74 epoch...
11:33:08.990   Training iter 50, batch loss 0.0372, batch acc 0.9884
11:33:11.014   Training iter 100, batch loss 0.0453, batch acc 0.9848
11:33:13.040   Training iter 150, batch loss 0.0437, batch acc 0.9862
11:33:15.065   Training iter 200, batch loss 0.0309, batch acc 0.9882
11:33:17.092   Training iter 250, batch loss 0.0417, batch acc 0.9876
11:33:19.127   Training iter 300, batch loss 0.0441, batch acc 0.9854
11:33:21.157   Training iter 350, batch loss 0.0383, batch acc 0.9890
11:33:23.185   Training iter 400, batch loss 0.0422, batch acc 0.9882
11:33:25.217   Training iter 450, batch loss 0.0417, batch acc 0.9868
11:33:27.246   Training iter 500, batch loss 0.0348, batch acc 0.9880
11:33:29.273   Training iter 550, batch loss 0.0423, batch acc 0.9886
11:33:31.306   Training iter 600, batch loss 0.0445, batch acc 0.9848
11:33:31.307 Training @ 75 epoch...
11:33:33.339   Training iter 50, batch loss 0.0400, batch acc 0.9860
11:33:35.362   Training iter 100, batch loss 0.0303, batch acc 0.9906
11:33:37.390   Training iter 150, batch loss 0.0411, batch acc 0.9878
11:33:39.416   Training iter 200, batch loss 0.0470, batch acc 0.9874
11:33:41.444   Training iter 250, batch loss 0.0388, batch acc 0.9876
11:33:43.471   Training iter 300, batch loss 0.0381, batch acc 0.9880
11:33:45.501   Training iter 350, batch loss 0.0446, batch acc 0.9868
11:33:47.528   Training iter 400, batch loss 0.0387, batch acc 0.9874
11:33:49.557   Training iter 450, batch loss 0.0466, batch acc 0.9848
11:33:51.585   Training iter 500, batch loss 0.0380, batch acc 0.9890
11:33:53.612   Training iter 550, batch loss 0.0351, batch acc 0.9890
11:33:55.641   Training iter 600, batch loss 0.0372, batch acc 0.9878
11:33:55.642 Testing @ 75 epoch...
11:33:56.818     Testing, total mean loss 0.04386, total acc 0.98530
11:33:56.818 Training @ 76 epoch...
11:33:58.857   Training iter 50, batch loss 0.0405, batch acc 0.9874
11:34:00.887   Training iter 100, batch loss 0.0385, batch acc 0.9894
11:34:02.923   Training iter 150, batch loss 0.0349, batch acc 0.9894
11:34:04.955   Training iter 200, batch loss 0.0391, batch acc 0.9876
11:34:06.990   Training iter 250, batch loss 0.0329, batch acc 0.9890
11:34:09.020   Training iter 300, batch loss 0.0384, batch acc 0.9868
11:34:11.049   Training iter 350, batch loss 0.0466, batch acc 0.9884
11:34:13.086   Training iter 400, batch loss 0.0461, batch acc 0.9872
11:34:15.122   Training iter 450, batch loss 0.0428, batch acc 0.9874
11:34:17.156   Training iter 500, batch loss 0.0412, batch acc 0.9866
11:34:19.192   Training iter 550, batch loss 0.0435, batch acc 0.9862
11:34:21.225   Training iter 600, batch loss 0.0374, batch acc 0.9888
11:34:21.226 Training @ 77 epoch...
11:34:23.261   Training iter 50, batch loss 0.0476, batch acc 0.9874
11:34:25.289   Training iter 100, batch loss 0.0390, batch acc 0.9878
11:34:27.318   Training iter 150, batch loss 0.0307, batch acc 0.9886
11:34:29.348   Training iter 200, batch loss 0.0431, batch acc 0.9878
11:34:31.377   Training iter 250, batch loss 0.0330, batch acc 0.9910
11:34:33.407   Training iter 300, batch loss 0.0484, batch acc 0.9868
11:34:35.436   Training iter 350, batch loss 0.0348, batch acc 0.9884
11:34:37.469   Training iter 400, batch loss 0.0493, batch acc 0.9822
11:34:39.500   Training iter 450, batch loss 0.0428, batch acc 0.9846
11:34:41.529   Training iter 500, batch loss 0.0318, batch acc 0.9890
11:34:43.556   Training iter 550, batch loss 0.0452, batch acc 0.9878
11:34:45.587   Training iter 600, batch loss 0.0380, batch acc 0.9886
11:34:45.588 Training @ 78 epoch...
11:34:47.622   Training iter 50, batch loss 0.0342, batch acc 0.9880
11:34:49.655   Training iter 100, batch loss 0.0403, batch acc 0.9864
11:34:51.686   Training iter 150, batch loss 0.0400, batch acc 0.9878
11:34:53.720   Training iter 200, batch loss 0.0345, batch acc 0.9892
11:34:55.749   Training iter 250, batch loss 0.0391, batch acc 0.9876
11:34:57.782   Training iter 300, batch loss 0.0393, batch acc 0.9872
11:34:59.812   Training iter 350, batch loss 0.0350, batch acc 0.9868
11:35:01.841   Training iter 400, batch loss 0.0406, batch acc 0.9868
11:35:03.872   Training iter 450, batch loss 0.0460, batch acc 0.9864
11:35:05.902   Training iter 500, batch loss 0.0494, batch acc 0.9854
11:35:07.931   Training iter 550, batch loss 0.0414, batch acc 0.9870
11:35:09.961   Training iter 600, batch loss 0.0324, batch acc 0.9896
11:35:09.962 Training @ 79 epoch...
11:35:11.990   Training iter 50, batch loss 0.0313, batch acc 0.9884
11:35:14.021   Training iter 100, batch loss 0.0322, batch acc 0.9894
11:35:16.052   Training iter 150, batch loss 0.0475, batch acc 0.9848
11:35:18.082   Training iter 200, batch loss 0.0413, batch acc 0.9880
11:35:20.113   Training iter 250, batch loss 0.0333, batch acc 0.9886
11:35:22.144   Training iter 300, batch loss 0.0368, batch acc 0.9876
11:35:24.174   Training iter 350, batch loss 0.0451, batch acc 0.9872
11:35:26.207   Training iter 400, batch loss 0.0449, batch acc 0.9878
11:35:28.239   Training iter 450, batch loss 0.0429, batch acc 0.9870
11:35:30.271   Training iter 500, batch loss 0.0452, batch acc 0.9858
11:35:32.299   Training iter 550, batch loss 0.0385, batch acc 0.9872
11:35:34.330   Training iter 600, batch loss 0.0317, batch acc 0.9894
11:35:34.331 Training @ 80 epoch...
11:35:36.362   Training iter 50, batch loss 0.0418, batch acc 0.9872
11:35:38.392   Training iter 100, batch loss 0.0414, batch acc 0.9862
11:35:40.421   Training iter 150, batch loss 0.0389, batch acc 0.9872
11:35:42.450   Training iter 200, batch loss 0.0377, batch acc 0.9888
11:35:44.479   Training iter 250, batch loss 0.0364, batch acc 0.9870
11:35:46.509   Training iter 300, batch loss 0.0454, batch acc 0.9858
11:35:48.541   Training iter 350, batch loss 0.0355, batch acc 0.9890
11:35:50.572   Training iter 400, batch loss 0.0399, batch acc 0.9862
11:35:52.602   Training iter 450, batch loss 0.0394, batch acc 0.9864
11:35:54.630   Training iter 500, batch loss 0.0370, batch acc 0.9876
11:35:56.661   Training iter 550, batch loss 0.0375, batch acc 0.9882
11:35:58.691   Training iter 600, batch loss 0.0453, batch acc 0.9864
11:35:58.692 Testing @ 80 epoch...
11:35:59.870     Testing, total mean loss 0.04581, total acc 0.98510
11:35:59.870 Training @ 81 epoch...
11:36:01.902   Training iter 50, batch loss 0.0404, batch acc 0.9878
11:36:03.929   Training iter 100, batch loss 0.0362, batch acc 0.9890
11:36:05.950   Training iter 150, batch loss 0.0434, batch acc 0.9868
11:36:07.980   Training iter 200, batch loss 0.0404, batch acc 0.9872
11:36:10.009   Training iter 250, batch loss 0.0360, batch acc 0.9878
11:36:12.031   Training iter 300, batch loss 0.0445, batch acc 0.9874
11:36:14.056   Training iter 350, batch loss 0.0370, batch acc 0.9878
11:36:16.060   Training iter 400, batch loss 0.0395, batch acc 0.9886
11:36:18.080   Training iter 450, batch loss 0.0352, batch acc 0.9890
11:36:20.109   Training iter 500, batch loss 0.0452, batch acc 0.9864
11:36:22.141   Training iter 550, batch loss 0.0413, batch acc 0.9880
11:36:24.170   Training iter 600, batch loss 0.0330, batch acc 0.9880
11:36:24.171 Training @ 82 epoch...
11:36:26.209   Training iter 50, batch loss 0.0462, batch acc 0.9840
11:36:28.234   Training iter 100, batch loss 0.0365, batch acc 0.9888
11:36:30.268   Training iter 150, batch loss 0.0335, batch acc 0.9894
11:36:32.297   Training iter 200, batch loss 0.0416, batch acc 0.9872
11:36:34.324   Training iter 250, batch loss 0.0374, batch acc 0.9886
11:36:36.353   Training iter 300, batch loss 0.0334, batch acc 0.9892
11:36:38.384   Training iter 350, batch loss 0.0398, batch acc 0.9868
11:36:40.411   Training iter 400, batch loss 0.0471, batch acc 0.9852
11:36:42.433   Training iter 450, batch loss 0.0390, batch acc 0.9890
11:36:44.459   Training iter 500, batch loss 0.0384, batch acc 0.9854
11:36:46.482   Training iter 550, batch loss 0.0439, batch acc 0.9856
11:36:48.510   Training iter 600, batch loss 0.0348, batch acc 0.9874
11:36:48.511 Training @ 83 epoch...
11:36:50.541   Training iter 50, batch loss 0.0396, batch acc 0.9892
11:36:52.564   Training iter 100, batch loss 0.0310, batch acc 0.9904
11:36:54.591   Training iter 150, batch loss 0.0455, batch acc 0.9856
11:36:56.618   Training iter 200, batch loss 0.0384, batch acc 0.9872
11:36:58.642   Training iter 250, batch loss 0.0377, batch acc 0.9886
11:37:00.667   Training iter 300, batch loss 0.0374, batch acc 0.9892
11:37:02.692   Training iter 350, batch loss 0.0446, batch acc 0.9868
11:37:04.722   Training iter 400, batch loss 0.0331, batch acc 0.9882
11:37:06.748   Training iter 450, batch loss 0.0343, batch acc 0.9886
11:37:08.771   Training iter 500, batch loss 0.0432, batch acc 0.9882
11:37:10.793   Training iter 550, batch loss 0.0412, batch acc 0.9878
11:37:12.822   Training iter 600, batch loss 0.0429, batch acc 0.9854
11:37:12.823 Training @ 84 epoch...
11:37:14.851   Training iter 50, batch loss 0.0428, batch acc 0.9876
11:37:16.880   Training iter 100, batch loss 0.0421, batch acc 0.9870
11:37:18.910   Training iter 150, batch loss 0.0347, batch acc 0.9876
11:37:20.939   Training iter 200, batch loss 0.0338, batch acc 0.9890
11:37:22.970   Training iter 250, batch loss 0.0360, batch acc 0.9886
11:37:24.999   Training iter 300, batch loss 0.0379, batch acc 0.9874
11:37:27.025   Training iter 350, batch loss 0.0451, batch acc 0.9840
11:37:29.054   Training iter 400, batch loss 0.0429, batch acc 0.9886
11:37:31.088   Training iter 450, batch loss 0.0339, batch acc 0.9890
11:37:33.120   Training iter 500, batch loss 0.0279, batch acc 0.9916
11:37:35.149   Training iter 550, batch loss 0.0480, batch acc 0.9856
11:37:37.180   Training iter 600, batch loss 0.0412, batch acc 0.9866
11:37:37.181 Training @ 85 epoch...
11:37:39.217   Training iter 50, batch loss 0.0374, batch acc 0.9888
11:37:41.247   Training iter 100, batch loss 0.0314, batch acc 0.9898
11:37:43.273   Training iter 150, batch loss 0.0413, batch acc 0.9860
11:37:45.301   Training iter 200, batch loss 0.0308, batch acc 0.9904
11:37:47.332   Training iter 250, batch loss 0.0383, batch acc 0.9882
11:37:49.349   Training iter 300, batch loss 0.0364, batch acc 0.9888
11:37:51.370   Training iter 350, batch loss 0.0430, batch acc 0.9868
11:37:53.395   Training iter 400, batch loss 0.0419, batch acc 0.9858
11:37:55.427   Training iter 450, batch loss 0.0458, batch acc 0.9832
11:37:57.455   Training iter 500, batch loss 0.0424, batch acc 0.9892
11:37:59.488   Training iter 550, batch loss 0.0400, batch acc 0.9880
11:38:01.511   Training iter 600, batch loss 0.0368, batch acc 0.9900
11:38:01.512 Testing @ 85 epoch...
11:38:02.685     Testing, total mean loss 0.04333, total acc 0.98550
11:38:02.685 Training @ 86 epoch...
11:38:04.717   Training iter 50, batch loss 0.0395, batch acc 0.9876
11:38:06.742   Training iter 100, batch loss 0.0305, batch acc 0.9888
11:38:08.769   Training iter 150, batch loss 0.0382, batch acc 0.9890
11:38:10.798   Training iter 200, batch loss 0.0350, batch acc 0.9888
11:38:12.829   Training iter 250, batch loss 0.0425, batch acc 0.9850
11:38:14.852   Training iter 300, batch loss 0.0420, batch acc 0.9876
11:38:16.882   Training iter 350, batch loss 0.0347, batch acc 0.9888
11:38:18.907   Training iter 400, batch loss 0.0413, batch acc 0.9864
11:38:20.933   Training iter 450, batch loss 0.0358, batch acc 0.9884
11:38:22.966   Training iter 500, batch loss 0.0381, batch acc 0.9884
11:38:24.997   Training iter 550, batch loss 0.0447, batch acc 0.9878
11:38:27.026   Training iter 600, batch loss 0.0404, batch acc 0.9880
11:38:27.027 Training @ 87 epoch...
11:38:29.062   Training iter 50, batch loss 0.0393, batch acc 0.9884
11:38:31.093   Training iter 100, batch loss 0.0431, batch acc 0.9854
11:38:33.126   Training iter 150, batch loss 0.0360, batch acc 0.9868
11:38:35.156   Training iter 200, batch loss 0.0436, batch acc 0.9860
11:38:37.192   Training iter 250, batch loss 0.0345, batch acc 0.9890
11:38:39.221   Training iter 300, batch loss 0.0433, batch acc 0.9866
11:38:41.250   Training iter 350, batch loss 0.0415, batch acc 0.9866
11:38:43.273   Training iter 400, batch loss 0.0400, batch acc 0.9872
11:38:45.292   Training iter 450, batch loss 0.0420, batch acc 0.9874
11:38:47.303   Training iter 500, batch loss 0.0330, batch acc 0.9894
11:38:49.325   Training iter 550, batch loss 0.0337, batch acc 0.9886
11:38:51.345   Training iter 600, batch loss 0.0388, batch acc 0.9858
11:38:51.346 Training @ 88 epoch...
11:38:53.370   Training iter 50, batch loss 0.0392, batch acc 0.9868
11:38:55.369   Training iter 100, batch loss 0.0411, batch acc 0.9880
11:38:57.387   Training iter 150, batch loss 0.0445, batch acc 0.9870
11:38:59.407   Training iter 200, batch loss 0.0374, batch acc 0.9862
11:39:01.431   Training iter 250, batch loss 0.0384, batch acc 0.9884
11:39:03.457   Training iter 300, batch loss 0.0306, batch acc 0.9912
11:39:05.480   Training iter 350, batch loss 0.0346, batch acc 0.9890
11:39:07.479   Training iter 400, batch loss 0.0403, batch acc 0.9864
11:39:09.479   Training iter 450, batch loss 0.0379, batch acc 0.9866
11:39:11.478   Training iter 500, batch loss 0.0338, batch acc 0.9896
11:39:13.490   Training iter 550, batch loss 0.0458, batch acc 0.9864
11:39:15.513   Training iter 600, batch loss 0.0363, batch acc 0.9880
11:39:15.514 Training @ 89 epoch...
11:39:17.528   Training iter 50, batch loss 0.0290, batch acc 0.9916
11:39:19.530   Training iter 100, batch loss 0.0423, batch acc 0.9870
11:39:21.552   Training iter 150, batch loss 0.0431, batch acc 0.9862
11:39:23.576   Training iter 200, batch loss 0.0388, batch acc 0.9862
11:39:25.600   Training iter 250, batch loss 0.0335, batch acc 0.9902
11:39:27.609   Training iter 300, batch loss 0.0333, batch acc 0.9910
11:39:29.610   Training iter 350, batch loss 0.0390, batch acc 0.9876
11:39:31.632   Training iter 400, batch loss 0.0390, batch acc 0.9874
11:39:33.652   Training iter 450, batch loss 0.0459, batch acc 0.9870
11:39:35.673   Training iter 500, batch loss 0.0369, batch acc 0.9862
11:39:37.693   Training iter 550, batch loss 0.0405, batch acc 0.9868
11:39:39.701   Training iter 600, batch loss 0.0374, batch acc 0.9880
11:39:39.702 Training @ 90 epoch...
11:39:41.721   Training iter 50, batch loss 0.0404, batch acc 0.9890
11:39:43.730   Training iter 100, batch loss 0.0365, batch acc 0.9886
11:39:45.732   Training iter 150, batch loss 0.0285, batch acc 0.9920
11:39:47.742   Training iter 200, batch loss 0.0367, batch acc 0.9880
11:39:49.757   Training iter 250, batch loss 0.0316, batch acc 0.9908
11:39:51.769   Training iter 300, batch loss 0.0343, batch acc 0.9870
11:39:53.788   Training iter 350, batch loss 0.0435, batch acc 0.9866
11:39:55.798   Training iter 400, batch loss 0.0532, batch acc 0.9838
11:39:57.822   Training iter 450, batch loss 0.0435, batch acc 0.9862
11:39:59.842   Training iter 500, batch loss 0.0381, batch acc 0.9868
11:40:01.852   Training iter 550, batch loss 0.0292, batch acc 0.9894
11:40:03.875   Training iter 600, batch loss 0.0457, batch acc 0.9860
11:40:03.876 Testing @ 90 epoch...
11:40:05.049     Testing, total mean loss 0.04534, total acc 0.98520
11:40:05.049 Training @ 91 epoch...
11:40:07.075   Training iter 50, batch loss 0.0366, batch acc 0.9886
11:40:09.092   Training iter 100, batch loss 0.0368, batch acc 0.9898
11:40:11.113   Training iter 150, batch loss 0.0506, batch acc 0.9856
11:40:13.123   Training iter 200, batch loss 0.0335, batch acc 0.9896
11:40:15.139   Training iter 250, batch loss 0.0381, batch acc 0.9856
11:40:17.150   Training iter 300, batch loss 0.0404, batch acc 0.9878
11:40:19.160   Training iter 350, batch loss 0.0415, batch acc 0.9848
11:40:21.177   Training iter 400, batch loss 0.0388, batch acc 0.9872
11:40:23.179   Training iter 450, batch loss 0.0350, batch acc 0.9892
11:40:25.182   Training iter 500, batch loss 0.0346, batch acc 0.9900
11:40:27.206   Training iter 550, batch loss 0.0310, batch acc 0.9898
11:40:29.228   Training iter 600, batch loss 0.0402, batch acc 0.9872
11:40:29.229 Training @ 92 epoch...
11:40:31.255   Training iter 50, batch loss 0.0276, batch acc 0.9912
11:40:33.281   Training iter 100, batch loss 0.0368, batch acc 0.9882
11:40:35.302   Training iter 150, batch loss 0.0421, batch acc 0.9850
11:40:37.325   Training iter 200, batch loss 0.0390, batch acc 0.9874
11:40:39.340   Training iter 250, batch loss 0.0393, batch acc 0.9876
11:40:41.361   Training iter 300, batch loss 0.0379, batch acc 0.9874
11:40:43.385   Training iter 350, batch loss 0.0301, batch acc 0.9912
11:40:45.409   Training iter 400, batch loss 0.0446, batch acc 0.9872
11:40:47.430   Training iter 450, batch loss 0.0337, batch acc 0.9918
11:40:49.451   Training iter 500, batch loss 0.0391, batch acc 0.9886
11:40:51.471   Training iter 550, batch loss 0.0443, batch acc 0.9856
11:40:53.492   Training iter 600, batch loss 0.0395, batch acc 0.9880
11:40:53.493 Training @ 93 epoch...
11:40:55.508   Training iter 50, batch loss 0.0437, batch acc 0.9856
11:40:57.520   Training iter 100, batch loss 0.0372, batch acc 0.9888
11:40:59.530   Training iter 150, batch loss 0.0432, batch acc 0.9884
11:41:01.538   Training iter 200, batch loss 0.0393, batch acc 0.9868
11:41:03.552   Training iter 250, batch loss 0.0379, batch acc 0.9900
11:41:05.578   Training iter 300, batch loss 0.0297, batch acc 0.9902
11:41:07.601   Training iter 350, batch loss 0.0297, batch acc 0.9914
11:41:09.623   Training iter 400, batch loss 0.0320, batch acc 0.9908
11:41:11.649   Training iter 450, batch loss 0.0355, batch acc 0.9876
11:41:13.672   Training iter 500, batch loss 0.0334, batch acc 0.9894
11:41:15.693   Training iter 550, batch loss 0.0513, batch acc 0.9844
11:41:17.716   Training iter 600, batch loss 0.0377, batch acc 0.9872
11:41:17.717 Training @ 94 epoch...
11:41:19.743   Training iter 50, batch loss 0.0324, batch acc 0.9900
11:41:21.764   Training iter 100, batch loss 0.0391, batch acc 0.9870
11:41:23.786   Training iter 150, batch loss 0.0317, batch acc 0.9902
11:41:25.808   Training iter 200, batch loss 0.0325, batch acc 0.9900
11:41:27.827   Training iter 250, batch loss 0.0483, batch acc 0.9870
11:41:29.848   Training iter 300, batch loss 0.0381, batch acc 0.9880
11:41:31.872   Training iter 350, batch loss 0.0412, batch acc 0.9876
11:41:33.882   Training iter 400, batch loss 0.0392, batch acc 0.9880
11:41:35.902   Training iter 450, batch loss 0.0369, batch acc 0.9888
11:41:37.929   Training iter 500, batch loss 0.0405, batch acc 0.9872
11:41:39.952   Training iter 550, batch loss 0.0302, batch acc 0.9894
11:41:41.973   Training iter 600, batch loss 0.0455, batch acc 0.9864
11:41:41.974 Training @ 95 epoch...
11:41:43.992   Training iter 50, batch loss 0.0389, batch acc 0.9862
11:41:46.021   Training iter 100, batch loss 0.0328, batch acc 0.9894
11:41:48.047   Training iter 150, batch loss 0.0399, batch acc 0.9886
11:41:50.070   Training iter 200, batch loss 0.0290, batch acc 0.9910
11:41:52.099   Training iter 250, batch loss 0.0379, batch acc 0.9886
11:41:54.123   Training iter 300, batch loss 0.0384, batch acc 0.9872
11:41:56.146   Training iter 350, batch loss 0.0276, batch acc 0.9906
11:41:58.171   Training iter 400, batch loss 0.0357, batch acc 0.9878
11:42:00.198   Training iter 450, batch loss 0.0402, batch acc 0.9886
11:42:02.221   Training iter 500, batch loss 0.0408, batch acc 0.9874
11:42:04.240   Training iter 550, batch loss 0.0373, batch acc 0.9866
11:42:06.261   Training iter 600, batch loss 0.0518, batch acc 0.9854
11:42:06.262 Testing @ 95 epoch...
11:42:07.436     Testing, total mean loss 0.04639, total acc 0.98370
11:42:07.436 Training @ 96 epoch...
11:42:09.470   Training iter 50, batch loss 0.0294, batch acc 0.9910
11:42:11.501   Training iter 100, batch loss 0.0336, batch acc 0.9906
11:42:13.524   Training iter 150, batch loss 0.0380, batch acc 0.9876
11:42:15.556   Training iter 200, batch loss 0.0345, batch acc 0.9906
11:42:17.582   Training iter 250, batch loss 0.0289, batch acc 0.9912
11:42:19.620   Training iter 300, batch loss 0.0344, batch acc 0.9884
11:42:21.653   Training iter 350, batch loss 0.0487, batch acc 0.9862
11:42:23.683   Training iter 400, batch loss 0.0407, batch acc 0.9874
11:42:25.711   Training iter 450, batch loss 0.0362, batch acc 0.9886
11:42:27.737   Training iter 500, batch loss 0.0428, batch acc 0.9862
11:42:29.738   Training iter 550, batch loss 0.0419, batch acc 0.9854
11:42:31.770   Training iter 600, batch loss 0.0455, batch acc 0.9836
11:42:31.771 Training @ 97 epoch...
11:42:33.797   Training iter 50, batch loss 0.0330, batch acc 0.9910
11:42:35.822   Training iter 100, batch loss 0.0365, batch acc 0.9878
11:42:37.851   Training iter 150, batch loss 0.0333, batch acc 0.9884
11:42:39.878   Training iter 200, batch loss 0.0442, batch acc 0.9872
11:42:41.904   Training iter 250, batch loss 0.0490, batch acc 0.9832
11:42:43.931   Training iter 300, batch loss 0.0367, batch acc 0.9872
11:42:45.952   Training iter 350, batch loss 0.0272, batch acc 0.9902
11:42:47.975   Training iter 400, batch loss 0.0331, batch acc 0.9884
11:42:50.001   Training iter 450, batch loss 0.0426, batch acc 0.9860
11:42:52.023   Training iter 500, batch loss 0.0372, batch acc 0.9876
11:42:54.050   Training iter 550, batch loss 0.0396, batch acc 0.9888
11:42:56.072   Training iter 600, batch loss 0.0399, batch acc 0.9896
11:42:56.072 Training @ 98 epoch...
11:42:58.100   Training iter 50, batch loss 0.0375, batch acc 0.9880
11:43:00.122   Training iter 100, batch loss 0.0345, batch acc 0.9884
11:43:02.152   Training iter 150, batch loss 0.0328, batch acc 0.9900
11:43:04.183   Training iter 200, batch loss 0.0475, batch acc 0.9870
11:43:06.209   Training iter 250, batch loss 0.0307, batch acc 0.9890
11:43:08.210   Training iter 300, batch loss 0.0300, batch acc 0.9900
11:43:10.210   Training iter 350, batch loss 0.0305, batch acc 0.9894
11:43:12.239   Training iter 400, batch loss 0.0523, batch acc 0.9848
11:43:14.266   Training iter 450, batch loss 0.0317, batch acc 0.9894
11:43:16.296   Training iter 500, batch loss 0.0385, batch acc 0.9876
11:43:18.329   Training iter 550, batch loss 0.0518, batch acc 0.9846
11:43:20.330   Training iter 600, batch loss 0.0337, batch acc 0.9866
11:43:20.331 Training @ 99 epoch...
11:43:22.364   Training iter 50, batch loss 0.0318, batch acc 0.9904
11:43:24.390   Training iter 100, batch loss 0.0350, batch acc 0.9894
11:43:26.401   Training iter 150, batch loss 0.0363, batch acc 0.9874
11:43:28.425   Training iter 200, batch loss 0.0397, batch acc 0.9876
11:43:30.440   Training iter 250, batch loss 0.0318, batch acc 0.9882
11:43:32.453   Training iter 300, batch loss 0.0405, batch acc 0.9872
11:43:34.481   Training iter 350, batch loss 0.0334, batch acc 0.9892
11:43:36.507   Training iter 400, batch loss 0.0409, batch acc 0.9866
11:43:38.533   Training iter 450, batch loss 0.0392, batch acc 0.9872
11:43:40.563   Training iter 500, batch loss 0.0354, batch acc 0.9890
11:43:42.590   Training iter 550, batch loss 0.0398, batch acc 0.9866
11:43:44.613   Training iter 600, batch loss 0.0425, batch acc 0.9880
